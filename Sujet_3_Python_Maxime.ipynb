{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fee4912-d12f-4b18-a9d9-f19a3704a9da",
   "metadata": {},
   "source": [
    "# Funathon 2023 - Sujet 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157edb9-8f45-4ad1-ab37-6c1a2e67a7c5",
   "metadata": {},
   "source": [
    "Responsables :\n",
    "- Julie Sixou, D2E\n",
    "- Antoine Palazzolo, SSP Lab\n",
    "- Thomas Faria, SSP Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c3a94a-ef0d-4501-9228-220d31f3ceb6",
   "metadata": {},
   "source": [
    "# Habitudes alimentaires à partir des données INCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab8a7a3-50dc-4e38-9205-420b9cab1f55",
   "metadata": {},
   "source": [
    "## Avant de commencer..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c84d3c-2058-4266-bf2f-d52b4a282e6f",
   "metadata": {},
   "source": [
    "Ce sujet est disponible dans 2 langages : R et Python.\n",
    "Ce notebook correspond à la version Python, qui est la plus complète des deux.\n",
    "\n",
    "Il s'agit là principalement d'une initiation à l'analyse de données et à la data visualization, à travers l'étude des données de consommations et habitudes alimentaires de l'[étude INCA 3](https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/).\n",
    "Le sujet est constituée de 3 parties distinctes et indépendantes :\n",
    "- Analyse exploratoire des données et visualisations\n",
    "- Clustering d'individus : ACP, K-moyennes, Clustering Ascendant Hiérarchique\n",
    "- Prédiction de l'IMC : premiers pas vers les méthodes de ML supervisé\n",
    "\n",
    "Il est également possible de ne faire qu'une ou deux parties du sujet. A noter que les corrigés présentés dans le sujet ne sont qu'une suggestion de comment répondre aux questions posées, mais qu'il existe évidemment d'autres manières de faire, parfois même bien meilleures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adbe276-e2db-471a-931c-be05efea1069",
   "metadata": {},
   "source": [
    "Si jamais vous n'êtes pas familiers avec l'une des thématiques du sujet, nous ne saurions que trop vous recommander de jeter un oeil aux ressources suivantes :\n",
    "- Débuter avec Pandas : https://pythonds.linogaliana.fr/pandas/\n",
    "- Une introduction au clustering : https://pythonds.linogaliana.fr/clustering/\n",
    "- Une introduction aux régressions en Python : https://pythonds.linogaliana.fr/regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e875b-59ac-48cb-8629-e50f7c3af232",
   "metadata": {},
   "source": [
    "Pour en savoir plus sur les données utilisées pour ce sujet et sur le contexte de l'étude : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/\n",
    "\n",
    "Pour lire la documentation associée aux données : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc0ae1-3e63-4792-8f12-91dd0ef12206",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ccb064-1f6b-4152-852c-729209734fc7",
   "metadata": {},
   "source": [
    "Si vous n'utilisez pas le Datalab, exécutez les cellules ci-dessous pour installer les packages nécessaires au sujet :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2450c2-3fb1-4aaf-91ef-30fbe145eadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet -r requirements_Python.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14484540-40cf-471e-a761-dd419fb492be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cd2bb9-d628-436b-a154-c184296c4252",
   "metadata": {},
   "source": [
    "Exécutez également les cellules ci-dessous pour importer l'ensemble des jeux de données nécessaires à l'étude :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2e953a-5d2a-4644-a9c2-c6ca16d60a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1e139-05ca-4d27-8965-ee9659770945",
   "metadata": {},
   "source": [
    "#### Imports des données avec s3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72b31fc-f676-489f-93c3-4adce67aacc3",
   "metadata": {},
   "source": [
    "A favoriser, en utilisant les données déjà importées sur le Datalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783894b-60fe-4df8-98e6-4a34729e778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pyarrow import csv, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede8e94d-8a1d-4738-a4f1-21ddb271009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = fs.S3FileSystem(endpoint_override='https://'+'minio.lab.sspcloud.fr')\n",
    "bucket = \"projet-funathon\"\n",
    "path_data = \"2023/sujet3/diffusion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e0324aa7-da42-4381-9cd8-f7d71c66482e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with s3.open_input_file(f\"{bucket}/{path_data}/description-indiv.csv\") as file:\n",
    "    description_indiv = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
    "\n",
    "with s3.open_input_file(f\"{bucket}/{path_data}/habitudes-indiv.csv\") as file:\n",
    "    habitudes_indiv = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
    "\n",
    "with s3.open_input_file(f\"{bucket}/{path_data}/actphys-sedent.csv\") as file:\n",
    "    actphys_sedent = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
    "\n",
    "with s3.open_input_file(f\"{bucket}/{path_data}/fpq.csv\") as file:\n",
    "    fpq = csv.read_csv(file, parse_options=csv.ParseOptions(delimiter=\";\")).to_pandas()\n",
    "\n",
    "\n",
    "# Pour la partie 3\n",
    "df = pd.read_parquet(f'{bucket}/{path_data}/description_individu_inca.parquet', filesystem=s3).infer_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a514efc-732c-4aca-8c29-eacdcdbe55c4",
   "metadata": {},
   "source": [
    "#### Imports des données depuis data.gouv.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd17192-125e-429c-bd50-96ddc6c2da5e",
   "metadata": {},
   "source": [
    "Eviter cette option pour ne pas surcharger le SSP Cloud si trop de participants font des téléchargements en même temps. A n'utiliser que si impossibilité d'utiliser le Datalab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccd4507-22d0-4a28-a2ef-1ddd440a676a",
   "metadata": {},
   "source": [
    "```python\n",
    "description_indiv = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/f982ee4a-b2db-4608-ab95-bfe51dfc4897\",\n",
    "                            sep=\";\"\n",
    "                            ).infer_objects()\n",
    "\n",
    "habitudes_indiv = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/099351b9-e32e-4e38-8f23-dec21fd07c71\",\n",
    "                            sep=\";\"\n",
    "                            ).infer_objects()\n",
    "\n",
    "actphys_sedent = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/e9a34b81-2105-4d82-a023-c14947fb2b2c\",\n",
    "                            sep=\";\"\n",
    "                            ).infer_objects()\n",
    "\n",
    "fpq = pd.read_csv(\"https://www.data.gouv.fr/fr/datasets/r/32e79499-9897-423b-acd6-143121340f86\",\n",
    "                            sep=\";\"\n",
    "                            ).infer_objects()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b023787-27db-4ad6-8cf6-f2d7cd3e443d",
   "metadata": {},
   "source": [
    "## Partie 1 : Analyse exploratoire des données et visualisations\n",
    "\n",
    "Premier point de contact : Julie Sixou\n",
    "\n",
    "Boîte à outils de ce qu'il est possible de faire avec ```pandas``` et ```matplotlib.pyplot```\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa9e446-8890-4641-bb89-f3a89e7f0479",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c505b8b-a7c4-4f64-ac13-ee90f4a8dc13",
   "metadata": {},
   "source": [
    "Explorons la base de données INCA3 : dans cette partie, nous allons vous montrer comment produire des graphes et statistiques univariées et bivariées.\n",
    "\n",
    "Le dictionnaire des variables et des modalités peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da0c89-a253-4bee-b145-d33c9df21697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation de Cartiflette pour la partie \"Cartographie\" (nécessaire que si vous n'utilisez pas le Datalab)\n",
    "!pip install git+https://github.com/inseefrlab/cartogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5133fdab-6cc4-4b35-8d98-1aa394c8416a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "\n",
    "import cartiflette.s3\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import seaborn as sns\n",
    "\n",
    "from pyarrow import fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c3b92-7832-4d9a-8f11-0a8fa644c0d2",
   "metadata": {},
   "source": [
    "### 1. Statistiques univariées avec la table _description_indiv_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba045c-d3eb-4f73-a071-021bd08ed9bd",
   "metadata": {},
   "source": [
    "Quelques exemples de ce qu'il est possible de faire avec ```matplotlib.pyplot``` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566ec9a-93b2-4480-831f-ec9bbc1a994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme des IMC\n",
    "\n",
    "description_indiv[\"imc\"].hist(\n",
    "    bins=100,  # Nombre de barres de l'histogramme\n",
    "    range=(0, 100),  # Plage des valeurs affichées sur l'axe x\n",
    "    color='skyblue',  # Couleur des barres de l'histogramme\n",
    "    edgecolor='black',  # Couleur des bords des barres\n",
    "    alpha=0.7  # Transparence des barres\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5455a606-72ba-4778-b488-22135e01647c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Histogramme des niveaux de diplôme\n",
    "\n",
    "description_indiv[\"diplome_interv\"].hist(\n",
    "    color=\"red\",\n",
    "    edgecolor=\"black\",\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "\n",
    "# Cette fois on ajoute une légende et un titre\n",
    "plt.title(\"Histogramme des niveaux de diplôme\")\n",
    "plt.xlabel(\"Code du niveau de diplôme\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a54e5-3c12-4450-9232-f7f6d3cbaed0",
   "metadata": {},
   "source": [
    "Recodons la variable des niveaux de diplôme pour mieux comprendre le graphe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a3999-1184-4c84-b052-8483983d04a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodage des niveaux de diplôme\n",
    "\n",
    "dico_libelle_diplome = {1: \"Aucun diplôme, n'a jamais été scolarisé\", \n",
    "                        2: \"Aucun diplôme, scolarité s'est arrêtée à l'école primaire\", \n",
    "                        3: \"Aucun diplôme, scolarité s'est arrêtée au collège\",\n",
    "                       4:\"Aucun diplôme, scolarité s'est arrêtée au delà du collège\",\n",
    "                       5:\"Aucun diplôme, sans précision\",\n",
    "                       6:\"CEP\",\n",
    "                       7:\"CAP, BEP, BEPC, brevet élémentaire, brevet de compagnon\",\n",
    "                       8:\"Baccalauréat technologique ou professionnel, Brevet professionnel ou de technicien, BEA, BEC, BEI, BEH, capacité en droit \",\n",
    "                       9:\"Baccalauréat général\",\n",
    "                       10:\"Diplôme de 1er cycle universitaire (Bac +3, licence), BTS, DUT, DEST, DEUG, diplôme des professions sociales ou de la santé, d'infirmier\",\n",
    "                       11:\"Diplôme de 2ème cycle universitaire (Bac+4, Bac+5), Master, Maîtrise, diplôme d'ingénieur, d'une grande école\",\n",
    "                       12:\"Diplôme de 3ème cycle universitaire (>Bac+5, doctorat), diplôme de vétérinaire, médecin, pharmacien\",\n",
    "                       13:\"Refus\",\n",
    "                       14:\"Ne sait pas\"}\n",
    "\n",
    "description_indiv['categorie_diplome'] = description_indiv['diplome_interv'].replace(dico_libelle_diplome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98b997b6-c229-4c6f-b2a0-92bbe14c2e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tableau des fréquences de chaque catégorie de diplome\n",
    "counts_diplome = description_indiv['categorie_diplome'].value_counts()\n",
    "\n",
    "# Graphique en barres horizontales\n",
    "counts_diplome.plot(kind='barh',\n",
    "                   color=\"red\",\n",
    "                   edgecolor=\"black\",\n",
    "                   alpha=0.7)\n",
    "\n",
    "\n",
    "plt.title(\"Histogramme des niveaux de diplôme\")\n",
    "plt.xlabel(\"Libelle du niveau de diplôme\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da7e0a4b-77ed-4e22-8ea9-214187de838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme type d'agglomération\n",
    "\n",
    "dico_libelle_agglo = {1:\"Rural\",\n",
    "                     2:\"2000 - 19 999 hab\",\n",
    "                     3:\"20 000 - 99 999 hab\",\n",
    "                     4:\"+ 100 000 hab\",\n",
    "                     5:\"Paris\"}\n",
    "\n",
    "description_indiv['categorie_agglo'] = description_indiv['agglo_5cl'].replace(dico_libelle_agglo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7208ab5-5880-4be7-823c-5b20f44ae131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "5850    5\n",
       "5851    5\n",
       "5852    4\n",
       "5853    4\n",
       "5854    5\n",
       "Name: agglo_5cl, Length: 5855, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_indiv['agglo_5cl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f11f33a4-1c3f-4885-9b93-a01ba81b8d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_agglo = description_indiv['categorie_agglo'].value_counts()\n",
    "\n",
    "# Générer le graphique en barres horizontales\n",
    "counts_agglo.plot(kind='barh',\n",
    "                   color=\"green\",\n",
    "                   edgecolor=\"black\",\n",
    "                   alpha=0.7)\n",
    "\n",
    "\n",
    "plt.title(\"Histogramme des types d'agglomération\")\n",
    "plt.xlabel(\"Type d'agglomération\")\n",
    "plt.ylabel(\"Nombre d'individus\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eebd6b-9344-4bc6-a915-a0710e37d9a5",
   "metadata": {},
   "source": [
    "A vous de jouer, faites la même chose pour les tranches de revenu : histogramme de la variable **RUC_4cl** qui donne le revenu mensuel total du foyer par unité de consommation (UC) en 4 classes. Les modalités de la variable sont les suivantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "315c44f2-5112-432e-9c0d-589d0d88cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Niveau de vie\n",
    "\n",
    "dico_RUC = {1:\"<900 €/mois/UC\",\n",
    "            2:\"[900-1 340[ €/mois/UC\",\n",
    "            3:\"[1 340-1 850[ €/mois/U\",\n",
    "            4:\">=1 850 €/mois/UC\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a67da53f-13a5-4be7-9f5b-9baa3744d1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUC_4cl_label\n",
       "[900-1 340[ €/mois/UC     1362\n",
       "<900 €/mois/UC            1355\n",
       ">=1 850 €/mois/UC         1341\n",
       "[1 340-1 850[ €/mois/U    1339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO\n",
    "description_indiv['RUC_4cl_label'] = description_indiv['RUC_4cl'].replace(dico_RUC)\n",
    "tranche_revenu_count = description_indiv['RUC_4cl_label'].value_counts()#.sort_values(ascending=False)\n",
    "tranche_revenu_count.plot(kind='barh',\n",
    "                   color=\"green\",\n",
    "                   edgecolor=\"black\",\n",
    "                   alpha=0.7)\n",
    "tranche_revenu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59e35482-c913-4320-936b-dd5001a5012c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1 340-1 850[ €/mois/U\n",
       "1            >=1 850 €/mois/UC\n",
       "2        [900-1 340[ €/mois/UC\n",
       "3            >=1 850 €/mois/UC\n",
       "4               <900 €/mois/UC\n",
       "                 ...          \n",
       "5850     [900-1 340[ €/mois/UC\n",
       "5851     [900-1 340[ €/mois/UC\n",
       "5852         >=1 850 €/mois/UC\n",
       "5853            <900 €/mois/UC\n",
       "5854    [1 340-1 850[ €/mois/U\n",
       "Name: RUC_4cl_label, Length: 5855, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_indiv['RUC_4cl_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7d98b571-cf3c-4afa-bbe4-56766c10bedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUC_4cl_label\n",
       "[900-1 340[ €/mois/UC     1362\n",
       "<900 €/mois/UC            1355\n",
       ">=1 850 €/mois/UC         1341\n",
       "[1 340-1 850[ €/mois/U    1339\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tranche_revenu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a91493-8198-4f0a-a898-611606de659b",
   "metadata": {},
   "source": [
    "### 2. Statistiques bivariées avec les tables _description_indiv_ et _habitudes_indiv_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79695f8-5932-4b1d-ba18-0ad2c228cf71",
   "metadata": {},
   "source": [
    "Quelques exemples de ce qu'il est possible de faire avec ```matplotlib.pyplot``` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e22e413-594f-4b12-8a61-074b92cef226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOMEN', 'NOIND', 'ech', 'enf_allaite', 'pop1', 'pop2', 'pop3',\n",
       "       'pond_indiv_adu_pop1', 'pond_indiv_enf_pop1', 'pond_indiv_adu_pop2',\n",
       "       ...\n",
       "       'bmr_kcal', 'sousest0', 'surest0', 'sousest1', 'sousest3', 'sousext',\n",
       "       'surext', 'categorie_diplome', 'categorie_agglo', 'RUC_4cl_label'],\n",
       "      dtype='object', length=188)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_indiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "118925dd-48c3-4a49-b799-d8625dd516f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Imc moyen par niveau de diplôme\n",
    "\n",
    "imc_par_diplome = description_indiv.groupby('categorie_diplome')['imc'].mean().sort_values(ascending=False)\n",
    "imc_par_diplome.plot(kind='barh',\n",
    "                    color=\"grey\",\n",
    "                    alpha=0.7)\n",
    "\n",
    "plt.title('Imc moyen par niveau de diplôme')\n",
    "plt.xlabel('Imc moyen')\n",
    "plt.ylabel('Niveau de diplôme')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f67d36c6-12a4-4aa4-aff3-0e0791273085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Autoproduction par type d'agglomération\n",
    "\n",
    "description_x_habitudes = pd.merge(description_indiv, habitudes_indiv,on=\"NOIND\")\n",
    "autoprod_par_agglo = description_x_habitudes.groupby('categorie_agglo')['autoproduction'].mean().sort_values(ascending=False)\n",
    "autoprod_par_agglo.plot(kind='barh',\n",
    "                    color=\"darkgreen\",\n",
    "                    alpha=0.7)\n",
    "\n",
    "plt.title(\"Part d'autoproduction par type d'agglomération\")\n",
    "plt.xlabel(\"Part d'autoproduction\")\n",
    "plt.ylabel(\"Type d'agglomération\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1c608-37e5-41b2-a0f3-52c767c9d2cc",
   "metadata": {},
   "source": [
    "A vous de jouer, représentez le croisement entre le score d'insécurité d'alimentaire (**IA_score**, on peut en faire la moyenne) et les tranches de revenu (par exemple, **RUC_4cl** qu'on a recodée précédemment, ou **revenu** qui donne le revenu disponible codé en plus de classes.)\n",
    "\n",
    "Le dictionnaire des variables et des modalités peut se trouver ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ca0a18bc-0350-478d-9f93-3d15e8baa155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUC_4cl_label\n",
       "<900 €/mois/UC            5.115756\n",
       "[900-1 340[ €/mois/UC     4.250761\n",
       "[1 340-1 850[ €/mois/U    3.958101\n",
       ">=1 850 €/mois/UC         3.599643\n",
       "Name: IA_score, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Score d'IA par tranche de revenu\n",
    "\n",
    "score_ia_par_revenu = description_x_habitudes.groupby('RUC_4cl_label')['IA_score'].mean().sort_values(ascending=False)\n",
    "score_ia_par_revenu.plot(kind='barh',\n",
    "                    color=\"darkgreen\",\n",
    "                    alpha=0.7)\n",
    "plt.title(\"Score IA par tranche de revenu\")\n",
    "plt.xlabel(\"Score IA\")\n",
    "plt.ylabel(\"Tranche de revenu\")\n",
    "plt.plot()\n",
    "score_ia_par_revenu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b8b1d4-ff77-4e61-a0fe-86f0565c86e5",
   "metadata": {},
   "source": [
    "Finalement, on se rend compte que la base est très riche et contient beaucoup de variables : beaucoup d'entre elles sont quantitatives, et on peut s'amuser à représenter leurs relations de corrélations en même temps dans une matrice de corrélation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b19cc5f6-6bba-484c-a45b-e232e64016d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice de corrélation\n",
    "\n",
    "df_num = description_x_habitudes.select_dtypes(include=['int', 'float'])\n",
    "df_num=df_num[[\"revenu\",\"IA_score\",\"imc\",\"regime_vegetarien\",\"poidsmax\",\"fume\",\"source_famille\",\"jardin_potager\",\"autoconsommation\",\"consommation_bio\"]]\n",
    "matrice_correlation = df_num.corr()\n",
    "matrice_correlation\n",
    "\n",
    "sns.heatmap(matrice_correlation, annot=False, cmap='crest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d5007b0-cd88-4561-a749-ceb2263b10ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOMEN</th>\n",
       "      <th>NOIND</th>\n",
       "      <th>ech</th>\n",
       "      <th>enf_allaite</th>\n",
       "      <th>pop1</th>\n",
       "      <th>pop2</th>\n",
       "      <th>pop3</th>\n",
       "      <th>pond_indiv_adu_pop1</th>\n",
       "      <th>pond_indiv_enf_pop1</th>\n",
       "      <th>pond_indiv_adu_pop2</th>\n",
       "      <th>pond_indiv_enf_pop2</th>\n",
       "      <th>pond_indiv_adu_pop3</th>\n",
       "      <th>pond_indiv_enf_pop3</th>\n",
       "      <th>pond_men_pop1</th>\n",
       "      <th>pond_men_pop2</th>\n",
       "      <th>zae</th>\n",
       "      <th>strate</th>\n",
       "      <th>fpc1</th>\n",
       "      <th>fpc2</th>\n",
       "      <th>fpc3</th>\n",
       "      <th>saison_pop1</th>\n",
       "      <th>saison_pop2</th>\n",
       "      <th>saison_pop3</th>\n",
       "      <th>region_adm_12cl</th>\n",
       "      <th>region_inca3</th>\n",
       "      <th>agglo_5cl</th>\n",
       "      <th>sex_PS</th>\n",
       "      <th>tage_PS</th>\n",
       "      <th>tage_PS_mois</th>\n",
       "      <th>lien_rep_enf</th>\n",
       "      <th>diplome_interv</th>\n",
       "      <th>etude_4cl_interv</th>\n",
       "      <th>situ_prof_5cl_interv</th>\n",
       "      <th>atrav_interv</th>\n",
       "      <th>trav_nuit_interv</th>\n",
       "      <th>trav_nuit_2cl_interv</th>\n",
       "      <th>PCS_8cl_interv</th>\n",
       "      <th>PCS_4cl_interv</th>\n",
       "      <th>tps_travail_interv</th>\n",
       "      <th>vacances_interv</th>\n",
       "      <th>interv_PR</th>\n",
       "      <th>sex_PR</th>\n",
       "      <th>tage_PR</th>\n",
       "      <th>lien_interv_PR</th>\n",
       "      <th>lien_PS_PR</th>\n",
       "      <th>diplome_PR</th>\n",
       "      <th>etude_4cl_PR</th>\n",
       "      <th>atrav_PR</th>\n",
       "      <th>PCS_8cl_PR</th>\n",
       "      <th>PCS_4cl_PR</th>\n",
       "      <th>tps_travail_PR</th>\n",
       "      <th>stat_log_2cl</th>\n",
       "      <th>soins</th>\n",
       "      <th>situ_fin_3cl</th>\n",
       "      <th>revenu</th>\n",
       "      <th>RUC_4cl</th>\n",
       "      <th>nbpers</th>\n",
       "      <th>nbadu</th>\n",
       "      <th>nbenf</th>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <th>IA_statut</th>\n",
       "      <th>IA_score</th>\n",
       "      <th>taille_m</th>\n",
       "      <th>taille_d</th>\n",
       "      <th>taille</th>\n",
       "      <th>poids_m</th>\n",
       "      <th>poids_d</th>\n",
       "      <th>poids</th>\n",
       "      <th>imc</th>\n",
       "      <th>statnut</th>\n",
       "      <th>maladie_allergie_alim</th>\n",
       "      <th>intoall_confirm_med</th>\n",
       "      <th>regime_vegetarien</th>\n",
       "      <th>regime_allergie</th>\n",
       "      <th>regime_maigrir_med</th>\n",
       "      <th>regime_maigrir_choix</th>\n",
       "      <th>regime_autre_med</th>\n",
       "      <th>regime_raisonmed_libelle</th>\n",
       "      <th>regime_poidsstable</th>\n",
       "      <th>regime_forme</th>\n",
       "      <th>regime_autreraison</th>\n",
       "      <th>regime_non</th>\n",
       "      <th>veget_viande</th>\n",
       "      <th>veget_prodmer</th>\n",
       "      <th>veget_prodlait</th>\n",
       "      <th>veget_oeuf</th>\n",
       "      <th>veget_miel</th>\n",
       "      <th>veget_autre_alim</th>\n",
       "      <th>veget_autre_alim_libelle</th>\n",
       "      <th>allergie_laitvache</th>\n",
       "      <th>allergie_prepainfsoja</th>\n",
       "      <th>allergie_prepainfamande</th>\n",
       "      <th>allergie_gluten</th>\n",
       "      <th>allergie_farineble</th>\n",
       "      <th>allergie_lupin</th>\n",
       "      <th>allergie_arachide</th>\n",
       "      <th>allergie_fruitcoque</th>\n",
       "      <th>allergie_fruitcoque_libelle</th>\n",
       "      <th>allergie_oeuf</th>\n",
       "      <th>allergie_poisson</th>\n",
       "      <th>allergie_crustace</th>\n",
       "      <th>allergie_mollusque</th>\n",
       "      <th>allergie_soja</th>\n",
       "      <th>allergie_sesame</th>\n",
       "      <th>allergie_moutarde</th>\n",
       "      <th>allergie_sulfite</th>\n",
       "      <th>allergie_celeri</th>\n",
       "      <th>allergie_autres_fruitleg</th>\n",
       "      <th>allergie_autres_fl_libelle</th>\n",
       "      <th>allergie_autresalim</th>\n",
       "      <th>allergie_autresalim_libelle</th>\n",
       "      <th>allergie_nondetermine</th>\n",
       "      <th>allergie_fruits</th>\n",
       "      <th>allergie_legumes</th>\n",
       "      <th>regime_passe</th>\n",
       "      <th>regime_nb_2dernann</th>\n",
       "      <th>regime_nb_anter2dernann</th>\n",
       "      <th>regime_type</th>\n",
       "      <th>regime_type_libelle</th>\n",
       "      <th>regime_duree_sem</th>\n",
       "      <th>regime_duree_mois</th>\n",
       "      <th>regime_duree_nsp</th>\n",
       "      <th>poids_anndern</th>\n",
       "      <th>poids_anndern_nsp</th>\n",
       "      <th>poids_modif</th>\n",
       "      <th>poids_modifalim</th>\n",
       "      <th>poids_plusAP</th>\n",
       "      <th>poids_medicaments</th>\n",
       "      <th>poids_substituts</th>\n",
       "      <th>poids_chirurgie</th>\n",
       "      <th>poids_modifalim_laityaourt</th>\n",
       "      <th>poids_modifalim_fromage</th>\n",
       "      <th>poids_modifalim_mg</th>\n",
       "      <th>poids_modifalim_fruit</th>\n",
       "      <th>poids_modifalim_legume</th>\n",
       "      <th>poids_modifalim_pdtfeculent</th>\n",
       "      <th>poids_modifalim_pizza</th>\n",
       "      <th>poids_modifalim_pain</th>\n",
       "      <th>poids_modifalim_vrouge</th>\n",
       "      <th>poids_modifalim_volaille</th>\n",
       "      <th>poids_modifalim_oeuf</th>\n",
       "      <th>poids_modifalim_gateau</th>\n",
       "      <th>poids_modifalim_edulcorant</th>\n",
       "      <th>poids_modifalim_pdtsalleges</th>\n",
       "      <th>poids_modifalim_BS</th>\n",
       "      <th>poids_modifalim_eau</th>\n",
       "      <th>poids_modifalim_autre</th>\n",
       "      <th>poids_modifalim_autre_libelle</th>\n",
       "      <th>poids_perception</th>\n",
       "      <th>poidsmax</th>\n",
       "      <th>poidsmax_nsp</th>\n",
       "      <th>age_poidsmax</th>\n",
       "      <th>age_poidsmax_nsp</th>\n",
       "      <th>poidsmin</th>\n",
       "      <th>poidsmin_nsp</th>\n",
       "      <th>age_poidsmin</th>\n",
       "      <th>age_poidsmin_nsp</th>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <th>menopause</th>\n",
       "      <th>enceinte</th>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <th>allaite</th>\n",
       "      <th>allaite_nbsem</th>\n",
       "      <th>enceinte_12dermois</th>\n",
       "      <th>fume</th>\n",
       "      <th>nb_cigarettes_jour</th>\n",
       "      <th>nb_cigarettes_sem</th>\n",
       "      <th>nb_cigarettes_nsp</th>\n",
       "      <th>nb_cigares_jour</th>\n",
       "      <th>nb_cigares_sem</th>\n",
       "      <th>nb_cigares_nsp</th>\n",
       "      <th>nb_pipes_jour</th>\n",
       "      <th>nb_pipes_sem</th>\n",
       "      <th>nb_pipes_nsp</th>\n",
       "      <th>fume_age_debut</th>\n",
       "      <th>fume_age_debut_nsp</th>\n",
       "      <th>fume_age_arret</th>\n",
       "      <th>fume_age_arret_nsp</th>\n",
       "      <th>bmr_kcal</th>\n",
       "      <th>sousest0</th>\n",
       "      <th>surest0</th>\n",
       "      <th>sousest1</th>\n",
       "      <th>sousest3</th>\n",
       "      <th>sousext</th>\n",
       "      <th>surext</th>\n",
       "      <th>categorie_diplome</th>\n",
       "      <th>categorie_agglo</th>\n",
       "      <th>RUC_4cl_label</th>\n",
       "      <th>POPULATION</th>\n",
       "      <th>periode_reference</th>\n",
       "      <th>repasenfantmidi_vous</th>\n",
       "      <th>repasenfantmidi_am</th>\n",
       "      <th>repasenfantmidi_creche</th>\n",
       "      <th>repasenfantmidi_parent</th>\n",
       "      <th>repasenfantmidi_autre</th>\n",
       "      <th>repasenfantmidi_autre_libelle</th>\n",
       "      <th>repasenfant_freq</th>\n",
       "      <th>conso_bebe_sein</th>\n",
       "      <th>lait_plussouvent</th>\n",
       "      <th>lait_plusvt_li_autr_anim_libelle</th>\n",
       "      <th>lait_plusvt_pi_autre_veg_libelle</th>\n",
       "      <th>lait_plusvt_boisson_veg_libelle</th>\n",
       "      <th>lait_plusvt_autre_anim_libelle</th>\n",
       "      <th>lait_plusvt_autre_libelle</th>\n",
       "      <th>lait_occ_laitmaternel</th>\n",
       "      <th>lait_occ_lait_1e_age</th>\n",
       "      <th>lait_occ_lait_2e_age</th>\n",
       "      <th>lait_occ_lait_croissance</th>\n",
       "      <th>lait_occ_li_autre_anim</th>\n",
       "      <th>lait_occ_li_autre_anim_libelle</th>\n",
       "      <th>lait_occ_li1e_age_protsoja</th>\n",
       "      <th>lait_occ_li2e_age_protsoja</th>\n",
       "      <th>lait_occ_soja_croissance</th>\n",
       "      <th>lait_occ_li1e_age_protriz</th>\n",
       "      <th>lait_occ_li2e_age_protriz</th>\n",
       "      <th>lait_occ_riz_croissance</th>\n",
       "      <th>lait_occ_pi_autre_veg</th>\n",
       "      <th>lait_occ_pi_autre_veg_libelle</th>\n",
       "      <th>lait_occ_boisson_lait_bebe</th>\n",
       "      <th>lait_occ_lait_regime_infantile</th>\n",
       "      <th>lait_occ_lait_vache</th>\n",
       "      <th>lait_occ_boisson_soja</th>\n",
       "      <th>lait_occ_boisson_veg</th>\n",
       "      <th>lait_occ_boisson_veg_libelle</th>\n",
       "      <th>lait_occ_autre_anim</th>\n",
       "      <th>lait_occ_autre_anim_libelle</th>\n",
       "      <th>lait_occ_autre</th>\n",
       "      <th>lait_occ_autre_libelle</th>\n",
       "      <th>lait_occ_aucun</th>\n",
       "      <th>lait_occ_nsp</th>\n",
       "      <th>etablissement_scolaire</th>\n",
       "      <th>lieu_repas_midi</th>\n",
       "      <th>lieu_repas_midi_autre_libelle</th>\n",
       "      <th>cantine_freq</th>\n",
       "      <th>cantine_jms_persfoyer</th>\n",
       "      <th>cantine_jms_veutpas</th>\n",
       "      <th>cantine_jms_probsante</th>\n",
       "      <th>cantine_jms_repaspasequilibre</th>\n",
       "      <th>cantine_jms_repaspasqualite</th>\n",
       "      <th>cantine_jms_repaschers</th>\n",
       "      <th>cantine_jms_ecoleproche</th>\n",
       "      <th>cantine_jms_paspropose</th>\n",
       "      <th>cantine_jms_pasaime</th>\n",
       "      <th>cantine_jms_autre_raison</th>\n",
       "      <th>cantine_jms_autre_raison_libelle</th>\n",
       "      <th>cantine_jms_nsp</th>\n",
       "      <th>collation_freq</th>\n",
       "      <th>collation_aliment1</th>\n",
       "      <th>collation_aliment2</th>\n",
       "      <th>collation_aliment3</th>\n",
       "      <th>collation_aliment4</th>\n",
       "      <th>collation_matin_freq</th>\n",
       "      <th>collation_matin_ecole_freq</th>\n",
       "      <th>collation_matin_pasecole_freq</th>\n",
       "      <th>collation_matin_aliment1</th>\n",
       "      <th>collation_matin_aliment2</th>\n",
       "      <th>collation_matin_aliment3</th>\n",
       "      <th>collation_matin_aliment4</th>\n",
       "      <th>distributeur_freq</th>\n",
       "      <th>distributeur_biscuits_sales</th>\n",
       "      <th>distributeur_biscuits_sucres</th>\n",
       "      <th>distributeur_barres_choco</th>\n",
       "      <th>distributeur_confiseries</th>\n",
       "      <th>distributeur_fruits_frais</th>\n",
       "      <th>distributeur_jus_de_fruits</th>\n",
       "      <th>distributeur_boissons_energ</th>\n",
       "      <th>distributeur_sodas</th>\n",
       "      <th>distributeur_eaux</th>\n",
       "      <th>distributeur_autre</th>\n",
       "      <th>distributeur_autre_libelle</th>\n",
       "      <th>distributeur_nsp</th>\n",
       "      <th>restaurationrapide_freq</th>\n",
       "      <th>aime_legumes</th>\n",
       "      <th>aime_viande</th>\n",
       "      <th>aime_fruits</th>\n",
       "      <th>aime_glaces</th>\n",
       "      <th>aime_fromage</th>\n",
       "      <th>aime_poisson</th>\n",
       "      <th>aime_soda</th>\n",
       "      <th>aime_lait</th>\n",
       "      <th>aime_yaourts</th>\n",
       "      <th>aime_jus_de_fruits</th>\n",
       "      <th>table_beurre</th>\n",
       "      <th>table_creme_fraiche</th>\n",
       "      <th>table_huile_olive</th>\n",
       "      <th>table_vinaigrette</th>\n",
       "      <th>table_mayonnaise</th>\n",
       "      <th>table_ketchup</th>\n",
       "      <th>table_sauce_soja</th>\n",
       "      <th>table_sel</th>\n",
       "      <th>etiquette_freq</th>\n",
       "      <th>etiquette_ingredients</th>\n",
       "      <th>etiquette_contenu_nutri</th>\n",
       "      <th>etiquette_portions</th>\n",
       "      <th>etiquette_message_nutri</th>\n",
       "      <th>etiquette_effets_benefiques</th>\n",
       "      <th>source_medecins</th>\n",
       "      <th>source_personnels_pharma</th>\n",
       "      <th>source_publicite</th>\n",
       "      <th>source_emissions_info</th>\n",
       "      <th>source_journaux</th>\n",
       "      <th>source_livres</th>\n",
       "      <th>source_professeurs</th>\n",
       "      <th>source_famille</th>\n",
       "      <th>source_amis</th>\n",
       "      <th>source_internet</th>\n",
       "      <th>source_emballages</th>\n",
       "      <th>source_autre</th>\n",
       "      <th>source_autre_libelle</th>\n",
       "      <th>conso_lardons_crus</th>\n",
       "      <th>conso_saucisses_crues</th>\n",
       "      <th>conso_viande_boeuf_crue</th>\n",
       "      <th>conso_viande_cheval_crue</th>\n",
       "      <th>conso_viande_porc_crue</th>\n",
       "      <th>conso_viande_volaille_crue</th>\n",
       "      <th>conso_poisson_cru</th>\n",
       "      <th>conso_mollusques_crus</th>\n",
       "      <th>conso_oeufs_crus</th>\n",
       "      <th>conso_croute_fleurie</th>\n",
       "      <th>conso_croute_lavee</th>\n",
       "      <th>conso_pate_pressee_non_cuite</th>\n",
       "      <th>conso_pate_pressee_cuite</th>\n",
       "      <th>conso_pate_persillee</th>\n",
       "      <th>pomme_crue_lave</th>\n",
       "      <th>pomme_crue_essuie</th>\n",
       "      <th>pomme_crue_epluche</th>\n",
       "      <th>pomme_crue_rien</th>\n",
       "      <th>pomme_crue_mange_pas</th>\n",
       "      <th>peche_crue_lave</th>\n",
       "      <th>peche_crue_essuie</th>\n",
       "      <th>peche_crue_epluche</th>\n",
       "      <th>peche_crue_rien</th>\n",
       "      <th>peche_crue_mange_pas</th>\n",
       "      <th>raisin_cru_lave</th>\n",
       "      <th>raisin_cru_essuie</th>\n",
       "      <th>raisin_cru_epluche</th>\n",
       "      <th>raisin_cru_rien</th>\n",
       "      <th>raisin_cru_mange_pas</th>\n",
       "      <th>fraise_crue_lave</th>\n",
       "      <th>fraise_crue_essuie</th>\n",
       "      <th>fraise_crue_epluche</th>\n",
       "      <th>fraise_crue_rien</th>\n",
       "      <th>fraise_crue_mange_pas</th>\n",
       "      <th>tomate_crue_lave</th>\n",
       "      <th>tomate_crue_essuie</th>\n",
       "      <th>tomate_crue_epluche</th>\n",
       "      <th>tomate_crue_rien</th>\n",
       "      <th>tomate_crue_mange_pas</th>\n",
       "      <th>champignon_cru_lave</th>\n",
       "      <th>champignon_cru_essuie</th>\n",
       "      <th>champignon_cru_epluche</th>\n",
       "      <th>champignon_cru_rien</th>\n",
       "      <th>champignon_cru_mange_pas</th>\n",
       "      <th>salade_crue_lave</th>\n",
       "      <th>salade_crue_essuie</th>\n",
       "      <th>salade_crue_epluche</th>\n",
       "      <th>salade_crue_rien</th>\n",
       "      <th>salade_crue_mange_pas</th>\n",
       "      <th>concombre_cru_lave</th>\n",
       "      <th>concombre_cru_essuie</th>\n",
       "      <th>concombre_cru_epluche</th>\n",
       "      <th>concombre_cru_rien</th>\n",
       "      <th>concombre_cru_mange_pas</th>\n",
       "      <th>utilisation_bib</th>\n",
       "      <th>bib_plastique</th>\n",
       "      <th>bib_verre</th>\n",
       "      <th>bib_nsp</th>\n",
       "      <th>sterilisation_bib</th>\n",
       "      <th>sterilisation_bib_libelle</th>\n",
       "      <th>tetine_caoutchouc</th>\n",
       "      <th>tetine_silicone</th>\n",
       "      <th>tetine_nsp</th>\n",
       "      <th>sterilisation_tetine</th>\n",
       "      <th>sterilisation_tetine_libelle</th>\n",
       "      <th>bib_lm</th>\n",
       "      <th>bib_li</th>\n",
       "      <th>bib_lc</th>\n",
       "      <th>bib_bl</th>\n",
       "      <th>bib_ppl</th>\n",
       "      <th>bib_eau</th>\n",
       "      <th>bib_jus</th>\n",
       "      <th>bib_autre</th>\n",
       "      <th>bib_autre_libelle</th>\n",
       "      <th>stockage_bib_lm</th>\n",
       "      <th>delai_conso_bib_lm</th>\n",
       "      <th>prepa_bib_li</th>\n",
       "      <th>conserv_eau</th>\n",
       "      <th>conserv_eau_libelle</th>\n",
       "      <th>reste_eau</th>\n",
       "      <th>conso_apres_prepa_bib_li</th>\n",
       "      <th>tps_conserv_bib_li</th>\n",
       "      <th>lieu_conserv_bib_li</th>\n",
       "      <th>lieu_conserv_bib_li_libelle</th>\n",
       "      <th>tps_conso_bib_li</th>\n",
       "      <th>chauffe_lm</th>\n",
       "      <th>chauffe_pi</th>\n",
       "      <th>chauffe_lc</th>\n",
       "      <th>chauffe_bl</th>\n",
       "      <th>bib_micro_ondes</th>\n",
       "      <th>bib_chauffe_bib</th>\n",
       "      <th>bib_bainmarie</th>\n",
       "      <th>diversification_alim_bebe</th>\n",
       "      <th>prepbb</th>\n",
       "      <th>prepbb_chauff</th>\n",
       "      <th>prepbb_chauff_coupplastique</th>\n",
       "      <th>prepbb_chauff_potverre</th>\n",
       "      <th>prepbb_chauff_recipopaque</th>\n",
       "      <th>prepbb_chauff_reciptranslucid</th>\n",
       "      <th>prepbb_chauff_recipceramique</th>\n",
       "      <th>prepbb_chauff_recipverre</th>\n",
       "      <th>prepbb_chauff_autre</th>\n",
       "      <th>prepbb_chauff_autre_libelle</th>\n",
       "      <th>conso_farine_ssgluten</th>\n",
       "      <th>conso_farine_ssgluten_age</th>\n",
       "      <th>conso_farine_ssgluten_age_nsp</th>\n",
       "      <th>conso_farine_acgluten</th>\n",
       "      <th>conso_farine_acgluten_age</th>\n",
       "      <th>conso_farine_acgluten_age_nsp</th>\n",
       "      <th>conso_cereales</th>\n",
       "      <th>conso_cereales_age</th>\n",
       "      <th>conso_cereales_age_nsp</th>\n",
       "      <th>conso_legumes_horspdt</th>\n",
       "      <th>conso_legumes_horspdt_age</th>\n",
       "      <th>conso_legumes_horspdt_age_nsp</th>\n",
       "      <th>conso_pdt</th>\n",
       "      <th>conso_pdt_age</th>\n",
       "      <th>conso_pdt_age_nsp</th>\n",
       "      <th>conso_riz_pates</th>\n",
       "      <th>conso_riz_pates_age</th>\n",
       "      <th>conso_riz_pates_age_nsp</th>\n",
       "      <th>conso_fruits</th>\n",
       "      <th>conso_fruits_age</th>\n",
       "      <th>conso_fruits_age_nsp</th>\n",
       "      <th>conso_yaourts</th>\n",
       "      <th>conso_yaourts_age</th>\n",
       "      <th>conso_yaourts_age_nsp</th>\n",
       "      <th>conso_autres_desserts</th>\n",
       "      <th>conso_autres_desserts_age</th>\n",
       "      <th>conso_autres_desserts_age_nsp</th>\n",
       "      <th>conso_fromage</th>\n",
       "      <th>conso_fromage_age</th>\n",
       "      <th>conso_fromage_age_nsp</th>\n",
       "      <th>conso_viande</th>\n",
       "      <th>conso_viande_age</th>\n",
       "      <th>conso_viande_age_nsp</th>\n",
       "      <th>conso_poisson</th>\n",
       "      <th>conso_poisson_age</th>\n",
       "      <th>conso_poisson_age_nsp</th>\n",
       "      <th>conso_jambon</th>\n",
       "      <th>conso_jambon_age</th>\n",
       "      <th>conso_jambon_age_nsp</th>\n",
       "      <th>conso_oeufs</th>\n",
       "      <th>conso_oeufs_age</th>\n",
       "      <th>conso_oeufs_age_nsp</th>\n",
       "      <th>conso_gateaux</th>\n",
       "      <th>conso_gateaux_age</th>\n",
       "      <th>conso_gateaux_age_nsp</th>\n",
       "      <th>conso_pain</th>\n",
       "      <th>conso_pain_age</th>\n",
       "      <th>conso_pain_age_nsp</th>\n",
       "      <th>conso_jus</th>\n",
       "      <th>conso_jus_age</th>\n",
       "      <th>conso_jus_age_nsp</th>\n",
       "      <th>conso_autres</th>\n",
       "      <th>conso_autres_age</th>\n",
       "      <th>conso_autres_age_nsp</th>\n",
       "      <th>conso_autres_libelle</th>\n",
       "      <th>conso_nsp</th>\n",
       "      <th>conso_plats_faits_maison</th>\n",
       "      <th>jardin</th>\n",
       "      <th>jardin_potager</th>\n",
       "      <th>jardin_arbres_fruitiers</th>\n",
       "      <th>jardin_poulailler</th>\n",
       "      <th>jardin_clapier</th>\n",
       "      <th>jardin_fleurs</th>\n",
       "      <th>jardin_rien</th>\n",
       "      <th>jardin_entretien</th>\n",
       "      <th>autoproduction_aliments</th>\n",
       "      <th>autoproduction_oeufs_freq</th>\n",
       "      <th>autoproduction_volailles_freq</th>\n",
       "      <th>autoproduction_volailles_libelle</th>\n",
       "      <th>autoproduction_lapins_freq</th>\n",
       "      <th>autoproduction_viandes_freq</th>\n",
       "      <th>autoproduction_viandes_libelle</th>\n",
       "      <th>autoproduction_lait_freq</th>\n",
       "      <th>autoproduction_pdt_freq</th>\n",
       "      <th>autoproduction_tomates_freq</th>\n",
       "      <th>autoproduction_tomates_libelle</th>\n",
       "      <th>autoproduction_carottes_freq</th>\n",
       "      <th>autoproduction_carottes_libelle</th>\n",
       "      <th>autoproduction_salades_freq</th>\n",
       "      <th>autoproduction_salades_libelle</th>\n",
       "      <th>autoproduction_abricots_freq</th>\n",
       "      <th>autoproduction_abricots_libelle</th>\n",
       "      <th>autoproduction_pommes_freq</th>\n",
       "      <th>autoproduction_pommes_libelle</th>\n",
       "      <th>autoproduction_fraises_freq</th>\n",
       "      <th>autoproduction_fraises_libelle</th>\n",
       "      <th>autoproduction_raisins_freq</th>\n",
       "      <th>autoproduction_autresfruits_freq</th>\n",
       "      <th>autoproduction_autrfruit_libelle</th>\n",
       "      <th>autoproduction_autreslegum_freq</th>\n",
       "      <th>autoproduction_autrlegum_libelle</th>\n",
       "      <th>cueillette_fruits_freq</th>\n",
       "      <th>cueillette_champignons_freq</th>\n",
       "      <th>peche_poissons_eau_douce_freq</th>\n",
       "      <th>peche_poissons_eau_mer_freq</th>\n",
       "      <th>peche_coquillages_freq</th>\n",
       "      <th>chasse_gibiers_freq</th>\n",
       "      <th>autoconsommation</th>\n",
       "      <th>autoconsommation_type</th>\n",
       "      <th>autoproduction</th>\n",
       "      <th>cueillette</th>\n",
       "      <th>autoconso_oeufs</th>\n",
       "      <th>autoconso_oeufs_type</th>\n",
       "      <th>autoconso_viandes</th>\n",
       "      <th>autoconso_viandes_type</th>\n",
       "      <th>autoconso_volailles_tot</th>\n",
       "      <th>autoconso_volailles_tot_type</th>\n",
       "      <th>autoconso_lait</th>\n",
       "      <th>autoconso_lait_type</th>\n",
       "      <th>autoconso_pdt</th>\n",
       "      <th>autoconso_pdt_type</th>\n",
       "      <th>autoconso_legumes_tot</th>\n",
       "      <th>autoconso_legumes_tot_type</th>\n",
       "      <th>autoconso_fruits_tot</th>\n",
       "      <th>autoconso_fruits_tot_type</th>\n",
       "      <th>autoconso_pdts_mer</th>\n",
       "      <th>autoconso_pdts_mer_type</th>\n",
       "      <th>conso_aliments_bio</th>\n",
       "      <th>conso_lait_bio_freq</th>\n",
       "      <th>conso_oeufs_bio_freq</th>\n",
       "      <th>conso_volailles_bio_freq</th>\n",
       "      <th>conso_viandes_bio_freq</th>\n",
       "      <th>conso_poissons_bio_freq</th>\n",
       "      <th>conso_fruits_bio_freq</th>\n",
       "      <th>conso_fruits_bio_libelle</th>\n",
       "      <th>conso_pdt_bio_freq</th>\n",
       "      <th>conso_legumes_bio_freq</th>\n",
       "      <th>conso_legumes_bio_libelle</th>\n",
       "      <th>conso_legumes_secs_bio_freq</th>\n",
       "      <th>conso_legumes_secs_bio_libelle</th>\n",
       "      <th>conso_pain_bio_freq</th>\n",
       "      <th>conso_cereales_bio_freq</th>\n",
       "      <th>conso_cereales_bio_libelle</th>\n",
       "      <th>conso_autres_alim_bio_freq</th>\n",
       "      <th>conso_autres_alim_bio_libelle</th>\n",
       "      <th>conso_lait_bebe_bio_freq</th>\n",
       "      <th>conso_yaourt_bebe_bio_freq</th>\n",
       "      <th>conso_jus_bebe_bio_freq</th>\n",
       "      <th>conso_puree_bebe_bio_freq</th>\n",
       "      <th>conso_cereales_bebe_bio_freq</th>\n",
       "      <th>conso_biscuits_bebe_bio_freq</th>\n",
       "      <th>conso_plats_bebe_bio_freq</th>\n",
       "      <th>conso_compotes_bebe_bio_freq</th>\n",
       "      <th>conso_cremes_bebe_bio_freq</th>\n",
       "      <th>consommation_bio</th>\n",
       "      <th>consommation_bio_type</th>\n",
       "      <th>conso_oeufs_bio_tjr_svt</th>\n",
       "      <th>conso_lait_bio_tjr_svt</th>\n",
       "      <th>conso_volailles_bio_tjr_svt</th>\n",
       "      <th>conso_viandes_bio_tjr_svt</th>\n",
       "      <th>conso_poissons_bio_tjr_svt</th>\n",
       "      <th>conso_fruits_bio_tjr_svt</th>\n",
       "      <th>conso_pdt_bio_tjr_svt</th>\n",
       "      <th>conso_legumes_bio_tjr_svt</th>\n",
       "      <th>conso_legumes_secs_bio_tjr_svt</th>\n",
       "      <th>conso_cereales_bio_tjr_svt</th>\n",
       "      <th>conso_pain_bio_tjr_svt</th>\n",
       "      <th>conso_autres_alim_bio_tjr_svt</th>\n",
       "      <th>conso_barbecue</th>\n",
       "      <th>conso_barbecue_elec</th>\n",
       "      <th>conso_barbecue_bois</th>\n",
       "      <th>conso_barbecue_gaz</th>\n",
       "      <th>conso_barbecue_printps_ete_freq</th>\n",
       "      <th>conso_barbecue_automn_hiver_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1101001</td>\n",
       "      <td>110100101</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11415.498010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18553.734263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20743.8570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>397.378201</td>\n",
       "      <td>561.623547</td>\n",
       "      <td>Z01091</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168.0</td>\n",
       "      <td>51.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.599998</td>\n",
       "      <td>18.282312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1378.0930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP, BEP, BEPC, brevet élémentaire, brevet de ...</td>\n",
       "      <td>Rural</td>\n",
       "      <td>[1 340-1 850[ €/mois/U</td>\n",
       "      <td>Pop2 Individu</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BISCUIT</td>\n",
       "      <td>YAOURT</td>\n",
       "      <td>CHIPS</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>COURGETTE, TOMATE</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>HARICOT VERT, SALADE</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CERISE</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>FRAISE, FRAMBOISE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BLE</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1101007</td>\n",
       "      <td>110100701</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4644.245013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4656.461407</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6559.1914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1561.796163</td>\n",
       "      <td>1678.940922</td>\n",
       "      <td>Z01091</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166.0</td>\n",
       "      <td>65.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.099998</td>\n",
       "      <td>23.624619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.7802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP, BEP, BEPC, brevet élémentaire, brevet de ...</td>\n",
       "      <td>Rural</td>\n",
       "      <td>&gt;=1 850 €/mois/UC</td>\n",
       "      <td>Pop2 Individu</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CHOCOLAT</td>\n",
       "      <td>BISCUIT</td>\n",
       "      <td>FRUIT</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>CHEVRE, MOUTON, VEAU</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>SALADE</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BANANE, POMME</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>BETTERAVE, CAROTTE, SALADE, TOMATE</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>BARRE DE CEREALES</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101008</td>\n",
       "      <td>110100801</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6016.879562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6307.757457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11348.4580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>437.741831</td>\n",
       "      <td>613.270384</td>\n",
       "      <td>Z01091</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.0</td>\n",
       "      <td>78.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.599998</td>\n",
       "      <td>29.949701</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1630.9735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP, BEP, BEPC, brevet élémentaire, brevet de ...</td>\n",
       "      <td>Rural</td>\n",
       "      <td>[900-1 340[ €/mois/UC</td>\n",
       "      <td>Pop2 Individu</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POULET</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1101012</td>\n",
       "      <td>110101201</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1782.445803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2041.062541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2783.3044</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1612.480487</td>\n",
       "      <td>1681.567869</td>\n",
       "      <td>Z01091</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177.0</td>\n",
       "      <td>81.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.900002</td>\n",
       "      <td>26.141914</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1749.4603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Diplôme de 1er cycle universitaire (Bac +3, li...</td>\n",
       "      <td>Rural</td>\n",
       "      <td>&gt;=1 850 €/mois/UC</td>\n",
       "      <td>Pop2 Individu</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>POMME</td>\n",
       "      <td>FROMAGE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1101014</td>\n",
       "      <td>110101401</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2359.105604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2455.423813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5051.0601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1670.598497</td>\n",
       "      <td>1966.134210</td>\n",
       "      <td>Z01091</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038265</td>\n",
       "      <td>0.166111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>51.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.799999</td>\n",
       "      <td>22.420361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090.1117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CAP, BEP, BEPC, brevet élémentaire, brevet de ...</td>\n",
       "      <td>Rural</td>\n",
       "      <td>&lt;900 €/mois/UC</td>\n",
       "      <td>Pop2 Individu</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>CAFE</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>POULE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>AUBERGINE, COURGETTE, POIVRON, POTIRON, TOMATE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>BETTERAVE, CAROTTE, CELERI RAVE, NAVET, RADIS</td>\n",
       "      <td>7.0</td>\n",
       "      <td>EPINARD, HARICOT VERT, SALADE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>CERISE, PRUNE</td>\n",
       "      <td>8.0</td>\n",
       "      <td></td>\n",
       "      <td>7.0</td>\n",
       "      <td>CASSIS, FRAISE, FRAMBOISE, GROSEILLE, MURE</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>POIRE, POMME</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>6.0</td>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NOMEN      NOIND  ech  enf_allaite  pop1  pop2  pop3  \\\n",
       "0  1101001  110100101    1          NaN     1     1     1   \n",
       "1  1101007  110100701    1          NaN     1     1     1   \n",
       "2  1101008  110100801    1          NaN     1     1     1   \n",
       "3  1101012  110101201    1          NaN     1     1     1   \n",
       "4  1101014  110101401    1          NaN     1     1     1   \n",
       "\n",
       "   pond_indiv_adu_pop1  pond_indiv_enf_pop1  pond_indiv_adu_pop2  \\\n",
       "0         11415.498010                  NaN         18553.734263   \n",
       "1          4644.245013                  NaN          4656.461407   \n",
       "2          6016.879562                  NaN          6307.757457   \n",
       "3          1782.445803                  NaN          2041.062541   \n",
       "4          2359.105604                  NaN          2455.423813   \n",
       "\n",
       "   pond_indiv_enf_pop2  pond_indiv_adu_pop3  pond_indiv_enf_pop3  \\\n",
       "0                  NaN           20743.8570                  NaN   \n",
       "1                  NaN            6559.1914                  NaN   \n",
       "2                  NaN           11348.4580                  NaN   \n",
       "3                  NaN            2783.3044                  NaN   \n",
       "4                  NaN            5051.0601                  NaN   \n",
       "\n",
       "   pond_men_pop1  pond_men_pop2     zae  strate      fpc1      fpc2      fpc3  \\\n",
       "0     397.378201     561.623547  Z01091       6  0.038265  0.166111  0.333333   \n",
       "1    1561.796163    1678.940922  Z01091       6  0.038265  0.166111  0.500000   \n",
       "2     437.741831     613.270384  Z01091       6  0.038265  0.166111  0.500000   \n",
       "3    1612.480487    1681.567869  Z01091       6  0.038265  0.166111  1.000000   \n",
       "4    1670.598497    1966.134210  Z01091       6  0.038265  0.166111  0.500000   \n",
       "\n",
       "   saison_pop1  saison_pop2  saison_pop3  region_adm_12cl  region_inca3  \\\n",
       "0            1          1.0          1.0                9             6   \n",
       "1            1          1.0          1.0                9             6   \n",
       "2            1          1.0          1.0                9             6   \n",
       "3            1          1.0          1.0                9             6   \n",
       "4            1          1.0          3.0                9             6   \n",
       "\n",
       "   agglo_5cl  sex_PS  tage_PS  tage_PS_mois  lien_rep_enf  diplome_interv  \\\n",
       "0          1       1        7           NaN           NaN             7.0   \n",
       "1          1       2        8           NaN           NaN             7.0   \n",
       "2          1       1        8           NaN           NaN             7.0   \n",
       "3          1       1        8           NaN           NaN            10.0   \n",
       "4          1       2        9           NaN           NaN             7.0   \n",
       "\n",
       "   etude_4cl_interv  situ_prof_5cl_interv  atrav_interv  trav_nuit_interv  \\\n",
       "0                 1                     3           2.0               NaN   \n",
       "1                 1                     1           NaN               4.0   \n",
       "2                 1                     1           NaN               4.0   \n",
       "3                 3                     1           NaN               4.0   \n",
       "4                 1                     4           1.0               NaN   \n",
       "\n",
       "   trav_nuit_2cl_interv  PCS_8cl_interv  PCS_4cl_interv  tps_travail_interv  \\\n",
       "0                   NaN               8               4                 NaN   \n",
       "1                   2.0               1               1                 2.0   \n",
       "2                   2.0               2               1                 1.0   \n",
       "3                   2.0               1               1                 1.0   \n",
       "4                   NaN               7               4                 1.0   \n",
       "\n",
       "   vacances_interv  interv_PR  sex_PR  tage_PR  lien_interv_PR  lien_PS_PR  \\\n",
       "0                2          0       1        2             2.0         2.0   \n",
       "1                1          0       1        2             1.0         1.0   \n",
       "2                1          1       1        2             NaN         NaN   \n",
       "3                1          1       1        2             NaN         NaN   \n",
       "4                1          0       1        3             1.0         1.0   \n",
       "\n",
       "   diplome_PR  etude_4cl_PR  atrav_PR  PCS_8cl_PR  PCS_4cl_PR  tps_travail_PR  \\\n",
       "0         7.0             1       NaN           2           1             1.0   \n",
       "1         7.0             1       1.0           7           4             1.0   \n",
       "2         7.0             1       NaN           2           1             1.0   \n",
       "3        10.0             3       NaN           1           1             1.0   \n",
       "4         3.0             1       1.0           7           4             1.0   \n",
       "\n",
       "   stat_log_2cl  soins  situ_fin_3cl  revenu  RUC_4cl  nbpers  nbadu  nbenf  \\\n",
       "0             2      2             2      12      3.0       4      3      1   \n",
       "1             1      2             1      11      4.0       2      2      0   \n",
       "2             1      2             1      11      2.0       4      2      2   \n",
       "3             2      2             1      11      4.0       1      1      0   \n",
       "4             1      2             2       6      1.0       2      2      0   \n",
       "\n",
       "   situ_alim_statut  IA_statut  IA_score  taille_m  taille_d  taille  poids_m  \\\n",
       "0                 1          0       NaN     168.0       NaN   168.0     51.6   \n",
       "1                 1          0       NaN     166.0       NaN   166.0     65.1   \n",
       "2                 1          0       NaN     162.0       NaN   162.0     78.6   \n",
       "3                 1          0       NaN     177.0       NaN   177.0     81.9   \n",
       "4                 1          0       NaN     152.0       NaN   152.0     51.8   \n",
       "\n",
       "   poids_d      poids        imc  statnut  maladie_allergie_alim  \\\n",
       "0      NaN  51.599998  18.282312      0.0                    0.0   \n",
       "1      NaN  65.099998  23.624619      1.0                    0.0   \n",
       "2      NaN  78.599998  29.949701      3.0                    0.0   \n",
       "3      NaN  81.900002  26.141914      3.0                    0.0   \n",
       "4      NaN  51.799999  22.420361      1.0                    0.0   \n",
       "\n",
       "   intoall_confirm_med  regime_vegetarien  regime_allergie  \\\n",
       "0                  NaN                0.0              0.0   \n",
       "1                  NaN                0.0              0.0   \n",
       "2                  NaN                0.0              0.0   \n",
       "3                  NaN                0.0              0.0   \n",
       "4                  NaN                0.0              0.0   \n",
       "\n",
       "   regime_maigrir_med  regime_maigrir_choix  regime_autre_med  \\\n",
       "0                 0.0                   0.0               0.0   \n",
       "1                 0.0                   0.0               0.0   \n",
       "2                 0.0                   0.0               0.0   \n",
       "3                 0.0                   0.0               0.0   \n",
       "4                 0.0                   0.0               0.0   \n",
       "\n",
       "  regime_raisonmed_libelle  regime_poidsstable  regime_forme  \\\n",
       "0                                          0.0           0.0   \n",
       "1                                          0.0           0.0   \n",
       "2                                          0.0           0.0   \n",
       "3                                          0.0           0.0   \n",
       "4                                          0.0           0.0   \n",
       "\n",
       "   regime_autreraison  regime_non  veget_viande  veget_prodmer  \\\n",
       "0                 0.0         1.0           0.0            0.0   \n",
       "1                 0.0         1.0           0.0            0.0   \n",
       "2                 0.0         1.0           0.0            0.0   \n",
       "3                 0.0         1.0           0.0            0.0   \n",
       "4                 0.0         1.0           0.0            0.0   \n",
       "\n",
       "   veget_prodlait  veget_oeuf  veget_miel  veget_autre_alim  \\\n",
       "0             0.0         0.0         0.0               0.0   \n",
       "1             0.0         0.0         0.0               0.0   \n",
       "2             0.0         0.0         0.0               0.0   \n",
       "3             0.0         0.0         0.0               0.0   \n",
       "4             0.0         0.0         0.0               0.0   \n",
       "\n",
       "  veget_autre_alim_libelle  allergie_laitvache  allergie_prepainfsoja  \\\n",
       "0                                          0.0                    0.0   \n",
       "1                                          0.0                    0.0   \n",
       "2                                          0.0                    0.0   \n",
       "3                                          0.0                    0.0   \n",
       "4                                          0.0                    0.0   \n",
       "\n",
       "   allergie_prepainfamande  allergie_gluten  allergie_farineble  \\\n",
       "0                      0.0              0.0                 0.0   \n",
       "1                      0.0              0.0                 0.0   \n",
       "2                      0.0              0.0                 0.0   \n",
       "3                      0.0              0.0                 0.0   \n",
       "4                      0.0              0.0                 0.0   \n",
       "\n",
       "   allergie_lupin  allergie_arachide  allergie_fruitcoque  \\\n",
       "0             0.0                0.0                  0.0   \n",
       "1             0.0                0.0                  0.0   \n",
       "2             0.0                0.0                  0.0   \n",
       "3             0.0                0.0                  0.0   \n",
       "4             0.0                0.0                  0.0   \n",
       "\n",
       "  allergie_fruitcoque_libelle  allergie_oeuf  allergie_poisson  \\\n",
       "0                                        0.0               0.0   \n",
       "1                                        0.0               0.0   \n",
       "2                                        0.0               0.0   \n",
       "3                                        0.0               0.0   \n",
       "4                                        0.0               0.0   \n",
       "\n",
       "   allergie_crustace  allergie_mollusque  allergie_soja  allergie_sesame  \\\n",
       "0                0.0                 0.0            0.0              0.0   \n",
       "1                0.0                 0.0            0.0              0.0   \n",
       "2                0.0                 0.0            0.0              0.0   \n",
       "3                0.0                 0.0            0.0              0.0   \n",
       "4                0.0                 0.0            0.0              0.0   \n",
       "\n",
       "   allergie_moutarde  allergie_sulfite  allergie_celeri  \\\n",
       "0                0.0               0.0              0.0   \n",
       "1                0.0               0.0              0.0   \n",
       "2                0.0               0.0              0.0   \n",
       "3                0.0               0.0              0.0   \n",
       "4                0.0               0.0              0.0   \n",
       "\n",
       "   allergie_autres_fruitleg allergie_autres_fl_libelle  allergie_autresalim  \\\n",
       "0                       0.0                                             0.0   \n",
       "1                       0.0                                             0.0   \n",
       "2                       0.0                                             0.0   \n",
       "3                       0.0                                             0.0   \n",
       "4                       0.0                                             0.0   \n",
       "\n",
       "                         allergie_autresalim_libelle  allergie_nondetermine  \\\n",
       "0                                                ...                    0.0   \n",
       "1                                                ...                    0.0   \n",
       "2                                                ...                    0.0   \n",
       "3                                                ...                    0.0   \n",
       "4                                                ...                    0.0   \n",
       "\n",
       "   allergie_fruits  allergie_legumes  regime_passe  regime_nb_2dernann  \\\n",
       "0              0.0               0.0           2.0                 NaN   \n",
       "1              0.0               0.0           2.0                 NaN   \n",
       "2              0.0               0.0           2.0                 NaN   \n",
       "3              0.0               0.0           2.0                 NaN   \n",
       "4              0.0               0.0           2.0                 NaN   \n",
       "\n",
       "   regime_nb_anter2dernann  regime_type regime_type_libelle  regime_duree_sem  \\\n",
       "0                      NaN          NaN                                   NaN   \n",
       "1                      NaN          NaN                                   NaN   \n",
       "2                      NaN          NaN                                   NaN   \n",
       "3                      NaN          NaN                                   NaN   \n",
       "4                      NaN          NaN                                   NaN   \n",
       "\n",
       "   regime_duree_mois  regime_duree_nsp  poids_anndern  poids_anndern_nsp  \\\n",
       "0                NaN               NaN            NaN                1.0   \n",
       "1                NaN               NaN           68.0                NaN   \n",
       "2                NaN               NaN           72.0                NaN   \n",
       "3                NaN               NaN           80.0                NaN   \n",
       "4                NaN               NaN           48.0                NaN   \n",
       "\n",
       "   poids_modif  poids_modifalim  poids_plusAP  poids_medicaments  \\\n",
       "0          4.0              NaN           NaN                NaN   \n",
       "1          2.0              0.0           1.0                0.0   \n",
       "2          4.0              NaN           NaN                NaN   \n",
       "3          4.0              NaN           NaN                NaN   \n",
       "4          4.0              NaN           NaN                NaN   \n",
       "\n",
       "   poids_substituts  poids_chirurgie  poids_modifalim_laityaourt  \\\n",
       "0               NaN              NaN                         NaN   \n",
       "1               0.0              0.0                         NaN   \n",
       "2               NaN              NaN                         NaN   \n",
       "3               NaN              NaN                         NaN   \n",
       "4               NaN              NaN                         NaN   \n",
       "\n",
       "   poids_modifalim_fromage  poids_modifalim_mg  poids_modifalim_fruit  \\\n",
       "0                      NaN                 NaN                    NaN   \n",
       "1                      NaN                 NaN                    NaN   \n",
       "2                      NaN                 NaN                    NaN   \n",
       "3                      NaN                 NaN                    NaN   \n",
       "4                      NaN                 NaN                    NaN   \n",
       "\n",
       "   poids_modifalim_legume  poids_modifalim_pdtfeculent  poids_modifalim_pizza  \\\n",
       "0                     NaN                          NaN                    NaN   \n",
       "1                     NaN                          NaN                    NaN   \n",
       "2                     NaN                          NaN                    NaN   \n",
       "3                     NaN                          NaN                    NaN   \n",
       "4                     NaN                          NaN                    NaN   \n",
       "\n",
       "   poids_modifalim_pain  poids_modifalim_vrouge  poids_modifalim_volaille  \\\n",
       "0                   NaN                     NaN                       NaN   \n",
       "1                   NaN                     NaN                       NaN   \n",
       "2                   NaN                     NaN                       NaN   \n",
       "3                   NaN                     NaN                       NaN   \n",
       "4                   NaN                     NaN                       NaN   \n",
       "\n",
       "   poids_modifalim_oeuf  poids_modifalim_gateau  poids_modifalim_edulcorant  \\\n",
       "0                   NaN                     NaN                         NaN   \n",
       "1                   NaN                     NaN                         NaN   \n",
       "2                   NaN                     NaN                         NaN   \n",
       "3                   NaN                     NaN                         NaN   \n",
       "4                   NaN                     NaN                         NaN   \n",
       "\n",
       "   poids_modifalim_pdtsalleges  poids_modifalim_BS  poids_modifalim_eau  \\\n",
       "0                          NaN                 NaN                  NaN   \n",
       "1                          NaN                 NaN                  NaN   \n",
       "2                          NaN                 NaN                  NaN   \n",
       "3                          NaN                 NaN                  NaN   \n",
       "4                          NaN                 NaN                  NaN   \n",
       "\n",
       "   poids_modifalim_autre poids_modifalim_autre_libelle  poids_perception  \\\n",
       "0                    NaN                                             1.0   \n",
       "1                    NaN                                             2.0   \n",
       "2                    NaN                                             2.0   \n",
       "3                    NaN                                             2.0   \n",
       "4                    NaN                                             1.0   \n",
       "\n",
       "   poidsmax  poidsmax_nsp  age_poidsmax  age_poidsmax_nsp  poidsmin  \\\n",
       "0       NaN           NaN           NaN               NaN       NaN   \n",
       "1      69.0           NaN          50.0               NaN      62.0   \n",
       "2      77.0           NaN          44.0               NaN      60.0   \n",
       "3      83.0           NaN          48.0               NaN      63.0   \n",
       "4       NaN           1.0           NaN               1.0       NaN   \n",
       "\n",
       "   poidsmin_nsp  age_poidsmin  age_poidsmin_nsp  nb_prise_10kg  menopause  \\\n",
       "0           NaN           NaN               NaN            NaN        NaN   \n",
       "1           NaN          30.0               NaN            4.0        1.0   \n",
       "2           NaN          20.0               NaN            4.0        NaN   \n",
       "3           NaN          20.0               NaN            4.0        NaN   \n",
       "4           1.0           NaN               1.0            5.0        1.0   \n",
       "\n",
       "   enceinte  enceinte_nbmois  allaite  allaite_nbsem  enceinte_12dermois  \\\n",
       "0       NaN              NaN      NaN            NaN                 NaN   \n",
       "1       NaN              NaN      NaN            NaN                 NaN   \n",
       "2       NaN              NaN      NaN            NaN                 NaN   \n",
       "3       NaN              NaN      NaN            NaN                 NaN   \n",
       "4       NaN              NaN      NaN            NaN                 NaN   \n",
       "\n",
       "   fume  nb_cigarettes_jour  nb_cigarettes_sem  nb_cigarettes_nsp  \\\n",
       "0   4.0                 NaN                NaN                NaN   \n",
       "1   4.0                 NaN                NaN                NaN   \n",
       "2   3.0                15.0                NaN                NaN   \n",
       "3   4.0                 NaN                NaN                NaN   \n",
       "4   4.0                 NaN                NaN                NaN   \n",
       "\n",
       "   nb_cigares_jour  nb_cigares_sem  nb_cigares_nsp  nb_pipes_jour  \\\n",
       "0              NaN             NaN             NaN            NaN   \n",
       "1              NaN             NaN             NaN            NaN   \n",
       "2              0.0             NaN             NaN            0.0   \n",
       "3              NaN             NaN             NaN            NaN   \n",
       "4              NaN             NaN             NaN            NaN   \n",
       "\n",
       "   nb_pipes_sem  nb_pipes_nsp  fume_age_debut  fume_age_debut_nsp  \\\n",
       "0           NaN           NaN             NaN                 NaN   \n",
       "1           NaN           NaN             NaN                 NaN   \n",
       "2           NaN           NaN            25.0                 NaN   \n",
       "3           NaN           NaN             NaN                 NaN   \n",
       "4           NaN           NaN             NaN                 NaN   \n",
       "\n",
       "   fume_age_arret  fume_age_arret_nsp   bmr_kcal  sousest0  surest0  sousest1  \\\n",
       "0             NaN                 NaN  1378.0930       0.0      0.0       0.0   \n",
       "1             NaN                 NaN  1352.7802       1.0      0.0       1.0   \n",
       "2            33.0                 NaN  1630.9735       0.0      0.0       0.0   \n",
       "3             NaN                 NaN  1749.4603       0.0      0.0       0.0   \n",
       "4             NaN                 NaN  1090.1117       0.0      0.0       0.0   \n",
       "\n",
       "   sousest3  sousext  surext  \\\n",
       "0       NaN      0.0     0.0   \n",
       "1       NaN      0.0     0.0   \n",
       "2       NaN      0.0     0.0   \n",
       "3       NaN      0.0     0.0   \n",
       "4       NaN      0.0     0.0   \n",
       "\n",
       "                                   categorie_diplome categorie_agglo  \\\n",
       "0  CAP, BEP, BEPC, brevet élémentaire, brevet de ...           Rural   \n",
       "1  CAP, BEP, BEPC, brevet élémentaire, brevet de ...           Rural   \n",
       "2  CAP, BEP, BEPC, brevet élémentaire, brevet de ...           Rural   \n",
       "3  Diplôme de 1er cycle universitaire (Bac +3, li...           Rural   \n",
       "4  CAP, BEP, BEPC, brevet élémentaire, brevet de ...           Rural   \n",
       "\n",
       "            RUC_4cl_label     POPULATION  periode_reference  \\\n",
       "0  [1 340-1 850[ €/mois/U  Pop2 Individu                  4   \n",
       "1       >=1 850 €/mois/UC  Pop2 Individu                  4   \n",
       "2   [900-1 340[ €/mois/UC  Pop2 Individu                  4   \n",
       "3       >=1 850 €/mois/UC  Pop2 Individu                  4   \n",
       "4          <900 €/mois/UC  Pop2 Individu                  4   \n",
       "\n",
       "   repasenfantmidi_vous  repasenfantmidi_am  repasenfantmidi_creche  \\\n",
       "0                   NaN                 NaN                     NaN   \n",
       "1                   NaN                 NaN                     NaN   \n",
       "2                   NaN                 NaN                     NaN   \n",
       "3                   NaN                 NaN                     NaN   \n",
       "4                   NaN                 NaN                     NaN   \n",
       "\n",
       "   repasenfantmidi_parent  repasenfantmidi_autre  \\\n",
       "0                     NaN                    NaN   \n",
       "1                     NaN                    NaN   \n",
       "2                     NaN                    NaN   \n",
       "3                     NaN                    NaN   \n",
       "4                     NaN                    NaN   \n",
       "\n",
       "  repasenfantmidi_autre_libelle  repasenfant_freq  conso_bebe_sein  \\\n",
       "0                                             NaN              NaN   \n",
       "1                                             NaN              NaN   \n",
       "2                                             NaN              NaN   \n",
       "3                                             NaN              NaN   \n",
       "4                                             NaN              NaN   \n",
       "\n",
       "   lait_plussouvent lait_plusvt_li_autr_anim_libelle  \\\n",
       "0               NaN                             None   \n",
       "1               NaN                             None   \n",
       "2               NaN                             None   \n",
       "3               NaN                             None   \n",
       "4               NaN                             None   \n",
       "\n",
       "  lait_plusvt_pi_autre_veg_libelle lait_plusvt_boisson_veg_libelle  \\\n",
       "0                             None                                   \n",
       "1                             None                                   \n",
       "2                             None                                   \n",
       "3                             None                                   \n",
       "4                             None                                   \n",
       "\n",
       "  lait_plusvt_autre_anim_libelle lait_plusvt_autre_libelle  \\\n",
       "0                           None                             \n",
       "1                           None                             \n",
       "2                           None                             \n",
       "3                           None                             \n",
       "4                           None                             \n",
       "\n",
       "   lait_occ_laitmaternel  lait_occ_lait_1e_age  lait_occ_lait_2e_age  \\\n",
       "0                    NaN                   NaN                   NaN   \n",
       "1                    NaN                   NaN                   NaN   \n",
       "2                    NaN                   NaN                   NaN   \n",
       "3                    NaN                   NaN                   NaN   \n",
       "4                    NaN                   NaN                   NaN   \n",
       "\n",
       "   lait_occ_lait_croissance  lait_occ_li_autre_anim  \\\n",
       "0                       NaN                     NaN   \n",
       "1                       NaN                     NaN   \n",
       "2                       NaN                     NaN   \n",
       "3                       NaN                     NaN   \n",
       "4                       NaN                     NaN   \n",
       "\n",
       "  lait_occ_li_autre_anim_libelle  lait_occ_li1e_age_protsoja  \\\n",
       "0                           None                         NaN   \n",
       "1                           None                         NaN   \n",
       "2                           None                         NaN   \n",
       "3                           None                         NaN   \n",
       "4                           None                         NaN   \n",
       "\n",
       "   lait_occ_li2e_age_protsoja  lait_occ_soja_croissance  \\\n",
       "0                         NaN                       NaN   \n",
       "1                         NaN                       NaN   \n",
       "2                         NaN                       NaN   \n",
       "3                         NaN                       NaN   \n",
       "4                         NaN                       NaN   \n",
       "\n",
       "   lait_occ_li1e_age_protriz  lait_occ_li2e_age_protriz  \\\n",
       "0                        NaN                        NaN   \n",
       "1                        NaN                        NaN   \n",
       "2                        NaN                        NaN   \n",
       "3                        NaN                        NaN   \n",
       "4                        NaN                        NaN   \n",
       "\n",
       "   lait_occ_riz_croissance  lait_occ_pi_autre_veg  \\\n",
       "0                      NaN                    NaN   \n",
       "1                      NaN                    NaN   \n",
       "2                      NaN                    NaN   \n",
       "3                      NaN                    NaN   \n",
       "4                      NaN                    NaN   \n",
       "\n",
       "  lait_occ_pi_autre_veg_libelle  lait_occ_boisson_lait_bebe  \\\n",
       "0                          None                         NaN   \n",
       "1                          None                         NaN   \n",
       "2                          None                         NaN   \n",
       "3                          None                         NaN   \n",
       "4                          None                         NaN   \n",
       "\n",
       "   lait_occ_lait_regime_infantile  lait_occ_lait_vache  lait_occ_boisson_soja  \\\n",
       "0                             NaN                  NaN                    NaN   \n",
       "1                             NaN                  NaN                    NaN   \n",
       "2                             NaN                  NaN                    NaN   \n",
       "3                             NaN                  NaN                    NaN   \n",
       "4                             NaN                  NaN                    NaN   \n",
       "\n",
       "   lait_occ_boisson_veg lait_occ_boisson_veg_libelle  lait_occ_autre_anim  \\\n",
       "0                   NaN                                               NaN   \n",
       "1                   NaN                                               NaN   \n",
       "2                   NaN                                               NaN   \n",
       "3                   NaN                                               NaN   \n",
       "4                   NaN                                               NaN   \n",
       "\n",
       "  lait_occ_autre_anim_libelle  lait_occ_autre lait_occ_autre_libelle  \\\n",
       "0                                         NaN                   None   \n",
       "1                                         NaN                   None   \n",
       "2                                         NaN                   None   \n",
       "3                                         NaN                   None   \n",
       "4                                         NaN                   None   \n",
       "\n",
       "   lait_occ_aucun  lait_occ_nsp  etablissement_scolaire  lieu_repas_midi  \\\n",
       "0             NaN           NaN                     NaN              2.0   \n",
       "1             NaN           NaN                     NaN              1.0   \n",
       "2             NaN           NaN                     NaN              3.0   \n",
       "3             NaN           NaN                     NaN              2.0   \n",
       "4             NaN           NaN                     NaN              1.0   \n",
       "\n",
       "  lieu_repas_midi_autre_libelle  cantine_freq  cantine_jms_persfoyer  \\\n",
       "0                                         2.0                    NaN   \n",
       "1                                         6.0                    NaN   \n",
       "2                                         1.0                    NaN   \n",
       "3                                         1.0                    NaN   \n",
       "4                                         8.0                    NaN   \n",
       "\n",
       "   cantine_jms_veutpas  cantine_jms_probsante  cantine_jms_repaspasequilibre  \\\n",
       "0                  NaN                    NaN                            NaN   \n",
       "1                  NaN                    NaN                            NaN   \n",
       "2                  NaN                    NaN                            NaN   \n",
       "3                  NaN                    NaN                            NaN   \n",
       "4                  NaN                    NaN                            NaN   \n",
       "\n",
       "   cantine_jms_repaspasqualite  cantine_jms_repaschers  \\\n",
       "0                          NaN                     NaN   \n",
       "1                          NaN                     NaN   \n",
       "2                          NaN                     NaN   \n",
       "3                          NaN                     NaN   \n",
       "4                          NaN                     NaN   \n",
       "\n",
       "   cantine_jms_ecoleproche  cantine_jms_paspropose  cantine_jms_pasaime  \\\n",
       "0                      NaN                     NaN                  NaN   \n",
       "1                      NaN                     NaN                  NaN   \n",
       "2                      NaN                     NaN                  NaN   \n",
       "3                      NaN                     NaN                  NaN   \n",
       "4                      NaN                     NaN                  NaN   \n",
       "\n",
       "   cantine_jms_autre_raison cantine_jms_autre_raison_libelle  cantine_jms_nsp  \\\n",
       "0                       NaN                                               NaN   \n",
       "1                       NaN                                               NaN   \n",
       "2                       NaN                                               NaN   \n",
       "3                       NaN                                               NaN   \n",
       "4                       NaN                                               NaN   \n",
       "\n",
       "   collation_freq collation_aliment1 collation_aliment2 collation_aliment3  \\\n",
       "0             1.0            BISCUIT             YAOURT              CHIPS   \n",
       "1             5.0           CHOCOLAT            BISCUIT              FRUIT   \n",
       "2             6.0                                                            \n",
       "3             3.0              POMME            FROMAGE                      \n",
       "4             4.0               CAFE                                         \n",
       "\n",
       "  collation_aliment4  collation_matin_freq  collation_matin_ecole_freq  \\\n",
       "0                                      NaN                         NaN   \n",
       "1                                      NaN                         NaN   \n",
       "2                                      NaN                         NaN   \n",
       "3                                      NaN                         NaN   \n",
       "4                                      NaN                         NaN   \n",
       "\n",
       "   collation_matin_pasecole_freq collation_matin_aliment1  \\\n",
       "0                            NaN                            \n",
       "1                            NaN                            \n",
       "2                            NaN                            \n",
       "3                            NaN                            \n",
       "4                            NaN                            \n",
       "\n",
       "  collation_matin_aliment2 collation_matin_aliment3 collation_matin_aliment4  \\\n",
       "0                                                                              \n",
       "1                                                                              \n",
       "2                                                                              \n",
       "3                                                                              \n",
       "4                                                                              \n",
       "\n",
       "   distributeur_freq  distributeur_biscuits_sales  \\\n",
       "0                6.0                          NaN   \n",
       "1                6.0                          NaN   \n",
       "2                3.0                          0.0   \n",
       "3                4.0                          0.0   \n",
       "4                6.0                          NaN   \n",
       "\n",
       "   distributeur_biscuits_sucres  distributeur_barres_choco  \\\n",
       "0                           NaN                        NaN   \n",
       "1                           NaN                        NaN   \n",
       "2                           0.0                        0.0   \n",
       "3                           0.0                        0.0   \n",
       "4                           NaN                        NaN   \n",
       "\n",
       "   distributeur_confiseries  distributeur_fruits_frais  \\\n",
       "0                       NaN                        NaN   \n",
       "1                       NaN                        NaN   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       NaN                        NaN   \n",
       "\n",
       "   distributeur_jus_de_fruits  distributeur_boissons_energ  \\\n",
       "0                         NaN                          NaN   \n",
       "1                         NaN                          NaN   \n",
       "2                         0.0                          0.0   \n",
       "3                         0.0                          0.0   \n",
       "4                         NaN                          NaN   \n",
       "\n",
       "   distributeur_sodas  distributeur_eaux  distributeur_autre  \\\n",
       "0                 NaN                NaN                 NaN   \n",
       "1                 NaN                NaN                 NaN   \n",
       "2                 1.0                1.0                 0.0   \n",
       "3                 0.0                1.0                 0.0   \n",
       "4                 NaN                NaN                 NaN   \n",
       "\n",
       "  distributeur_autre_libelle  distributeur_nsp  restaurationrapide_freq  \\\n",
       "0                                          NaN                      5.0   \n",
       "1                                          NaN                      6.0   \n",
       "2                                          NaN                      6.0   \n",
       "3                                          NaN                      6.0   \n",
       "4                                          NaN                      7.0   \n",
       "\n",
       "   aime_legumes  aime_viande  aime_fruits  aime_glaces  aime_fromage  \\\n",
       "0           NaN          NaN          NaN          NaN           NaN   \n",
       "1           NaN          NaN          NaN          NaN           NaN   \n",
       "2           NaN          NaN          NaN          NaN           NaN   \n",
       "3           NaN          NaN          NaN          NaN           NaN   \n",
       "4           NaN          NaN          NaN          NaN           NaN   \n",
       "\n",
       "   aime_poisson  aime_soda  aime_lait  aime_yaourts  aime_jus_de_fruits  \\\n",
       "0           NaN        NaN        NaN           NaN                 NaN   \n",
       "1           NaN        NaN        NaN           NaN                 NaN   \n",
       "2           NaN        NaN        NaN           NaN                 NaN   \n",
       "3           NaN        NaN        NaN           NaN                 NaN   \n",
       "4           NaN        NaN        NaN           NaN                 NaN   \n",
       "\n",
       "   table_beurre  table_creme_fraiche  table_huile_olive  table_vinaigrette  \\\n",
       "0           0.0                  0.0                0.0                1.0   \n",
       "1           0.0                  0.0                1.0                1.0   \n",
       "2           0.0                  0.0                0.0                0.0   \n",
       "3           0.0                  0.0                0.0                1.0   \n",
       "4           0.0                  0.0                0.0                0.0   \n",
       "\n",
       "   table_mayonnaise  table_ketchup  table_sauce_soja  table_sel  \\\n",
       "0               0.0            0.0               0.0        1.0   \n",
       "1               0.0            0.0               0.0        1.0   \n",
       "2               0.0            0.0               0.0        0.0   \n",
       "3               0.0            0.0               0.0        0.0   \n",
       "4               0.0            0.0               0.0        0.0   \n",
       "\n",
       "   etiquette_freq  etiquette_ingredients  etiquette_contenu_nutri  \\\n",
       "0             3.0                    4.0                      4.0   \n",
       "1             2.0                    2.0                      2.0   \n",
       "2             4.0                    NaN                      NaN   \n",
       "3             2.0                    3.0                      3.0   \n",
       "4             2.0                    2.0                      2.0   \n",
       "\n",
       "   etiquette_portions  etiquette_message_nutri  etiquette_effets_benefiques  \\\n",
       "0                 4.0                      4.0                          4.0   \n",
       "1                 3.0                      2.0                          2.0   \n",
       "2                 NaN                      NaN                          NaN   \n",
       "3                 2.0                      3.0                          2.0   \n",
       "4                 4.0                      4.0                          2.0   \n",
       "\n",
       "   source_medecins  source_personnels_pharma  source_publicite  \\\n",
       "0              2.0                       2.0               1.0   \n",
       "1              2.0                       1.0               1.0   \n",
       "2              1.0                       2.0               2.0   \n",
       "3              1.0                       2.0               1.0   \n",
       "4              1.0                       1.0               2.0   \n",
       "\n",
       "   source_emissions_info  source_journaux  source_livres  source_professeurs  \\\n",
       "0                    1.0              2.0            2.0                 2.0   \n",
       "1                    1.0              1.0            1.0                 2.0   \n",
       "2                    2.0              2.0            2.0                 2.0   \n",
       "3                    1.0              1.0            2.0                 2.0   \n",
       "4                    1.0              1.0            2.0                 2.0   \n",
       "\n",
       "   source_famille  source_amis  source_internet  source_emballages  \\\n",
       "0             1.0          1.0              1.0                NaN   \n",
       "1             1.0          1.0              1.0                NaN   \n",
       "2             1.0          2.0              2.0                NaN   \n",
       "3             1.0          1.0              1.0                NaN   \n",
       "4             2.0          2.0              2.0                NaN   \n",
       "\n",
       "   source_autre source_autre_libelle  conso_lardons_crus  \\\n",
       "0           2.0                                      3.0   \n",
       "1           2.0                                      4.0   \n",
       "2           2.0                                      4.0   \n",
       "3           3.0                                      4.0   \n",
       "4           2.0                                      4.0   \n",
       "\n",
       "   conso_saucisses_crues  conso_viande_boeuf_crue  conso_viande_cheval_crue  \\\n",
       "0                    4.0                      4.0                       5.0   \n",
       "1                    4.0                      4.0                       4.0   \n",
       "2                    4.0                      4.0                       4.0   \n",
       "3                    4.0                      3.0                       4.0   \n",
       "4                    5.0                      4.0                       5.0   \n",
       "\n",
       "   conso_viande_porc_crue  conso_viande_volaille_crue  conso_poisson_cru  \\\n",
       "0                     4.0                         4.0                4.0   \n",
       "1                     4.0                         4.0                4.0   \n",
       "2                     4.0                         4.0                4.0   \n",
       "3                     4.0                         4.0                3.0   \n",
       "4                     4.0                         4.0                4.0   \n",
       "\n",
       "   conso_mollusques_crus  conso_oeufs_crus  conso_croute_fleurie  \\\n",
       "0                    3.0               4.0                   1.0   \n",
       "1                    6.0               2.0                   1.0   \n",
       "2                    4.0               4.0                   1.0   \n",
       "3                    3.0               2.0                   1.0   \n",
       "4                    3.0               3.0                   1.0   \n",
       "\n",
       "   conso_croute_lavee  conso_pate_pressee_non_cuite  conso_pate_pressee_cuite  \\\n",
       "0                 3.0                           2.0                       2.0   \n",
       "1                 3.0                           2.0                       2.0   \n",
       "2                 2.0                           2.0                       2.0   \n",
       "3                 1.0                           2.0                       2.0   \n",
       "4                 3.0                           2.0                       2.0   \n",
       "\n",
       "   conso_pate_persillee  pomme_crue_lave  pomme_crue_essuie  \\\n",
       "0                   1.0              1.0                1.0   \n",
       "1                   1.0              0.0                1.0   \n",
       "2                   2.0              0.0                0.0   \n",
       "3                   1.0              1.0                0.0   \n",
       "4                   1.0              0.0                0.0   \n",
       "\n",
       "   pomme_crue_epluche  pomme_crue_rien  pomme_crue_mange_pas  peche_crue_lave  \\\n",
       "0                 0.0              0.0                   0.0              1.0   \n",
       "1                 0.0              0.0                   0.0              0.0   \n",
       "2                 1.0              0.0                   0.0              1.0   \n",
       "3                 1.0              0.0                   0.0              1.0   \n",
       "4                 1.0              0.0                   0.0              1.0   \n",
       "\n",
       "   peche_crue_essuie  peche_crue_epluche  peche_crue_rien  \\\n",
       "0                1.0                 0.0              0.0   \n",
       "1                1.0                 0.0              0.0   \n",
       "2                0.0                 0.0              0.0   \n",
       "3                0.0                 0.0              0.0   \n",
       "4                1.0                 0.0              0.0   \n",
       "\n",
       "   peche_crue_mange_pas  raisin_cru_lave  raisin_cru_essuie  \\\n",
       "0                   0.0              1.0                1.0   \n",
       "1                   0.0              1.0                0.0   \n",
       "2                   0.0              1.0                0.0   \n",
       "3                   0.0              1.0                0.0   \n",
       "4                   0.0              1.0                0.0   \n",
       "\n",
       "   raisin_cru_epluche  raisin_cru_rien  raisin_cru_mange_pas  \\\n",
       "0                 0.0              0.0                   0.0   \n",
       "1                 0.0              0.0                   0.0   \n",
       "2                 0.0              0.0                   0.0   \n",
       "3                 0.0              0.0                   0.0   \n",
       "4                 0.0              0.0                   0.0   \n",
       "\n",
       "   fraise_crue_lave  fraise_crue_essuie  fraise_crue_epluche  \\\n",
       "0               0.0                 0.0                  0.0   \n",
       "1               1.0                 0.0                  0.0   \n",
       "2               1.0                 0.0                  0.0   \n",
       "3               1.0                 0.0                  0.0   \n",
       "4               1.0                 0.0                  0.0   \n",
       "\n",
       "   fraise_crue_rien  fraise_crue_mange_pas  tomate_crue_lave  \\\n",
       "0               1.0                    0.0               1.0   \n",
       "1               0.0                    0.0               1.0   \n",
       "2               0.0                    0.0               0.0   \n",
       "3               0.0                    0.0               1.0   \n",
       "4               0.0                    0.0               1.0   \n",
       "\n",
       "   tomate_crue_essuie  tomate_crue_epluche  tomate_crue_rien  \\\n",
       "0                 1.0                  0.0               0.0   \n",
       "1                 0.0                  0.0               0.0   \n",
       "2                 0.0                  0.0               0.0   \n",
       "3                 0.0                  0.0               0.0   \n",
       "4                 0.0                  0.0               0.0   \n",
       "\n",
       "   tomate_crue_mange_pas  champignon_cru_lave  champignon_cru_essuie  \\\n",
       "0                    0.0                  0.0                    0.0   \n",
       "1                    0.0                  0.0                    0.0   \n",
       "2                    1.0                  1.0                    0.0   \n",
       "3                    0.0                  0.0                    1.0   \n",
       "4                    0.0                  1.0                    0.0   \n",
       "\n",
       "   champignon_cru_epluche  champignon_cru_rien  champignon_cru_mange_pas  \\\n",
       "0                     0.0                  0.0                       1.0   \n",
       "1                     1.0                  0.0                       0.0   \n",
       "2                     0.0                  0.0                       0.0   \n",
       "3                     0.0                  0.0                       0.0   \n",
       "4                     1.0                  0.0                       0.0   \n",
       "\n",
       "   salade_crue_lave  salade_crue_essuie  salade_crue_epluche  \\\n",
       "0               1.0                 0.0                  0.0   \n",
       "1               1.0                 0.0                  0.0   \n",
       "2               1.0                 0.0                  0.0   \n",
       "3               1.0                 0.0                  0.0   \n",
       "4               1.0                 0.0                  0.0   \n",
       "\n",
       "   salade_crue_rien  salade_crue_mange_pas  concombre_cru_lave  \\\n",
       "0               0.0                    0.0                 1.0   \n",
       "1               0.0                    0.0                 0.0   \n",
       "2               0.0                    0.0                 1.0   \n",
       "3               0.0                    0.0                 0.0   \n",
       "4               0.0                    0.0                 1.0   \n",
       "\n",
       "   concombre_cru_essuie  concombre_cru_epluche  concombre_cru_rien  \\\n",
       "0                   0.0                    1.0                 0.0   \n",
       "1                   0.0                    1.0                 0.0   \n",
       "2                   0.0                    0.0                 0.0   \n",
       "3                   0.0                    1.0                 0.0   \n",
       "4                   0.0                    1.0                 0.0   \n",
       "\n",
       "   concombre_cru_mange_pas  utilisation_bib  bib_plastique  bib_verre  \\\n",
       "0                      0.0              NaN            NaN        NaN   \n",
       "1                      0.0              NaN            NaN        NaN   \n",
       "2                      0.0              NaN            NaN        NaN   \n",
       "3                      0.0              NaN            NaN        NaN   \n",
       "4                      0.0              NaN            NaN        NaN   \n",
       "\n",
       "   bib_nsp  sterilisation_bib sterilisation_bib_libelle  tetine_caoutchouc  \\\n",
       "0      NaN                NaN                                          NaN   \n",
       "1      NaN                NaN                                          NaN   \n",
       "2      NaN                NaN                                          NaN   \n",
       "3      NaN                NaN                                          NaN   \n",
       "4      NaN                NaN                                          NaN   \n",
       "\n",
       "   tetine_silicone  tetine_nsp  sterilisation_tetine  \\\n",
       "0              NaN         NaN                   NaN   \n",
       "1              NaN         NaN                   NaN   \n",
       "2              NaN         NaN                   NaN   \n",
       "3              NaN         NaN                   NaN   \n",
       "4              NaN         NaN                   NaN   \n",
       "\n",
       "  sterilisation_tetine_libelle  bib_lm  bib_li  bib_lc  bib_bl  bib_ppl  \\\n",
       "0                                  NaN     NaN     NaN     NaN      NaN   \n",
       "1                                  NaN     NaN     NaN     NaN      NaN   \n",
       "2                                  NaN     NaN     NaN     NaN      NaN   \n",
       "3                                  NaN     NaN     NaN     NaN      NaN   \n",
       "4                                  NaN     NaN     NaN     NaN      NaN   \n",
       "\n",
       "   bib_eau  bib_jus  bib_autre bib_autre_libelle  stockage_bib_lm  \\\n",
       "0      NaN      NaN        NaN                                NaN   \n",
       "1      NaN      NaN        NaN                                NaN   \n",
       "2      NaN      NaN        NaN                                NaN   \n",
       "3      NaN      NaN        NaN                                NaN   \n",
       "4      NaN      NaN        NaN                                NaN   \n",
       "\n",
       "   delai_conso_bib_lm  prepa_bib_li  conserv_eau conserv_eau_libelle  \\\n",
       "0                 NaN           NaN          NaN                       \n",
       "1                 NaN           NaN          NaN                       \n",
       "2                 NaN           NaN          NaN                       \n",
       "3                 NaN           NaN          NaN                       \n",
       "4                 NaN           NaN          NaN                       \n",
       "\n",
       "   reste_eau  conso_apres_prepa_bib_li  tps_conserv_bib_li  \\\n",
       "0        NaN                       NaN                 NaN   \n",
       "1        NaN                       NaN                 NaN   \n",
       "2        NaN                       NaN                 NaN   \n",
       "3        NaN                       NaN                 NaN   \n",
       "4        NaN                       NaN                 NaN   \n",
       "\n",
       "   lieu_conserv_bib_li lieu_conserv_bib_li_libelle  tps_conso_bib_li  \\\n",
       "0                  NaN                                           NaN   \n",
       "1                  NaN                                           NaN   \n",
       "2                  NaN                                           NaN   \n",
       "3                  NaN                                           NaN   \n",
       "4                  NaN                                           NaN   \n",
       "\n",
       "   chauffe_lm  chauffe_pi  chauffe_lc  chauffe_bl  bib_micro_ondes  \\\n",
       "0         NaN         NaN         NaN         NaN              NaN   \n",
       "1         NaN         NaN         NaN         NaN              NaN   \n",
       "2         NaN         NaN         NaN         NaN              NaN   \n",
       "3         NaN         NaN         NaN         NaN              NaN   \n",
       "4         NaN         NaN         NaN         NaN              NaN   \n",
       "\n",
       "   bib_chauffe_bib  bib_bainmarie  diversification_alim_bebe  prepbb  \\\n",
       "0              NaN            NaN                        NaN     NaN   \n",
       "1              NaN            NaN                        NaN     NaN   \n",
       "2              NaN            NaN                        NaN     NaN   \n",
       "3              NaN            NaN                        NaN     NaN   \n",
       "4              NaN            NaN                        NaN     NaN   \n",
       "\n",
       "   prepbb_chauff  prepbb_chauff_coupplastique  prepbb_chauff_potverre  \\\n",
       "0            NaN                          NaN                     NaN   \n",
       "1            NaN                          NaN                     NaN   \n",
       "2            NaN                          NaN                     NaN   \n",
       "3            NaN                          NaN                     NaN   \n",
       "4            NaN                          NaN                     NaN   \n",
       "\n",
       "   prepbb_chauff_recipopaque  prepbb_chauff_reciptranslucid  \\\n",
       "0                        NaN                            NaN   \n",
       "1                        NaN                            NaN   \n",
       "2                        NaN                            NaN   \n",
       "3                        NaN                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   prepbb_chauff_recipceramique  prepbb_chauff_recipverre  \\\n",
       "0                           NaN                       NaN   \n",
       "1                           NaN                       NaN   \n",
       "2                           NaN                       NaN   \n",
       "3                           NaN                       NaN   \n",
       "4                           NaN                       NaN   \n",
       "\n",
       "   prepbb_chauff_autre prepbb_chauff_autre_libelle  conso_farine_ssgluten  \\\n",
       "0                  NaN                        None                    NaN   \n",
       "1                  NaN                        None                    NaN   \n",
       "2                  NaN                        None                    NaN   \n",
       "3                  NaN                        None                    NaN   \n",
       "4                  NaN                        None                    NaN   \n",
       "\n",
       "   conso_farine_ssgluten_age  conso_farine_ssgluten_age_nsp  \\\n",
       "0                        NaN                            NaN   \n",
       "1                        NaN                            NaN   \n",
       "2                        NaN                            NaN   \n",
       "3                        NaN                            NaN   \n",
       "4                        NaN                            NaN   \n",
       "\n",
       "   conso_farine_acgluten  conso_farine_acgluten_age  \\\n",
       "0                    NaN                        NaN   \n",
       "1                    NaN                        NaN   \n",
       "2                    NaN                        NaN   \n",
       "3                    NaN                        NaN   \n",
       "4                    NaN                        NaN   \n",
       "\n",
       "   conso_farine_acgluten_age_nsp  conso_cereales  conso_cereales_age  \\\n",
       "0                            NaN             NaN                 NaN   \n",
       "1                            NaN             NaN                 NaN   \n",
       "2                            NaN             NaN                 NaN   \n",
       "3                            NaN             NaN                 NaN   \n",
       "4                            NaN             NaN                 NaN   \n",
       "\n",
       "   conso_cereales_age_nsp  conso_legumes_horspdt  conso_legumes_horspdt_age  \\\n",
       "0                     NaN                    NaN                        NaN   \n",
       "1                     NaN                    NaN                        NaN   \n",
       "2                     NaN                    NaN                        NaN   \n",
       "3                     NaN                    NaN                        NaN   \n",
       "4                     NaN                    NaN                        NaN   \n",
       "\n",
       "   conso_legumes_horspdt_age_nsp  conso_pdt  conso_pdt_age  conso_pdt_age_nsp  \\\n",
       "0                            NaN        NaN            NaN                NaN   \n",
       "1                            NaN        NaN            NaN                NaN   \n",
       "2                            NaN        NaN            NaN                NaN   \n",
       "3                            NaN        NaN            NaN                NaN   \n",
       "4                            NaN        NaN            NaN                NaN   \n",
       "\n",
       "   conso_riz_pates  conso_riz_pates_age  conso_riz_pates_age_nsp  \\\n",
       "0              NaN                  NaN                      NaN   \n",
       "1              NaN                  NaN                      NaN   \n",
       "2              NaN                  NaN                      NaN   \n",
       "3              NaN                  NaN                      NaN   \n",
       "4              NaN                  NaN                      NaN   \n",
       "\n",
       "   conso_fruits  conso_fruits_age  conso_fruits_age_nsp  conso_yaourts  \\\n",
       "0           NaN               NaN                   NaN            NaN   \n",
       "1           NaN               NaN                   NaN            NaN   \n",
       "2           NaN               NaN                   NaN            NaN   \n",
       "3           NaN               NaN                   NaN            NaN   \n",
       "4           NaN               NaN                   NaN            NaN   \n",
       "\n",
       "   conso_yaourts_age  conso_yaourts_age_nsp  conso_autres_desserts  \\\n",
       "0                NaN                    NaN                    NaN   \n",
       "1                NaN                    NaN                    NaN   \n",
       "2                NaN                    NaN                    NaN   \n",
       "3                NaN                    NaN                    NaN   \n",
       "4                NaN                    NaN                    NaN   \n",
       "\n",
       "   conso_autres_desserts_age  conso_autres_desserts_age_nsp  conso_fromage  \\\n",
       "0                        NaN                            NaN            NaN   \n",
       "1                        NaN                            NaN            NaN   \n",
       "2                        NaN                            NaN            NaN   \n",
       "3                        NaN                            NaN            NaN   \n",
       "4                        NaN                            NaN            NaN   \n",
       "\n",
       "   conso_fromage_age  conso_fromage_age_nsp  conso_viande  conso_viande_age  \\\n",
       "0                NaN                    NaN           NaN               NaN   \n",
       "1                NaN                    NaN           NaN               NaN   \n",
       "2                NaN                    NaN           NaN               NaN   \n",
       "3                NaN                    NaN           NaN               NaN   \n",
       "4                NaN                    NaN           NaN               NaN   \n",
       "\n",
       "   conso_viande_age_nsp  conso_poisson  conso_poisson_age  \\\n",
       "0                   NaN            NaN                NaN   \n",
       "1                   NaN            NaN                NaN   \n",
       "2                   NaN            NaN                NaN   \n",
       "3                   NaN            NaN                NaN   \n",
       "4                   NaN            NaN                NaN   \n",
       "\n",
       "   conso_poisson_age_nsp  conso_jambon  conso_jambon_age  \\\n",
       "0                    NaN           NaN               NaN   \n",
       "1                    NaN           NaN               NaN   \n",
       "2                    NaN           NaN               NaN   \n",
       "3                    NaN           NaN               NaN   \n",
       "4                    NaN           NaN               NaN   \n",
       "\n",
       "   conso_jambon_age_nsp  conso_oeufs  conso_oeufs_age  conso_oeufs_age_nsp  \\\n",
       "0                   NaN          NaN              NaN                  NaN   \n",
       "1                   NaN          NaN              NaN                  NaN   \n",
       "2                   NaN          NaN              NaN                  NaN   \n",
       "3                   NaN          NaN              NaN                  NaN   \n",
       "4                   NaN          NaN              NaN                  NaN   \n",
       "\n",
       "   conso_gateaux  conso_gateaux_age  conso_gateaux_age_nsp  conso_pain  \\\n",
       "0            NaN                NaN                    NaN         NaN   \n",
       "1            NaN                NaN                    NaN         NaN   \n",
       "2            NaN                NaN                    NaN         NaN   \n",
       "3            NaN                NaN                    NaN         NaN   \n",
       "4            NaN                NaN                    NaN         NaN   \n",
       "\n",
       "   conso_pain_age  conso_pain_age_nsp  conso_jus  conso_jus_age  \\\n",
       "0             NaN                 NaN        NaN            NaN   \n",
       "1             NaN                 NaN        NaN            NaN   \n",
       "2             NaN                 NaN        NaN            NaN   \n",
       "3             NaN                 NaN        NaN            NaN   \n",
       "4             NaN                 NaN        NaN            NaN   \n",
       "\n",
       "   conso_jus_age_nsp  conso_autres  conso_autres_age  conso_autres_age_nsp  \\\n",
       "0                NaN           NaN               NaN                   NaN   \n",
       "1                NaN           NaN               NaN                   NaN   \n",
       "2                NaN           NaN               NaN                   NaN   \n",
       "3                NaN           NaN               NaN                   NaN   \n",
       "4                NaN           NaN               NaN                   NaN   \n",
       "\n",
       "  conso_autres_libelle conso_nsp  conso_plats_faits_maison  jardin  \\\n",
       "0                           None                       NaN     1.0   \n",
       "1                           None                       NaN     1.0   \n",
       "2                           None                       NaN     0.0   \n",
       "3                           None                       NaN     0.0   \n",
       "4                           None                       NaN     1.0   \n",
       "\n",
       "   jardin_potager  jardin_arbres_fruitiers  jardin_poulailler  jardin_clapier  \\\n",
       "0             1.0                      1.0                0.0             0.0   \n",
       "1             1.0                      1.0                0.0             0.0   \n",
       "2             NaN                      NaN                NaN             NaN   \n",
       "3             NaN                      NaN                NaN             NaN   \n",
       "4             1.0                      1.0                1.0             0.0   \n",
       "\n",
       "   jardin_fleurs  jardin_rien  jardin_entretien  autoproduction_aliments  \\\n",
       "0            1.0          0.0               1.0                      1.0   \n",
       "1            1.0          0.0               2.0                      1.0   \n",
       "2            NaN          NaN               NaN                      1.0   \n",
       "3            NaN          NaN               NaN                      2.0   \n",
       "4            1.0          0.0               2.0                      1.0   \n",
       "\n",
       "   autoproduction_oeufs_freq  autoproduction_volailles_freq  \\\n",
       "0                        1.0                            1.0   \n",
       "1                        4.0                            1.0   \n",
       "2                        3.0                            2.0   \n",
       "3                        NaN                            NaN   \n",
       "4                        5.0                            2.0   \n",
       "\n",
       "  autoproduction_volailles_libelle  autoproduction_lapins_freq  \\\n",
       "0                                                          1.0   \n",
       "1                                                          2.0   \n",
       "2                           POULET                         8.0   \n",
       "3                                                          NaN   \n",
       "4                            POULE                         1.0   \n",
       "\n",
       "   autoproduction_viandes_freq autoproduction_viandes_libelle  \\\n",
       "0                          1.0                                  \n",
       "1                          3.0           CHEVRE, MOUTON, VEAU   \n",
       "2                          1.0                                  \n",
       "3                          NaN                                  \n",
       "4                          1.0                                  \n",
       "\n",
       "   autoproduction_lait_freq  autoproduction_pdt_freq  \\\n",
       "0                       1.0                      1.0   \n",
       "1                       1.0                      5.0   \n",
       "2                       1.0                      2.0   \n",
       "3                       NaN                      NaN   \n",
       "4                       1.0                      5.0   \n",
       "\n",
       "   autoproduction_tomates_freq  \\\n",
       "0                          4.0   \n",
       "1                          1.0   \n",
       "2                          1.0   \n",
       "3                          NaN   \n",
       "4                          5.0   \n",
       "\n",
       "                   autoproduction_tomates_libelle  \\\n",
       "0                               COURGETTE, TOMATE   \n",
       "1                                                   \n",
       "2                                                   \n",
       "3                                                   \n",
       "4  AUBERGINE, COURGETTE, POIVRON, POTIRON, TOMATE   \n",
       "\n",
       "   autoproduction_carottes_freq  \\\n",
       "0                           1.0   \n",
       "1                           1.0   \n",
       "2                           1.0   \n",
       "3                           NaN   \n",
       "4                           5.0   \n",
       "\n",
       "                 autoproduction_carottes_libelle  autoproduction_salades_freq  \\\n",
       "0                                                                         4.0   \n",
       "1                                                                         6.0   \n",
       "2                                                                         1.0   \n",
       "3                                                                         NaN   \n",
       "4  BETTERAVE, CAROTTE, CELERI RAVE, NAVET, RADIS                          7.0   \n",
       "\n",
       "  autoproduction_salades_libelle  autoproduction_abricots_freq  \\\n",
       "0           HARICOT VERT, SALADE                           4.0   \n",
       "1                         SALADE                           1.0   \n",
       "2                                                          1.0   \n",
       "3                                                          NaN   \n",
       "4  EPINARD, HARICOT VERT, SALADE                           5.0   \n",
       "\n",
       "  autoproduction_abricots_libelle  autoproduction_pommes_freq  \\\n",
       "0                          CERISE                         1.0   \n",
       "1                                                         1.0   \n",
       "2                                                         1.0   \n",
       "3                                                         NaN   \n",
       "4                   CERISE, PRUNE                         8.0   \n",
       "\n",
       "  autoproduction_pommes_libelle  autoproduction_fraises_freq  \\\n",
       "0                                                        4.0   \n",
       "1                                                        1.0   \n",
       "2                                                        1.0   \n",
       "3                                                        NaN   \n",
       "4                                                        7.0   \n",
       "\n",
       "               autoproduction_fraises_libelle  autoproduction_raisins_freq  \\\n",
       "0                           FRAISE, FRAMBOISE                          1.0   \n",
       "1                                                                      5.0   \n",
       "2                                                                      1.0   \n",
       "3                                                                      NaN   \n",
       "4  CASSIS, FRAISE, FRAMBOISE, GROSEILLE, MURE                          5.0   \n",
       "\n",
       "   autoproduction_autresfruits_freq autoproduction_autrfruit_libelle  \\\n",
       "0                               NaN                                    \n",
       "1                               NaN                                    \n",
       "2                               NaN                                    \n",
       "3                               NaN                                    \n",
       "4                               NaN                                    \n",
       "\n",
       "   autoproduction_autreslegum_freq autoproduction_autrlegum_libelle  \\\n",
       "0                              NaN                                    \n",
       "1                              NaN                                    \n",
       "2                              NaN                                    \n",
       "3                              NaN                                    \n",
       "4                              NaN                                    \n",
       "\n",
       "   cueillette_fruits_freq  cueillette_champignons_freq  \\\n",
       "0                     3.0                          3.0   \n",
       "1                     4.0                          3.0   \n",
       "2                     4.0                          2.0   \n",
       "3                     4.0                          4.0   \n",
       "4                     1.0                          4.0   \n",
       "\n",
       "   peche_poissons_eau_douce_freq  peche_poissons_eau_mer_freq  \\\n",
       "0                            1.0                          1.0   \n",
       "1                            2.0                          1.0   \n",
       "2                            1.0                          1.0   \n",
       "3                            1.0                          1.0   \n",
       "4                            1.0                          1.0   \n",
       "\n",
       "   peche_coquillages_freq  chasse_gibiers_freq  autoconsommation  \\\n",
       "0                     1.0                  1.0               1.0   \n",
       "1                     1.0                  2.0               1.0   \n",
       "2                     1.0                  2.0               1.0   \n",
       "3                     1.0                  1.0               1.0   \n",
       "4                     1.0                  2.0               1.0   \n",
       "\n",
       "   autoconsommation_type  autoproduction  cueillette  autoconso_oeufs  \\\n",
       "0                    2.0             1.0         1.0              0.0   \n",
       "1                    2.0             1.0         1.0              1.0   \n",
       "2                    2.0             1.0         1.0              1.0   \n",
       "3                    2.0             0.0         1.0              0.0   \n",
       "4                    2.0             1.0         1.0              1.0   \n",
       "\n",
       "   autoconso_oeufs_type  autoconso_viandes  autoconso_viandes_type  \\\n",
       "0                   0.0                0.0                     0.0   \n",
       "1                   2.0                1.0                     1.0   \n",
       "2                   1.0                0.0                     0.0   \n",
       "3                   0.0                0.0                     0.0   \n",
       "4                   2.0                0.0                     0.0   \n",
       "\n",
       "   autoconso_volailles_tot  autoconso_volailles_tot_type  autoconso_lait  \\\n",
       "0                      0.0                           0.0             0.0   \n",
       "1                      1.0                           1.0             0.0   \n",
       "2                      1.0                           1.0             0.0   \n",
       "3                      0.0                           0.0             0.0   \n",
       "4                      1.0                           1.0             0.0   \n",
       "\n",
       "   autoconso_lait_type  autoconso_pdt  autoconso_pdt_type  \\\n",
       "0                  0.0            0.0                 0.0   \n",
       "1                  0.0            1.0                 2.0   \n",
       "2                  0.0            0.0                 0.0   \n",
       "3                  0.0            0.0                 0.0   \n",
       "4                  0.0            1.0                 2.0   \n",
       "\n",
       "   autoconso_legumes_tot  autoconso_legumes_tot_type  autoconso_fruits_tot  \\\n",
       "0                    1.0                         2.0                   1.0   \n",
       "1                    1.0                         2.0                   1.0   \n",
       "2                    0.0                         0.0                   1.0   \n",
       "3                    1.0                         2.0                   1.0   \n",
       "4                    1.0                         2.0                   1.0   \n",
       "\n",
       "   autoconso_fruits_tot_type  autoconso_pdts_mer  autoconso_pdts_mer_type  \\\n",
       "0                        2.0                 0.0                      0.0   \n",
       "1                        2.0                 0.0                      0.0   \n",
       "2                        2.0                 0.0                      0.0   \n",
       "3                        2.0                 0.0                      0.0   \n",
       "4                        2.0                 0.0                      0.0   \n",
       "\n",
       "   conso_aliments_bio  conso_lait_bio_freq  conso_oeufs_bio_freq  \\\n",
       "0                 1.0                  3.0                   6.0   \n",
       "1                 1.0                  2.0                   1.0   \n",
       "2                 2.0                  NaN                   NaN   \n",
       "3                 2.0                  NaN                   NaN   \n",
       "4                 1.0                  1.0                   4.0   \n",
       "\n",
       "   conso_volailles_bio_freq  conso_viandes_bio_freq  conso_poissons_bio_freq  \\\n",
       "0                       6.0                     6.0                      4.0   \n",
       "1                       2.0                     1.0                      3.0   \n",
       "2                       NaN                     NaN                      NaN   \n",
       "3                       NaN                     NaN                      NaN   \n",
       "4                       3.0                     1.0                      1.0   \n",
       "\n",
       "   conso_fruits_bio_freq conso_fruits_bio_libelle  conso_pdt_bio_freq  \\\n",
       "0                    6.0                                          6.0   \n",
       "1                    1.0            BANANE, POMME                 1.0   \n",
       "2                    NaN                                          NaN   \n",
       "3                    NaN                                          NaN   \n",
       "4                    3.0             POIRE, POMME                 4.0   \n",
       "\n",
       "   conso_legumes_bio_freq           conso_legumes_bio_libelle  \\\n",
       "0                     6.0                                       \n",
       "1                     1.0  BETTERAVE, CAROTTE, SALADE, TOMATE   \n",
       "2                     NaN                                       \n",
       "3                     NaN                                       \n",
       "4                     4.0                                       \n",
       "\n",
       "   conso_legumes_secs_bio_freq conso_legumes_secs_bio_libelle  \\\n",
       "0                          6.0                                  \n",
       "1                          4.0                                  \n",
       "2                          NaN                                  \n",
       "3                          NaN                                  \n",
       "4                          6.0                                  \n",
       "\n",
       "   conso_pain_bio_freq  conso_cereales_bio_freq conso_cereales_bio_libelle  \\\n",
       "0                  3.0                      3.0                        BLE   \n",
       "1                  3.0                      3.0          BARRE DE CEREALES   \n",
       "2                  NaN                      NaN                              \n",
       "3                  NaN                      NaN                              \n",
       "4                  1.0                      4.0                              \n",
       "\n",
       "   conso_autres_alim_bio_freq conso_autres_alim_bio_libelle  \\\n",
       "0                         6.0                                 \n",
       "1                         NaN                                 \n",
       "2                         NaN                                 \n",
       "3                         NaN                                 \n",
       "4                         4.0                                 \n",
       "\n",
       "   conso_lait_bebe_bio_freq  conso_yaourt_bebe_bio_freq  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "3                       NaN                         NaN   \n",
       "4                       NaN                         NaN   \n",
       "\n",
       "   conso_jus_bebe_bio_freq  conso_puree_bebe_bio_freq  \\\n",
       "0                      NaN                        NaN   \n",
       "1                      NaN                        NaN   \n",
       "2                      NaN                        NaN   \n",
       "3                      NaN                        NaN   \n",
       "4                      NaN                        NaN   \n",
       "\n",
       "   conso_cereales_bebe_bio_freq  conso_biscuits_bebe_bio_freq  \\\n",
       "0                           NaN                           NaN   \n",
       "1                           NaN                           NaN   \n",
       "2                           NaN                           NaN   \n",
       "3                           NaN                           NaN   \n",
       "4                           NaN                           NaN   \n",
       "\n",
       "   conso_plats_bebe_bio_freq  conso_compotes_bebe_bio_freq  \\\n",
       "0                        NaN                           NaN   \n",
       "1                        NaN                           NaN   \n",
       "2                        NaN                           NaN   \n",
       "3                        NaN                           NaN   \n",
       "4                        NaN                           NaN   \n",
       "\n",
       "   conso_cremes_bebe_bio_freq  consommation_bio  consommation_bio_type  \\\n",
       "0                         NaN               0.0                    0.0   \n",
       "1                         NaN               1.0                    2.0   \n",
       "2                         NaN               0.0                    0.0   \n",
       "3                         NaN               0.0                    0.0   \n",
       "4                         NaN               1.0                    1.0   \n",
       "\n",
       "   conso_oeufs_bio_tjr_svt  conso_lait_bio_tjr_svt  \\\n",
       "0                      NaN                     0.0   \n",
       "1                      1.0                     1.0   \n",
       "2                      0.0                     0.0   \n",
       "3                      0.0                     0.0   \n",
       "4                      0.0                     1.0   \n",
       "\n",
       "   conso_volailles_bio_tjr_svt  conso_viandes_bio_tjr_svt  \\\n",
       "0                          NaN                        NaN   \n",
       "1                          1.0                        1.0   \n",
       "2                          0.0                        0.0   \n",
       "3                          0.0                        0.0   \n",
       "4                          0.0                        1.0   \n",
       "\n",
       "   conso_poissons_bio_tjr_svt  conso_fruits_bio_tjr_svt  \\\n",
       "0                         0.0                       NaN   \n",
       "1                         0.0                       1.0   \n",
       "2                         0.0                       0.0   \n",
       "3                         0.0                       0.0   \n",
       "4                         1.0                       0.0   \n",
       "\n",
       "   conso_pdt_bio_tjr_svt  conso_legumes_bio_tjr_svt  \\\n",
       "0                    NaN                        NaN   \n",
       "1                    1.0                        1.0   \n",
       "2                    0.0                        0.0   \n",
       "3                    0.0                        0.0   \n",
       "4                    0.0                        0.0   \n",
       "\n",
       "   conso_legumes_secs_bio_tjr_svt  conso_cereales_bio_tjr_svt  \\\n",
       "0                             NaN                         0.0   \n",
       "1                             0.0                         0.0   \n",
       "2                             0.0                         0.0   \n",
       "3                             0.0                         0.0   \n",
       "4                             NaN                         0.0   \n",
       "\n",
       "   conso_pain_bio_tjr_svt  conso_autres_alim_bio_tjr_svt  conso_barbecue  \\\n",
       "0                     0.0                            NaN             1.0   \n",
       "1                     0.0                            NaN             1.0   \n",
       "2                     0.0                            0.0             1.0   \n",
       "3                     0.0                            0.0             1.0   \n",
       "4                     1.0                            0.0             2.0   \n",
       "\n",
       "   conso_barbecue_elec  conso_barbecue_bois  conso_barbecue_gaz  \\\n",
       "0                  0.0                  1.0                 0.0   \n",
       "1                  0.0                  1.0                 1.0   \n",
       "2                  0.0                  1.0                 0.0   \n",
       "3                  0.0                  0.0                 1.0   \n",
       "4                  NaN                  NaN                 NaN   \n",
       "\n",
       "   conso_barbecue_printps_ete_freq  conso_barbecue_automn_hiver_freq  \n",
       "0                              3.0                               1.0  \n",
       "1                              4.0                               1.0  \n",
       "2                              3.0                               2.0  \n",
       "3                              4.0                               2.0  \n",
       "4                              NaN                               NaN  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_x_habitudes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d47dfb-434b-48e8-829e-56063e29af54",
   "metadata": {},
   "source": [
    "A vous d'ajouter les variables qui vous intéressent et à multiplier les visualisations !\n",
    "Les plus beaux graphes seront partagés à l'issue du funathon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6f3843-855f-4fa4-8f76-171b81930a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd7c0-7459-4474-a8c0-4977f185324b",
   "metadata": {},
   "source": [
    "### 3. Cartographie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578ecff-28da-4834-a461-71d9682f4eff",
   "metadata": {},
   "source": [
    "Pour la cartographie, on a besoin de fonds de carte. Ce sont des bases d'objets vectoriels. Par exemple, pour une carte de France par région, on aura une ligne par région avec un attribut géographique renseignant les coordonnées du vecteur (ou polygone). Le package **cartiflette** nous permet de les télécharger directement et facilement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04f1f720-16fc-4565-b98d-fd688614d3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://minio.lab.sspcloud.fr/projet-cartiflette/diffusion/shapefiles-test1/year=2022/administrative_level=REGION/crs=4326/FRANCE_ENTIERE=metropole/vectorfile_format=topojson/provider=IGN/source=EXPRESS-COG-CARTO-TERRITOIRE/raw.topojson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: : 4.76MiB [00:00, 56.6MiB/s]\n",
      "ERROR 1: PROJ: proj_create_from_database: Open of /opt/mamba/share/proj failed\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "region = cartiflette.s3.download_vectorfile_url_all(\n",
    "    crs = 4326,\n",
    "    values = \"metropole\",\n",
    "    borders=\"REGION\", # notre unité géographique\n",
    "    vectorfile_format=\"topojson\",\n",
    "    filter_by=\"FRANCE_ENTIERE\", # le champ qui nous intéresse\n",
    "    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n",
    "    year=2022)\n",
    "ax = region.plot()\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4e94a5ca-5805-4928-8113-ccca4a8be8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ID</th>\n",
       "      <th>NOM_M</th>\n",
       "      <th>NOM</th>\n",
       "      <th>INSEE_REG</th>\n",
       "      <th>source</th>\n",
       "      <th>territoire</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION_FXX_0000000000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ILE-DE-FRANCE</td>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>11</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.94279 49.07828, 2.94294 49.07828, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION_FXX_0000000000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRE-VAL DE LOIRE</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "      <td>24</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.34194 48.31617, 2.34224 48.31617, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION_FXX_0000000000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOURGOGNE-FRANCHE-COMTE</td>\n",
       "      <td>Bourgogne-Franche-Comté</td>\n",
       "      <td>27</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((7.01658 47.64695, 7.01644 47.64695, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REGION_FXX_0000000000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMANDIE</td>\n",
       "      <td>Normandie</td>\n",
       "      <td>28</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-1.51177 48.66055, -1.51162 48...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGION_FXX_0000000000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAUTS-DE-FRANCE</td>\n",
       "      <td>Hauts-de-France</td>\n",
       "      <td>32</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.72418 49.08072, 2.72418 49.08062, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  ID                    NOM_M  \\\n",
       "0  REGION_FXX_0000000000001 NaN            ILE-DE-FRANCE   \n",
       "1  REGION_FXX_0000000000002 NaN      CENTRE-VAL DE LOIRE   \n",
       "2  REGION_FXX_0000000000003 NaN  BOURGOGNE-FRANCHE-COMTE   \n",
       "3  REGION_FXX_0000000000004 NaN                NORMANDIE   \n",
       "4  REGION_FXX_0000000000005 NaN          HAUTS-DE-FRANCE   \n",
       "\n",
       "                       NOM INSEE_REG                            source  \\\n",
       "0            Île-de-France        11  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "1      Centre-Val de Loire        24  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "2  Bourgogne-Franche-Comté        27  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "3                Normandie        28  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "4          Hauts-de-France        32  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "\n",
       "  territoire                                           geometry  \n",
       "0  metropole  POLYGON ((2.94279 49.07828, 2.94294 49.07828, ...  \n",
       "1  metropole  POLYGON ((2.34194 48.31617, 2.34224 48.31617, ...  \n",
       "2  metropole  POLYGON ((7.01658 47.64695, 7.01644 47.64695, ...  \n",
       "3  metropole  MULTIPOLYGON (((-1.51177 48.66055, -1.51162 48...  \n",
       "4  metropole  POLYGON ((2.72418 49.08072, 2.72418 49.08062, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaece957-d5e8-40e4-9fc8-b5fb24505565",
   "metadata": {},
   "source": [
    "On va s'intéresser aux fréquences de consommation de certains aliments, présentes dans la table fpq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31f7064d-f2c5-4e96-b0f0-f0e0ed9c8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "description_x_fpq = pd.merge(description_indiv,fpq,on=\"NOIND\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7a8ebb09-99e8-4bde-9014-909c8954046b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recodage de la variable région pour avoir les mêmes noms que dans notre fond de carte (qu'on vient de télécharger avec cartiflette)\n",
    "\n",
    "dico_libelle_region = {1:\"ILE-DE-FRANCE\",\n",
    "                      2:\"NORMANDIE\",\n",
    "                      3:\"CENTRE-VAL DE LOIRE\",\n",
    "                      4:\"PAYS DE LA LOIRE\",\n",
    "                      5:\"BRETAGNE\",\n",
    "                      6:\"HAUTS-DE-FRANCE\",\n",
    "                      7:\"GRAND EST\",\n",
    "                      8:\"BOURGOGNE-FRANCHE-COMTE\",\n",
    "                      9:\"AUVERGNE-RHONE-ALPES\",\n",
    "                      10:\"PROVENCE-ALPES-COTE D'AZUR\",\n",
    "                      11:\"OCCITANIE\",\n",
    "                      12:\"NOUVELLE-AQUITAINE\"}\n",
    "\n",
    "description_x_fpq[\"region_recode\"]=description_x_fpq['region_adm_12cl'].replace(dico_libelle_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "23998dd9-4c75-4744-8c28-2ffa3ebc51ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region_recode\n",
       "AUVERGNE-RHONE-ALPES          5.205775\n",
       "BOURGOGNE-FRANCHE-COMTE       5.630435\n",
       "BRETAGNE                      6.551802\n",
       "CENTRE-VAL DE LOIRE           3.404255\n",
       "GRAND EST                     5.797945\n",
       "HAUTS-DE-FRANCE               6.303672\n",
       "ILE-DE-FRANCE                 4.288275\n",
       "NORMANDIE                     5.388889\n",
       "NOUVELLE-AQUITAINE            4.390625\n",
       "OCCITANIE                     4.109873\n",
       "PAYS DE LA LOIRE              3.769676\n",
       "PROVENCE-ALPES-COTE D'AZUR    4.062281\n",
       "Name: BA_biere_freq_M, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Variable à représenter géographiquement : nombre de bière consommées par mois. \n",
    "\n",
    "biere_par_region = description_x_fpq.groupby('region_recode')['BA_biere_freq_M'].mean()\n",
    "biere_par_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bfbba85-23dd-484c-8eaf-7ba9a979ec4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ID</th>\n",
       "      <th>NOM_M</th>\n",
       "      <th>NOM</th>\n",
       "      <th>INSEE_REG</th>\n",
       "      <th>source</th>\n",
       "      <th>territoire</th>\n",
       "      <th>geometry</th>\n",
       "      <th>BA_biere_freq_M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REGION_FXX_0000000000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ILE-DE-FRANCE</td>\n",
       "      <td>Île-de-France</td>\n",
       "      <td>11</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.94279 49.07828, 2.94294 49.07828, ...</td>\n",
       "      <td>4.288275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REGION_FXX_0000000000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CENTRE-VAL DE LOIRE</td>\n",
       "      <td>Centre-Val de Loire</td>\n",
       "      <td>24</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.34194 48.31617, 2.34224 48.31617, ...</td>\n",
       "      <td>3.404255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REGION_FXX_0000000000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BOURGOGNE-FRANCHE-COMTE</td>\n",
       "      <td>Bourgogne-Franche-Comté</td>\n",
       "      <td>27</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((7.01658 47.64695, 7.01644 47.64695, ...</td>\n",
       "      <td>5.630435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REGION_FXX_0000000000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NORMANDIE</td>\n",
       "      <td>Normandie</td>\n",
       "      <td>28</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-1.51177 48.66055, -1.51162 48...</td>\n",
       "      <td>5.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REGION_FXX_0000000000005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HAUTS-DE-FRANCE</td>\n",
       "      <td>Hauts-de-France</td>\n",
       "      <td>32</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((2.72418 49.08072, 2.72418 49.08062, ...</td>\n",
       "      <td>6.303672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>REGION_FXX_0000000000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GRAND EST</td>\n",
       "      <td>Grand Est</td>\n",
       "      <td>44</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((5.10156 47.65953, 5.10156 47.65963, ...</td>\n",
       "      <td>5.797945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>REGION_FXX_0000000000007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PAYS DE LA LOIRE</td>\n",
       "      <td>Pays de la Loire</td>\n",
       "      <td>52</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-2.35799 47.04230, -2.35799 47...</td>\n",
       "      <td>3.769676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>REGION_FXX_0000000000008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BRETAGNE</td>\n",
       "      <td>Bretagne</td>\n",
       "      <td>53</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-4.01308 47.70860, -4.01323 47...</td>\n",
       "      <td>6.551802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>REGION_FXX_0000000000009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NOUVELLE-AQUITAINE</td>\n",
       "      <td>Nouvelle-Aquitaine</td>\n",
       "      <td>75</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-1.17334 45.58609, -1.17348 45...</td>\n",
       "      <td>4.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>REGION_FXX_0000000000010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OCCITANIE</td>\n",
       "      <td>Occitanie</td>\n",
       "      <td>76</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((-0.08763 43.33373, -0.08763 43...</td>\n",
       "      <td>4.109873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REGION_FXX_0000000000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AUVERGNE-RHONE-ALPES</td>\n",
       "      <td>Auvergne-Rhône-Alpes</td>\n",
       "      <td>84</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>POLYGON ((6.62993 45.10934, 6.62935 45.10963, ...</td>\n",
       "      <td>5.205775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>REGION_FXX_0000000000012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PROVENCE-ALPES-COTE D'AZUR</td>\n",
       "      <td>Provence-Alpes-Côte d'Azur</td>\n",
       "      <td>93</td>\n",
       "      <td>IGN:EXPRESS-COG-CARTO-TERRITOIRE</td>\n",
       "      <td>metropole</td>\n",
       "      <td>MULTIPOLYGON (((6.19933 42.98205, 6.19918 42.9...</td>\n",
       "      <td>4.062281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          id  ID                       NOM_M  \\\n",
       "0   REGION_FXX_0000000000001 NaN               ILE-DE-FRANCE   \n",
       "1   REGION_FXX_0000000000002 NaN         CENTRE-VAL DE LOIRE   \n",
       "2   REGION_FXX_0000000000003 NaN     BOURGOGNE-FRANCHE-COMTE   \n",
       "3   REGION_FXX_0000000000004 NaN                   NORMANDIE   \n",
       "4   REGION_FXX_0000000000005 NaN             HAUTS-DE-FRANCE   \n",
       "5   REGION_FXX_0000000000006 NaN                   GRAND EST   \n",
       "6   REGION_FXX_0000000000007 NaN            PAYS DE LA LOIRE   \n",
       "7   REGION_FXX_0000000000008 NaN                    BRETAGNE   \n",
       "8   REGION_FXX_0000000000009 NaN          NOUVELLE-AQUITAINE   \n",
       "9   REGION_FXX_0000000000010 NaN                   OCCITANIE   \n",
       "10  REGION_FXX_0000000000011 NaN        AUVERGNE-RHONE-ALPES   \n",
       "11  REGION_FXX_0000000000012 NaN  PROVENCE-ALPES-COTE D'AZUR   \n",
       "\n",
       "                           NOM INSEE_REG                            source  \\\n",
       "0                Île-de-France        11  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "1          Centre-Val de Loire        24  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "2      Bourgogne-Franche-Comté        27  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "3                    Normandie        28  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "4              Hauts-de-France        32  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "5                    Grand Est        44  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "6             Pays de la Loire        52  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "7                     Bretagne        53  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "8           Nouvelle-Aquitaine        75  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "9                    Occitanie        76  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "10        Auvergne-Rhône-Alpes        84  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "11  Provence-Alpes-Côte d'Azur        93  IGN:EXPRESS-COG-CARTO-TERRITOIRE   \n",
       "\n",
       "   territoire                                           geometry  \\\n",
       "0   metropole  POLYGON ((2.94279 49.07828, 2.94294 49.07828, ...   \n",
       "1   metropole  POLYGON ((2.34194 48.31617, 2.34224 48.31617, ...   \n",
       "2   metropole  POLYGON ((7.01658 47.64695, 7.01644 47.64695, ...   \n",
       "3   metropole  MULTIPOLYGON (((-1.51177 48.66055, -1.51162 48...   \n",
       "4   metropole  POLYGON ((2.72418 49.08072, 2.72418 49.08062, ...   \n",
       "5   metropole  POLYGON ((5.10156 47.65953, 5.10156 47.65963, ...   \n",
       "6   metropole  MULTIPOLYGON (((-2.35799 47.04230, -2.35799 47...   \n",
       "7   metropole  MULTIPOLYGON (((-4.01308 47.70860, -4.01323 47...   \n",
       "8   metropole  MULTIPOLYGON (((-1.17334 45.58609, -1.17348 45...   \n",
       "9   metropole  MULTIPOLYGON (((-0.08763 43.33373, -0.08763 43...   \n",
       "10  metropole  POLYGON ((6.62993 45.10934, 6.62935 45.10963, ...   \n",
       "11  metropole  MULTIPOLYGON (((6.19933 42.98205, 6.19918 42.9...   \n",
       "\n",
       "    BA_biere_freq_M  \n",
       "0          4.288275  \n",
       "1          3.404255  \n",
       "2          5.630435  \n",
       "3          5.388889  \n",
       "4          6.303672  \n",
       "5          5.797945  \n",
       "6          3.769676  \n",
       "7          6.551802  \n",
       "8          4.390625  \n",
       "9          4.109873  \n",
       "10         5.205775  \n",
       "11         4.062281  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On crée un petit tableau avec nos régions et leurs attributs géographiques, \n",
    "# et surtout la variable qu'on vient de calculer (c'est-à-dire le nombre de bières consommées par mois par région en moyenne)\n",
    "\n",
    "region_inca=pd.merge(region,biere_par_region,left_on=\"NOM_M\",right_on=\"region_recode\")\n",
    "region_inca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5224851-7086-4838-b1fe-9f0af1a43376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Créez une figure et des axes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Dessinez la carte choroplèthe\n",
    "region_inca.plot(column='BA_biere_freq_M', cmap='YlOrRd', linewidth=0.8, ax=ax, edgecolor='0.8')\n",
    "\n",
    "# Ajoutez une légende\n",
    "sm = plt.cm.ScalarMappable(cmap='YlOrRd', norm=plt.Normalize(vmin=region_inca['BA_biere_freq_M'].min(), vmax=region_inca['BA_biere_freq_M'].max()))\n",
    "plt.colorbar(sm, ax=ax)\n",
    "plt.title(\"Nombre de bières consommées par mois en moyenne par région\")\n",
    "\n",
    "# Affichez le graphique\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b9956-0a0d-456b-8693-6a4c4c0c8b12",
   "metadata": {},
   "source": [
    "Maintenant, créez votre propre carte ! Vous pouvez regarder directement dans le dictionnaire des variables, ou bien vous aider des libellés. Les fréquences en nombre de jours par mois finissent par _freq_M, et les indicatrices de consommation finissent par _ON (ces dernières valent 1 si le produit est consommé et 0 sinon). \n",
    "\n",
    "Par exemple, on peut choisir parmi les variables dans : ```fpq.columns.tolist()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7c57d344-3e83-4b4b-a5ca-12faf0a10e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "5d8b18da-cf52-477e-8cf6-90cd2d2d0d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS : Corrélations entre consommations mensuelles d'aliments\n",
    "\n",
    "# Output souhaité : Top K des produits consommés la plus corrélée (positivement ou négativement)\n",
    "\n",
    "# on récupère les variables de fréquence de conso (suffixées freq_M) \n",
    "variables_freq_M = [ variable for variable in fpq.columns.tolist() if 'freq_M' in variable ]\n",
    "variables_freq_M\n",
    "\n",
    "fpq_freq_M = fpq[ variables_freq_M ].fillna(0)\n",
    "fpq_freq_M\n",
    "\n",
    "matrice_correlation = fpq_freq_M.corr()\n",
    "matrice_correlation\n",
    "\n",
    "# transformation matrice des orrélations en dataframe des paires de corrélations\n",
    "correlations = matrice_correlation.stack().reset_index()\n",
    "#set column names\n",
    "correlations.columns = ['item1','item2','correlation']\n",
    "#print (correlations)\n",
    "\n",
    "\n",
    "correlations['categorie_item1'] = correlations.item1.str[:3]\n",
    "correlations['categorie_item2'] = correlations.item2.str[:3]\n",
    "correlations\n",
    "\n",
    "# suppression des lignes où les 2 items ont la même catégorie\n",
    "correlations =  correlations.drop(correlations[(correlations.categorie_item1 == correlations.categorie_item2)].index)\n",
    "correlations = correlations[~correlations['item1'].str.contains('tot')]\n",
    "correlations = correlations[~correlations['item2'].str.contains('tot')]\n",
    "#correlations =  correlations.drop(correlations[('tot' in correlations.item1)].index)\n",
    "\n",
    "top_combos_max_cor = correlations.sort_values(by='correlation', ascending=False).head(10)\n",
    "top_combos_min_cor = correlations.sort_values(by='correlation', ascending=True).head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "24379198-0b4d-4122-a94e-1657afbec351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>categorie_item1</th>\n",
       "      <th>categorie_item2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31128</th>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>BIS_biscuit_maison_freq_M</td>\n",
       "      <td>0.754089</td>\n",
       "      <td>PL_</td>\n",
       "      <td>BIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35688</th>\n",
       "      <td>BIS_biscuit_maison_freq_M</td>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>0.754089</td>\n",
       "      <td>BIS</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27284</th>\n",
       "      <td>VC_boeuf_maison_freq_M</td>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>0.741766</td>\n",
       "      <td>VC_</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31084</th>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>VC_boeuf_maison_freq_M</td>\n",
       "      <td>0.741766</td>\n",
       "      <td>PL_</td>\n",
       "      <td>VC_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31088</th>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>VC_poulet_maison_freq_M</td>\n",
       "      <td>0.741208</td>\n",
       "      <td>PL_</td>\n",
       "      <td>VC_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28048</th>\n",
       "      <td>VC_poulet_maison_freq_M</td>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>0.741208</td>\n",
       "      <td>VC_</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23082</th>\n",
       "      <td>LEG_haricot_freq_M</td>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>0.734691</td>\n",
       "      <td>LEG</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31062</th>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>LEG_haricot_freq_M</td>\n",
       "      <td>0.734691</td>\n",
       "      <td>PL_</td>\n",
       "      <td>LEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32823</th>\n",
       "      <td>FR_banane_freq_M</td>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>0.730462</td>\n",
       "      <td>FR_</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31113</th>\n",
       "      <td>PL_yaourt_entremet_freq_M</td>\n",
       "      <td>FR_banane_freq_M</td>\n",
       "      <td>0.730462</td>\n",
       "      <td>PL_</td>\n",
       "      <td>FR_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           item1                      item2  correlation  \\\n",
       "31128  PL_yaourt_entremet_freq_M  BIS_biscuit_maison_freq_M     0.754089   \n",
       "35688  BIS_biscuit_maison_freq_M  PL_yaourt_entremet_freq_M     0.754089   \n",
       "27284     VC_boeuf_maison_freq_M  PL_yaourt_entremet_freq_M     0.741766   \n",
       "31084  PL_yaourt_entremet_freq_M     VC_boeuf_maison_freq_M     0.741766   \n",
       "31088  PL_yaourt_entremet_freq_M    VC_poulet_maison_freq_M     0.741208   \n",
       "28048    VC_poulet_maison_freq_M  PL_yaourt_entremet_freq_M     0.741208   \n",
       "23082         LEG_haricot_freq_M  PL_yaourt_entremet_freq_M     0.734691   \n",
       "31062  PL_yaourt_entremet_freq_M         LEG_haricot_freq_M     0.734691   \n",
       "32823           FR_banane_freq_M  PL_yaourt_entremet_freq_M     0.730462   \n",
       "31113  PL_yaourt_entremet_freq_M           FR_banane_freq_M     0.730462   \n",
       "\n",
       "      categorie_item1 categorie_item2  \n",
       "31128             PL_             BIS  \n",
       "35688             BIS             PL_  \n",
       "27284             VC_             PL_  \n",
       "31084             PL_             VC_  \n",
       "31088             PL_             VC_  \n",
       "28048             VC_             PL_  \n",
       "23082             LEG             PL_  \n",
       "31062             PL_             LEG  \n",
       "32823             FR_             PL_  \n",
       "31113             PL_             FR_  "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_combos_max_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "e9c14352-18fe-42a8-9974-4574bd0eafc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item1</th>\n",
       "      <th>item2</th>\n",
       "      <th>correlation</th>\n",
       "      <th>categorie_item1</th>\n",
       "      <th>categorie_item2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10691</th>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>BIS_biscuit_maison_freq_M</td>\n",
       "      <td>-0.268984</td>\n",
       "      <td>PL_</td>\n",
       "      <td>BIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35581</th>\n",
       "      <td>BIS_biscuit_maison_freq_M</td>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>-0.268984</td>\n",
       "      <td>BIS</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10625</th>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>LEG_haricot_freq_M</td>\n",
       "      <td>-0.265552</td>\n",
       "      <td>PL_</td>\n",
       "      <td>LEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22975</th>\n",
       "      <td>LEG_haricot_freq_M</td>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>-0.265552</td>\n",
       "      <td>LEG</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10651</th>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>VC_poulet_maison_freq_M</td>\n",
       "      <td>-0.263379</td>\n",
       "      <td>PL_</td>\n",
       "      <td>VC_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27941</th>\n",
       "      <td>VC_poulet_maison_freq_M</td>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>-0.263379</td>\n",
       "      <td>VC_</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10627</th>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>LEG_haricot_maison_freq_M</td>\n",
       "      <td>-0.261089</td>\n",
       "      <td>PL_</td>\n",
       "      <td>LEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23357</th>\n",
       "      <td>LEG_haricot_maison_freq_M</td>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>-0.261089</td>\n",
       "      <td>LEG</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27177</th>\n",
       "      <td>VC_boeuf_maison_freq_M</td>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>-0.259269</td>\n",
       "      <td>VC_</td>\n",
       "      <td>PL_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10647</th>\n",
       "      <td>PL_yaourtentremet_freq_M</td>\n",
       "      <td>VC_boeuf_maison_freq_M</td>\n",
       "      <td>-0.259269</td>\n",
       "      <td>PL_</td>\n",
       "      <td>VC_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           item1                      item2  correlation  \\\n",
       "10691   PL_yaourtentremet_freq_M  BIS_biscuit_maison_freq_M    -0.268984   \n",
       "35581  BIS_biscuit_maison_freq_M   PL_yaourtentremet_freq_M    -0.268984   \n",
       "10625   PL_yaourtentremet_freq_M         LEG_haricot_freq_M    -0.265552   \n",
       "22975         LEG_haricot_freq_M   PL_yaourtentremet_freq_M    -0.265552   \n",
       "10651   PL_yaourtentremet_freq_M    VC_poulet_maison_freq_M    -0.263379   \n",
       "27941    VC_poulet_maison_freq_M   PL_yaourtentremet_freq_M    -0.263379   \n",
       "10627   PL_yaourtentremet_freq_M  LEG_haricot_maison_freq_M    -0.261089   \n",
       "23357  LEG_haricot_maison_freq_M   PL_yaourtentremet_freq_M    -0.261089   \n",
       "27177     VC_boeuf_maison_freq_M   PL_yaourtentremet_freq_M    -0.259269   \n",
       "10647   PL_yaourtentremet_freq_M     VC_boeuf_maison_freq_M    -0.259269   \n",
       "\n",
       "      categorie_item1 categorie_item2  \n",
       "10691             PL_             BIS  \n",
       "35581             BIS             PL_  \n",
       "10625             PL_             LEG  \n",
       "22975             LEG             PL_  \n",
       "10651             PL_             VC_  \n",
       "27941             VC_             PL_  \n",
       "10627             PL_             LEG  \n",
       "23357             LEG             PL_  \n",
       "27177             VC_             PL_  \n",
       "10647             PL_             VC_  "
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_combos_min_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f456cf-c7ca-4b80-885d-8b31fe5073e3",
   "metadata": {},
   "source": [
    "## Partie 2 : Clustering d'individus\n",
    "\n",
    "Premier point de contact : Antoine Palazzolo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4a2760-a941-4f12-84e3-278180730cf1",
   "metadata": {},
   "source": [
    "Lorsque l'on pense au Machine Learning, les premiers exemples qui viennent en tête sont souvent des problèmes de régression ou bien de classification.\n",
    "Ces cas d'usage font partie d'une branche du ML appelée _apprentissage supervisé_, qui requiert notamment d'avoir des données labellisées permettant aux diverses méthodes utilisées de comprendre la relation entre un ensemble de variables explicatives et une variable à prédire.\n",
    "\n",
    "_L'apprentissage non supervisé_ est une autre branche du ML qui ne consiste cette fois plus à prédire une variable donnée à partir de données labellisées.\n",
    "Au coeur de l'apprentissage non supervisé on trouve notamment le __clustering__.\n",
    "Cette fois-ci, le but est de créer à partir d'une population donnée un ensemble de clusters (ou paquets) d'individus regroupés par similarité, en utilisant de façon automatiques les caractéristiques les plus discriminantes de notre population. Ce sera peut-être plus clair avec quelques exemples et applications :\n",
    "- Une enseigne de retail possède une centaine de magasins en France et souhaite regrouper ces derniers en une poignée de groupes qu'elle pourra approvisionner de la même façon. Chaque groupe devra regrouper des magasins ayant des performances similaires et une clientèle proche. C'est un problème de clustering.\n",
    "- A partir d'une base de données regroupant les thèmes de prédilection de centaines de journalistes (ou bien leurs références), on souhaite regrouper ces mêmes journalistes en quelques catégories au sein desquelles chaque individu aura une orientation politique proche de celles des autres.\n",
    "- En fonction des caractéristiques physiques d'espèces animales ou végétales, on souhaite regrouper ces espèces en un plus petit nombre de groupes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e57398-8acd-4680-8fa5-ea5d712b1921",
   "metadata": {},
   "source": [
    "Il existe plusieurs méthodes pour faire du clustering, les deux plus connues étant :\n",
    "- Les [K-Moyennes](https://fr.wikipedia.org/wiki/K-moyennes) (ou K-Means), méthode la plus connue, basée sur l'utilisation de centroïdes itérés\n",
    "- Le [Clustering Ascendant Hiérarchique](https://fr.wikipedia.org/wiki/Regroupement_hi%C3%A9rarchique) (CAH), basé sur des regroupements en groupes de plus en plus grands, donnant par exemple lieu à des visualisations sous forme de dendrogrammes (ressemblant aux arbres phylogénétiques de vos cours de SVT au lycée)\n",
    "\n",
    "Nous allons mettre en pratique ces deux méthodes dans ce sujet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73323a-0153-41b6-9017-06b3a560e6c7",
   "metadata": {},
   "source": [
    "Une fois nos clusterings effectués, l'un des enjeux est ensuite aussi de pouvoir interpréter ces derniers :\n",
    "- Quelles sont les caractéristiques les plus discriminantes dans la constitution des groupes ?\n",
    "- Les clusters générés font-ils bien sens ? Que peut-on dire de ces groupes ?\n",
    "- Quelles méthodes de visualisation sont les plus adaptées ?\n",
    "\n",
    "Pour répondre à ces questions, un des outils principaux que nous pouvons utiliser est l'[Analyse en Composantes Principales](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales) (ACP), qui à partir de l'ensemble initial des colonnes en crée un ensemble de taille réduite qui maximise la discrimination des données les unes par rapport aux autres via ces nouvelles colonnes.\n",
    "En réduisant la dimension à moins de 3, on peut ainsi représenter graphiquement les données de façon plus claire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917d36-8696-4440-9b55-9f61725ea2f6",
   "metadata": {},
   "source": [
    "### 1. Preprocessing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c049f261-da0b-4ee8-b13a-1d56de6a4096",
   "metadata": {},
   "source": [
    "Pour cette étude nous allons commencer par la table des habitudes individuelles.\n",
    "Cette table contient les données des questionnaires auto-administrés relatifs aux volets « Habitudes alimentaires » et « Origine des aliments ».\n",
    "\n",
    "Elle regroupe les informations suivantes : lieux et occasions de consommation, consommations hors-foyer et entre les repas, préférences alimentaires, présence de sel/beurre/sauce sur la table au moment des repas, lecture des étiquettes, sources d’informations en alimentation, consommation de denrées animales crues et des croûtes de fromage, préparation des fruits et légumes crus, spécificités de l’alimentation des enfants de 0 à 35 mois (ex : allaitement (exclusif ou partiel), type de laits consommés, diversification alimentaire, matériaux des biberons et des tétines, préparation, stockage et conservation des biberons de lait, mode de chauffage des laits et contenants utilisés), autoconsommation et utilisation de produits phytosanitaires au potager, consommation d’aliments issus de l’agriculture biologique et cuisson des aliments au barbecue.\n",
    "\n",
    "Une fois le sujet terminé, vous pourrez si vous le souhaitez reproduire cette partie avec d'autres des tables à disposition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6787ea21-06f5-464e-b45d-8ea6a4f70d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0794e5-da86-449b-a085-bdba43fa1183",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7869779e-c56a-41b8-b79a-a789137cb453",
   "metadata": {},
   "source": [
    "#### Etape 1 : Analyse exploratoire & sélection de variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435dce15-ae58-44fb-9243-5a71a7c44c12",
   "metadata": {},
   "source": [
    "Regardons déjà à quoi ressemblent nos données en pratique. En utilisant Pandas, pouvez-vous dire :\n",
    "- Combien y a-t-il d'individus et de variables ?\n",
    "- Combien de variables présentent des valeurs vides ? En quelle proportion ?\n",
    "- Y a-t-il des variables qui ont la même valeur pour tous les individus ? Seront-elles utiles pour la discrimination des observations dans le clustering ?\n",
    "- Y a-t-il des variables qui n'ont pas de sens pour la caractérisation d'un groupe ? Cela comprend par exemple les identifiants.\n",
    "- Quels sont les types des variables ? Combien de variables non-numériques ? En pratique nous allons ici nous focaliser uniquement sur les données numériques de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93578fa3-f1db-4c5e-9cfa-a66ff7d33d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A vous de jouer !\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80c87c7-fd5e-4ed9-aea4-e231b8ef9f76",
   "metadata": {},
   "source": [
    "A partir des analyses que vous venez de réaliser, vous devriez avoir une meilleure idée de quoi garder dans la table pour appliquer les méthodes de clustering. Créez donc ```habitudes_indiv_clustering_1``` à partir de ```habitudes_indiv``` en retirant toutes les colonnes gênantes ou inutiles :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd79ab0-a795-4f1b-9fa4-02fdd02e166a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> Si besoin, dérouler pour révéler les indications plus détaillées :</summary>\n",
    "<br>\n",
    "\n",
    "Il vous faudra donc, a minima :\n",
    "- Retirer les colonnes d'identifiants\n",
    "- Retirer les colonnes vides\n",
    "- Conserver uniquement les colonnes numériques\n",
    "\n",
    "Pour aller plus loin, retirez les colonnes à moins de 2 valeurs distinctes.\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e350037-bcdd-4618-a217-66f25a970d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_1 = pd.DataFrame() # TODO\n",
    "\n",
    "habitudes_indiv_clustering_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0591321f-ef34-4957-8f78-c8290c1f7641",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Sélectionner les caractéristiques pour le clustering\n",
    "\n",
    "habitudes_indiv_clustering_1 = habitudes_indiv.drop(\n",
    "    ['POPULATION', 'NOIND', 'periode_reference'],  # Identifiants\n",
    "    axis=1\n",
    ").dropna(\n",
    "    axis=1, how='all'  # Colonnes vides\n",
    ").select_dtypes(\n",
    "    include=np.number  # Colonnes numériques à garder\n",
    ")\n",
    "\n",
    "habitudes_indiv_clustering_1 = habitudes_indiv_clustering_1.loc[\n",
    "    :, habitudes_indiv_clustering_1.nunique() > 1\n",
    "]  # On retire les colonnes avec moins de 2 valeurs distinctes\n",
    "\n",
    "habitudes_indiv_clustering_1.shape\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5019df24-d84e-487d-b086-669ac6d538c7",
   "metadata": {},
   "source": [
    "#### Etape 2 : Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71ae675-56f4-4bb9-8e8b-3c3c68ce3af0",
   "metadata": {},
   "source": [
    "Comme vous l'avez peut-être vu, si l'on cherche à retirer toutes les lignes ou colonnes avec au moins une valeur manquante, il ne reste plus grand-chose à la table...\n",
    "Nous allons donc les garder, d'autant plus que cela ne les empêche pas de contenir de l'information importante.\n",
    "\n",
    "Dans ce cas comment traiter les NaNs ?\n",
    "Il existe une méthode pour les remplacer par une valeur numérique, il s'agit de l'__[imputation](https://fr.wikipedia.org/wiki/Imputation_(statistique))__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50fa3e6-c22b-45ca-bd9f-20fe2c0146b6",
   "metadata": {},
   "source": [
    "Plusieurs méthodes d'imputation existent : remplacer les valeurs manquantes par la moyenne de la colonne, par une valeur issue de régression linéaire, de régression stochastique, etc.\n",
    "\n",
    "Dans notre cas particulier, la plupart des variables sont binaires, des réponses Oui/Non à une question.\n",
    "Une méthode que nous pouvons donc utiliser (mais d'autres marcheraient très bien aussi) est l'imputation par la valeur la plus fréquente de la colonne.\n",
    "\n",
    "En termes d'interprétation, cela revient à simplifier le problème en considérant que les non-répondants auraient répondu la même chose que la majorité des répondants, quitte à ce que cela mène à de possibles erreurs.\n",
    "Par exemple, les répondants \"Homme\" ont peu de chances de répondre \"Oui\" à l'allaitement, mais c'est une solution qui fonctionne tout de même en général très bien.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee550d-573c-43b1-aa6d-00829fbc94e2",
   "metadata": {},
   "source": [
    "A présent, appliquez cette stratégie d'imputation sur la table ```habitudes_indiv_clustering_1``` pour donner naissance à ```habitudes_indiv_clustering_2```. On demandera à ce que la table nouvellement créée soit sous la forme d'un array numpy, pour faciliter la suite des opérations.\n",
    "\n",
    "Vous avez le droit d'importer et utiliser la fonction ```SimpleImputer``` du package ```sklearn.impute```, dont l'output est déjà bien sous un format numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057bd13b-12d2-464a-a922-16bd888710e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2b127a-30b8-4a24-a865-651496f4627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_2 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c3628f-ff15-46bd-82e2-c450859ce8dd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Gérer les valeurs manquantes (NaN)\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "habitudes_indiv_clustering_2 = imputer.fit_transform(habitudes_indiv_clustering_1)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e056ea-5177-4c34-aa98-47b238550404",
   "metadata": {},
   "source": [
    "#### Etape 3 : Normalisation des colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ba789-3745-41a7-b4b4-5d4352167572",
   "metadata": {},
   "source": [
    "Pour la plupart des méthodes que nous allons utiliser, nous ne souhaitons pas nécessairement donner plus d'importance à une colonne qu'à une autre.\n",
    "Or pour plusieurs des fonctions que nous allons manipuler, le poids affecté à une colonne peut dépendre de sa moyenne ou de sa variance.\n",
    "\n",
    "Ici, les questions étant pour la plupart binaires, nous ne voulons pas qu'une question avec davantage de réponses positives ait une importance plus grande qu'une autre.\n",
    "Nous devons donc renormaliser les colonnes pour corriger ce problème.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99efd0cf-c7a4-4947-8122-96585b51042c",
   "metadata": {},
   "source": [
    "A vous de jouer : renormalisez l'ensemble des colonnes pour amener leur moyenne à 0 et leur variance à 1. Vous stockerez le résultat dans le tableau ```habitudes_indiv_clustering_3```.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```StandardScaler``` du package ```sklearn.preprocessing```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236e56e9-b966-40df-9c8f-4736f1a86968",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_3 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21905f6-526b-46c8-a9ec-96d77f230cab",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Normaliser les colonnes\n",
    "scaler = StandardScaler()\n",
    "habitudes_indiv_clustering_3 = scaler.fit_transform(habitudes_indiv_clustering_2)\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b401c50f-a004-466c-a97a-f19044bed319",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Etape 4 : Gestion des outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fbd468-56f6-4755-8c16-1ff319ebe9ba",
   "metadata": {},
   "source": [
    "Dans ce type de questionnaire il n'est pas rare de trouver des observations aberrantes, par exemple en raison d'individus répondant de façon absurde aux questions.\n",
    "De façon générale, si la base de données est suffisamment grande et que l'on ne s'intéresse pas nécessairement à chaque individu, une bonne pratique peut être de retirer les outliers de notre base.\n",
    "Cela permet en effet de limiter les risques d'avoir des clusters à un seul individu ne représentant rien d'intéressant ou d'avoir des visualisations déformées par une observation très loin par rapport aux autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8764c9-103e-4fd0-8e15-c4320d5c2402",
   "metadata": {},
   "source": [
    "A vous de jouer : retirez les outliers de la table ```habitudes_indiv_clustering_3```, disons 5% des observations, et stockez le résultat dans la table ```habitudes_indiv_clustering_4```.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```IsolationForest``` du package ```sklearn.ensemble```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfa22d3-9d7c-44b1-92d9-bf70a7931107",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering_4 = pd.DataFrame() # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dda9b15-1c1c-45cf-a319-072891eece3e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Détecter et retirer les outliers\n",
    "outlier_detector = IsolationForest(contamination=0.05, random_state=0)\n",
    "outlier_labels = outlier_detector.fit_predict(habitudes_indiv_clustering_3)\n",
    "habitudes_indiv_clustering_4 = habitudes_indiv_clustering_3[outlier_labels == 1]\n",
    "\n",
    "habitudes_indiv_clustering_4.shape\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6dd01-e3be-433c-80e7-37a4c71e5b44",
   "metadata": {},
   "source": [
    "Si vous le souhaitez, vous pourrez dans un second temps reproduire la suite sans retirer les outliers pour comparer les résultats obtenus.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16303c23-bae3-478c-bde2-d822093633d8",
   "metadata": {},
   "source": [
    "Vous avez à présent terminé le preprocessing de la table pour la partie Clustering.\n",
    "Libre à vous de rajouter des opérations supplémentaires si vous en voyez le besoin.\n",
    "Sinon nous pouvons rentrer dans le vif du sujet.\n",
    "\n",
    "Pour simplifier les notations, exécutez la cellule ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff6b809-7028-4ebd-b361-8de0f7090322",
   "metadata": {},
   "outputs": [],
   "source": [
    "habitudes_indiv_clustering = np.copy(habitudes_indiv_clustering_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f753dc2-3c24-48d3-b9c5-38c229463cdc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 2. Le clustering en lui-même"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6928c114-9d3a-4029-a10f-390b7896e5ae",
   "metadata": {},
   "source": [
    "Dans cette partie, nous allons mettre en pratique les 2 méthodes de clustering les plus classiques :\n",
    "- Les K-Moyennes (ou K-Means)\n",
    "- Le Clustering Ascendant Hiérarchique (CAH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cf647d-d2b7-40fc-a3ad-67e5d0b6cde0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### K-Moyennes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d7638f-4c80-4f3b-a07d-38737d03f079",
   "metadata": {},
   "source": [
    "Dans ce sujet, nous ne revenons pas sur la théorie derrière l'algorithme du K-Means.\n",
    "Donc si vous êtes intéressés pour savoir ce qui se passe derrière l'utilisation du package en boîte noire, la documentation sur cette thématique est largement disponible sur Internet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b50f93-d287-45f4-b84c-a9dc36543a19",
   "metadata": {},
   "source": [
    "##### Choisir le nombre de clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145d029f-1042-409a-8e47-84dd262d227e",
   "metadata": {},
   "source": [
    "Une particularité des K-moyennes est qu'il faut choisir en amont de l'application de l'algorithme le nombre de clusters (ou de centroïdes) ```k```, a priori sans savoir quel serait le nombre optimal.\n",
    "Il existe plusieurs méthodes pour faire ce choix :\n",
    "- S'il existe des contraintes métier ou des interprétations relatives au \"monde réel\" imposant une valeur de ```k```\n",
    "- En utilisant la méthode dite du __coude__, qui est la façon la plus simple d'avoir une idée de ```k``` à utiliser.\n",
    "    + Le principe est de lancer le K-means avec plusieurs valeurs de ```k```, représenter une mesure de la distance moyenne intra-clusters en fonction de ```k``` et trouver le premier point d'inflexion\n",
    "    + En revanche, le ```k``` renvoyé n'est pas toujours stable et parfois peu pertinent.\n",
    "- En utilisant la méthode dite de __silhouette__, méthode a priori plus fine mais un peu plus complexe que celle du coude\n",
    "    + Le score à maximiser par rapport à ```k``` est cette fois la moyenne d'une mesure de la similitude d’une observation à l’intérieur d’un groupe par rapport à d’autres groupes pour chaque point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfe8f98-3c8d-4d89-b8fc-223a3a1aee58",
   "metadata": {},
   "source": [
    "A titre d'exemple, utilisez la méthode du coude pour trouver le nombre optimal de clusters pour les données de ```habitudes_indiv_clustering```. On cherchera un ```k``` compris entre 1 et 10.\n",
    "\n",
    "Vous pouvez importer et utiliser la fonction ```KElbowVisualizer``` du package ```yellowbrick.cluster```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f935d28-93bb-4c86-867a-d26d0e487160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e2e9c-58d5-40e4-901c-b96ede0e1d7c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "elbow_method = KElbowVisualizer(KMeans(), k=(1,10))\n",
    "elbow_method.fit(habitudes_indiv_clustering)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d45aa1f-ec6e-4350-a5d0-c3e44b41bde9",
   "metadata": {},
   "source": [
    "Quel est le ```k``` obtenu ? Cette valeur reste-t-elle la même si vous lancez la méthode plusieurs fois ?\n",
    "\n",
    "S'il n'y a pas de point d'inflexion (ou coude) bien défini sur le graphique produit, la valeur peut souvent varier. Pour la suite du sujet, nous conserverons une valeur fixe, que vous pourrez modifier par la suite si vous le souhaitez. Exécutez la ligne ci-dessous :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b87b0-c8c7-4a0d-8255-df36e0050f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_kmeans = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111ed92f-7e74-4dfb-b8b8-5111eb1e3ac4",
   "metadata": {},
   "source": [
    "##### Le clustering en lui-même"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d562e-dd02-41f1-9b8c-dd0aeb48f14b",
   "metadata": {},
   "source": [
    "Une fois les données préprocessées et le ```k``` déterminé, clusteriser les données n'est plus très difficile.\n",
    "\n",
    "A l'aide de la documentation de la fonction ```KMeans()``` du package ```sklearn.cluster```, créez le vecteur ```clusters_kmeans``` des clusters obtenus par la méthode des K-moyennes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30946355-8b2e-44d3-871e-5e1fe90b7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9e4962-f8d8-4c72-add6-c9d37967471e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=k_kmeans, random_state=0)\n",
    "clusters_kmeans = kmeans.fit_predict(habitudes_indiv_clustering)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b36d0e-ba52-48bd-ae65-247b7b6bb2c8",
   "metadata": {},
   "source": [
    "Félicitations, vous avez désormais vos clusters !\n",
    "Pouvez-vous dire quelle est la taille de chacun ? Ces valeurs sont-elles proches les unes des autres ? Pouvez-vous déjà interpréter vos résultats ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f529d-171e-464b-8a87-8f8d3b82603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea3d960-2c1f-4e4e-b741-e9ea77fc0361",
   "metadata": {},
   "source": [
    "On a certes obtenu nos clusters, mais tout cela n'est pas encore très visuel...\n",
    "\n",
    "Mais pas de panique, plus que quelques cellules à attendre pour passer à la visualisation par ACP !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd856808-5dca-42e1-aa95-920fabe9990f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Clustering Ascendant Hiérarchique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfca4d-31c0-474d-b489-dbe1de5b9405",
   "metadata": {},
   "source": [
    "Avant de passer à la visualisation, nous allons nous attarder sur une autre méthode de clustering, à peu près équivalente aux K-moyennes en termes de performances, mais dont les résultats sont beaucoup plus visuels : le [CAH](https://www.xlstat.com/fr/solutions/fonctionnalites/classification-ascendante-hierarchique-cah). Comment est-ce que ça marche ?\n",
    "\n",
    "- On commence par calculer la dissimilarité entre nos N individus, ie leur distance deux à deux dans l'espace de nos variables\n",
    "- Puis on regroupe les deux individus dont le regroupement minimise un critère d'agrégation donné, créant ainsi une classe comprenant ces deux individus.\n",
    "- On calcule ensuite la dissimilarité entre cette classe et les N-2 autres individus en utilisant le critère d'agrégation.\n",
    "- Puis on regroupe les deux individus ou classes d'individus dont le regroupement minimise le critère d'agrégation.\n",
    "- On continue ainsi jusqu'à ce que tous les individus soient regroupés.\n",
    "\n",
    "Ces regroupements successifs produisent un arbre binaire de classification (_dendrogramme_), dont la racine correspond à la classe regroupant l'ensemble des individus.\n",
    "Ce dendrogramme représente une hiérarchie de partitions.\n",
    "On peut alors choisir une partition en tronquant l'arbre à un niveau donné, le niveau dépendant soit des contraintes de l'utilisateur, soit de critères plus objectifs.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050ced51-dab0-4f0d-88c9-1099d91724e4",
   "metadata": {},
   "source": [
    "Dans ce sujet, nous allons nous limiter à la méthode d'agrégation la plus standard, dite de __Ward__.\n",
    "En utilisant la fonction ```linkage``` du package ```scipy.cluster.hierarchy```, créez les regroupements successifs mentionnés plus haut.\n",
    "Le résultat tient en deux lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae640c8b-3892-4784-bfea-d5e658c4cfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regroupements = '' # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073e0bc-80cd-4f7b-ade1-460b0fe33c68",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from scipy.cluster.hierarchy import linkage\n",
    "\n",
    "# Utiliser la méthode linkage pour effectuer le clustering hiérarchique\n",
    "regroupements = linkage(habitudes_indiv_clustering, method='ward')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56cb913-023c-45b2-9dff-0e9ee93d268a",
   "metadata": {},
   "source": [
    "Maintenant les regroupements effectués, nous pouvons dessiner le dendrogramme les représentant.\n",
    "Pour des contraintes de lisibilité, nous vous demanderons de limiter l'affichage de l'arbre à une profondeur de 6.\n",
    "\n",
    "En utilisant les packages ```matplotlib.pyplot``` et ```sklearn.cluster.hierarchy```, représentez le dendrogramme :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03386895-d47c-4040-a399-aab1457d1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "profondeur_a_afficher = 6\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# TODO\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c75028e-69e9-4c0f-b4f1-be44cc5a0bd0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster.hierarchy import dendrogram\n",
    "\n",
    "profondeur_a_afficher = 6\n",
    "\n",
    "# Afficher le dendrogramme\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(regroupements,\n",
    "           truncate_mode='level',\n",
    "           p=profondeur_a_afficher)\n",
    "\n",
    "plt.title(\"Dendrogramme sur la table des habitudes alimentaires\")\n",
    "plt.xlabel(\"Classes d'individus\")\n",
    "plt.ylabel(\"Distance entre les classes\")\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beefdd5-f525-4036-abd1-ddbc8070f287",
   "metadata": {},
   "source": [
    "Si tout s'est bien passé jusqu'ici, vous devriez avoir un magnifique dendrogramme sous les yeux !\n",
    "\n",
    "Cependant une question demeure : jusque-là la problématique du nombre de clusters à utiliser ne s'est toujours pas posée, comment allons-nous choisir maintenant ?\n",
    "Encore une fois, des contraintes du monde réel peuvent venir diriger le choix.\n",
    "Si ce n'est pas le cas, on peut faire par rapport à l'allure du dendrogramme, en choisissant une coupe horizontale de l'arbre cohérente.\n",
    "Cette coupe détermine alors les clusters finaux."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f8697-8f60-497b-a9ee-299cc822aa9c",
   "metadata": {},
   "source": [
    "En utilisant la fonction ```fcluster``` du package ```sklearn.cluster.hierarchy```, réalisez cette coupe du dendrogramme au niveau ```k_cah = 3``` pour créer le vecteur ```clusters_cah``` des clusters obtenus par CAH. Une fois les clusters générés, que pouvez-vous en dire ? Est-ce cohérent avec votre dendrogramme ?\n",
    "\n",
    "Une fois le reste du sujet effectué, vous pourrez également reprendre cette partie avec ```k_cah = 4```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5c3cbd-acb4-4b5c-bb2e-aa93acb3215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_cah = 3  # Nombre de clusters souhaité\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8387b6a9-709d-49cf-955a-0da7dd33c7d0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.cluster.hierarchy import fcluster\n",
    "\n",
    "k_cah = 3  # Nombre de clusters souhaité\n",
    "clusters_cah = fcluster(regroupements, k_cah, criterion='maxclust')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6750427-157a-4e32-a4d2-29c7c60fd6a7",
   "metadata": {},
   "source": [
    "Maintenant les clusters obtenus par deux méthodes différentes, il est temps de passer à la visualisation !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6725dcb-dc38-4688-ace7-309e7602e770",
   "metadata": {},
   "source": [
    "### 3. Visualisations et interprétations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0e83ad-c992-4b61-9cea-f0a2bb7a9f47",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Réaliser l'ACP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b2f16-ba6d-4e1e-a74a-16e7fe49ff14",
   "metadata": {},
   "source": [
    "La méthode la plus simple pour visualiser nos clusters serait de représenter chaque individu dans l'espace à N dimensions des variables de la table, et colorier chaque individu en fonction de son cluster.\n",
    "On pourrait alors bien différencier les variables les plus discrimantes et les différents groupes.\n",
    "Un seul problème ici : dès que N > 3, nous avons du mal à représenter le résultat de façon intelligible...\n",
    "\n",
    "C'est là qu'intervient __l'Analyse en Composantes Principales__ ([ACP](https://www.xlstat.com/fr/solutions/fonctionnalites/analyse-en-composantes-principales-acp)), qui permet de projeter notre espace à haute dimension dans un espace de dimension plus petite.\n",
    "La contrainte majeure de la projection est de pouvoir conserver le maximum d'information (mesurée par la variance totale de l'ensemble de données) dans notre nombre réduit de dimensions, appelées composantes principales.\n",
    "En se limitant à 2 ou 3 dimensions, on peut ainsi se représenter visuellement les relations entre les observations avec une perte de fiabilité minimale.\n",
    "\n",
    "Dans notre situation, on peut espérer que les clusters déterminés dans notre espace à N dimensions se différencient bien sur notre projection par ACP, et que la composition des composantes principales en fonction des variables initiales permette d'interpréter les clusters obtenus. Nous allons donc tester cette hypothèse !\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836d22f-cb8d-41af-9222-ce5c75c96b68",
   "metadata": {},
   "source": [
    "Nous allons commencer par le calcul des 3 composantes principales. Créez :\n",
    "- Un dataframe ```composantes_principales``` avec les mêmes colonnes que ```habitudes_indiv_clustering```, de longueur 3, où la ligne i correspond à la i-ème composante principale obtenue par l'ACP, et où chaque case correspond à la contribution relative de la variable j à à la composante i.\n",
    "- Un dataframe ```projection_individus``` correspondant à la projection des individus de ```habitudes_indiv_clustering``` dans l'espace des composantes principales. Ce dataframe aura donc 3 colonnes, que l'on pourra nommer [PC1, PC2, PC3].\n",
    "\n",
    "Vous pourrez utiliser la fonction ```PCA``` du package ```sklearn.decomposition``` ainsi que les différentes méthodes associées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83040b01-8daf-4ec4-bf90-a0691e9edfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_composantes_principales = 3\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d933a64-ad22-4afd-acfd-2c528b8c266b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "nb_composantes_principales = 3\n",
    "\n",
    "# Effectuer l'ACP\n",
    "acp = PCA(n_components=nb_composantes_principales)\n",
    "projection_individus_array = acp.fit_transform(habitudes_indiv_clustering)\n",
    "projection_individus = pd.DataFrame(data=projection_individus_array, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# Obtenir les poids des caractéristiques pour chaque composante principale\n",
    "composantes_principales = pd.DataFrame(acp.components_, columns=habitudes_indiv_clustering.columns)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74527adb-734f-4f47-968a-39bc3b85bc5e",
   "metadata": {},
   "source": [
    "Maintenant l'ACP terminée, nous allons tâcher d'interpréter les composantes principales obtenues.\n",
    "En effet, la combinaison linéaire des colonnes donnant naissance à nos nouveaux axes a souvent un \"sens\" dans le monde réel :\n",
    "- Soit parce qu'une petite poignée de variables représente la majorité de la composante\n",
    "- Soit parce que la plupart des colonnes intervenant dans la composante sommée se combinent bien pour former une interprétation naturelle.\n",
    "\n",
    "Ici, cela pourrait par exemple être :\n",
    "- La 1ère composante quasiment égale à une somme des variables \"Mange bio\", \"Mange de saison\" et \"Mange local\", montrant ainsi que l'axe le plus discriminant serait le fait pour un individu de se nourrir de façon plus ou moins écologique.\n",
    "- La 2è composante définie comme la somme pour tous les sports de la variable \"Pratique x sport régulièrement\", donnant ainsi un second axe discriminant les individus plus ou moins sportifs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29123de4-58f0-4fd5-a449-b398ae7cb021",
   "metadata": {},
   "source": [
    "Voyons ce que cela donne sur nos données. En utilisant la table ```composantes_principales``` et la fonction ```barh``` du package ```matplotlib.pyplot```, représentez les 20 variables les plus importantes (en termes de poids absolu) pour la 1ère composante de l'ACP, ainsi que leur contribution relative à la composante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67aa881-5b91-4ca5-b690-8580166795ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_top_features = 20\n",
    "\n",
    "# TODO\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbf9266-b8cc-4d3b-ba10-bd08bbeb9b96",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "nb_top_features = 20\n",
    "\n",
    "# Sélectionner les 20 caractéristiques les plus importantes pour PC1\n",
    "pc1_top_features_abs = composantes_principales.iloc[0].abs().nlargest(nb_top_features, keep='all')\n",
    "pc1_top_features = composantes_principales.iloc[0].loc[pc1_top_features_abs.index]\n",
    "\n",
    "# Afficher les poids des caractéristiques pour PC1\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(pc1_top_features.index, pc1_top_features.values)\n",
    "plt.title(f'{nb_top_features} variables les plus représentées pour PC1')\n",
    "plt.xlabel('Poids')\n",
    "plt.ylabel('Variables')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dacbeb-1774-4044-8d35-20aa02f14aff",
   "metadata": {},
   "source": [
    "Faites ensuite la même chose pour PC2 et pour PC3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0380680f-cf47-4111-8ff5-9f51dae9a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8ef8ae-5f07-47e0-be2c-bc37b7542c4c",
   "metadata": {},
   "source": [
    "A présent, comment pouvez-vous interpréter vos résultats ?\n",
    "Êtes-vous capables de donner un sens aux combinaisons linéaires obtenues ?\n",
    "Peut-on renommer nos variables \"PC1\", \"PC2, \"PC3\" ?\n",
    "\n",
    "Si vous ne vous souvenez plus de la signification des variables, vous pouvez retrouver le dictionnaire des variables ici : https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df0fcc-3195-4e19-831f-312ca20afcee",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "Il n'est pas garanti que vous retrouviez exactement les mêmes résultats, mais voici une proposition d'interprétation suite à l'exécution des codes du corrigé :\n",
    "- PC1 : Une mesure agrégée représentant à quel point l'individu a tendance à produire lui-même ce qu'il mange\n",
    "    - Nombreuses variables commençant par \"autoproduction\" et \"autoconso\" avec des poids positifs\n",
    "- PC2 : Une mesure agrégée représentant à quel point l'individu a tendance à manger bio\n",
    "    - Nombreuses variables contenant le mot \"bio\" avec des poids positifs\n",
    "- PC3 : Plus difficile à interpréter, une mesure agrégée de préférences alimentaires liées aux produits frais\n",
    "    - A quel point l'individu est-il prompt à manger frais (fruits & légumes, produits laitiers) ?\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e4ffb9-6aaa-4009-9b6a-db1f1fd6b95c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Et le clustering dans tout ça ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35217e-3d79-4085-a7b2-3c250cf3ba5a",
   "metadata": {},
   "source": [
    "Nous avons notre projection sur 2 ou 3 dimensions, nous avons interprété ces nouveaux axes, il s'agit donc maintenant de faire ce pour quoi l'ACP a initialement été réalisée : l'observation des clusters.\n",
    "\n",
    "Pour commencer, créez la table ```projection_individus_et_clusters``` concaténant les tables ```projection_individus```, ```clusters_kmeans``` et ```clusters_cah```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163e636-7773-442c-b2b1-2f9548f30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77aa0f7f-d45a-4044-9c4b-722222068fc5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "projection_individus_et_clusters = projection_individus.copy()\n",
    "projection_individus_et_clusters['cluster_kmeans'] = clusters_kmeans\n",
    "projection_individus_et_clusters['cluster_cah'] = clusters_cah\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d878023-e631-4422-a991-b04fed6c4c64",
   "metadata": {},
   "source": [
    "A présent, il ne vous reste plus qu'à utiliser la méthode ```.scatter()``` du package ```matplotlib.pyplot``` pour représenter vos individus dans l'espace __2D__ généré par les composantes PC1 et PC2. Concentrons-nous d'abord sur les clusters par K-moyennes : vous colorierez donc vos points en fonction de la valeur de la colonne 'cluster_kmeans'. A vous de jouer !\n",
    "\n",
    "Bonus : N'hésitez pas à renommer vos axes pour leur donner des noms plus explicites en fonction des interprétations que vous avez faites précédemment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c5879d-1884-43a2-8835-d21b2c1da95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32e25a-df88-408e-a57f-b35d1cc2cbe0",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Afficher le graphique des clusters en 2D\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter_plot = plt.scatter(\n",
    "    projection_individus_et_clusters['PC1'],\n",
    "    projection_individus_et_clusters['PC2'],\n",
    "    c=projection_individus_et_clusters['cluster_kmeans'],\n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "plt.legend(handles=scatter_plot.legend_elements()[0], labels=range(k_kmeans))\n",
    "plt.title('Individus groupés par tendances alimentaires')\n",
    "plt.xlabel('PC1 - Production & consommation de sa propre nourriture')\n",
    "plt.ylabel('PC2 - Consommation d\\'aliments bio')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e187a-4a9f-4996-803e-7d3923b421cf",
   "metadata": {},
   "source": [
    "Plutôt cool, non ?\n",
    "La grande question maintenant : vos clusters se différencient-ils bien sur votre visualisation ? Si les choses sont bien faites, il devrait y avoir peu de superposition des différents groupes.\n",
    "\n",
    "Pouvez-vous maintenant caractériser vos clusters en fonction de leur position sur votre graphe ? Vous avez ainsi vos _individus-types_ permettant de schématiser votre population.\n",
    "\n",
    "A présent, faites pareil sur les clusters obtenus par CAH, obtenez-vous exactement les mêmes clusters ? L'interprétation que vous avez faite change-t-elle ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d011e03a-d52e-47e3-94b3-ea9d0ed8405c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99c9664-7330-460c-84d9-5c7fb8c8f49e",
   "metadata": {},
   "source": [
    "Pour terminer, quid d'utiliser notre 3è composante principale dans notre représentation graphique ?\n",
    "Utilisez la fonction ```.scatter()``` pour réaliser cette fois un graphe en __3 dimensions__ dans lequel représenter vos individus.\n",
    "Comment évolue l'apparence de vos clusters ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9601eaf-5d58-40f7-9d34-7a3b1752c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348476ba-6ed7-4026-8e85-90f31f194f04",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary> <font size=2 color=\"red\"><b>Dérouler pour révéler le corrigé</b></font> </summary>\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Afficher le graphique des clusters en 3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "xs = projection_individus_et_clusters['PC1']\n",
    "ys = projection_individus_et_clusters['PC2']\n",
    "zs = projection_individus_et_clusters['PC3']\n",
    "ax.scatter(xs, ys, zs,\n",
    "           c=projection_individus_et_clusters['cluster_kmeans'],\n",
    "           cmap='viridis')\n",
    "\n",
    "ax.set_xlabel('PC1 - Production & consommation de sa propre nourriture')\n",
    "ax.set_ylabel('PC2 - Consommation d\\'aliments bio')\n",
    "ax.set_zlabel('PC3 - Préférences produits frais')\n",
    "\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0fab5-e545-4782-9153-d2b04bf8b14d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 4. Pour aller plus loin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b591a2e-6286-48bf-8904-e0963eb69f8f",
   "metadata": {},
   "source": [
    "Vous avez à présent terminé la partie clustering du sujet. Si vous souhaitez aller plus loin, vous pouvez :\n",
    "\n",
    "- Reproduire toutes les exécutions en retirant seulement l'une des étapes du preprocessing, comme par exemple le traitement des outliers. Comment évoluent alors les clusters et visualisations ?\n",
    "    + Retirer les outliers peut souvent conduire à la création de clusters constitués d'un seul individu, très éloigné des autres sur l'ACP. Il faut donc traiter ce type d'observations à part ou bien augmenter le nombre de clusters pour compenser.\n",
    "\n",
    "<br>\n",
    " \n",
    "- Reproduire toutes les exécutions en changeant le nombre de clusters ```k``` : comment évoluent les clusters ? Que cela donne-t-il sur les ACP ?\n",
    "    + Le cas ```k = 4``` est particulièrement intéressant : les clusters semblent se superposer sur les visualisations en 2D, mais on se rend compte lors de la visualisation 3D que les clusters prétendumment superposés se différencient en fait très bien si l'on rajoute la 3è composante principale. Cela permet alors de caractériser encore plus finement nos individus types.\n",
    "\n",
    "<br>\n",
    "\n",
    "- Reproduire toutes les exécutions sur une autre table que celles des habitudes alimentaires.\n",
    "    + Nous vous recommandons par exemple d'essayer avec :\n",
    "        - ```actphys_sedent``` : questionnaire sur l'activité physique des répondants\n",
    "        - ```fpq``` : questionnaire sur le fréquential alimentaire des individus\n",
    "    + Comment les clusters s'interprètent-ils alors ? Quels sont nos individus-types ?\n",
    "    + Si vous souhaitez aller encore plus loin, vous pouvez faire une jointure sur les différentes tables et opérer le clustering sur la table jointe afin de voir quelles sont les caractéristiques les plus discriminantes.\n",
    "    + Pour les autres tables, attention à ne bien garder que des variables numériques, et par exemple faire du _one-hot encoding_ sur les variables catégorielles codées sur des nombres entre 1 et 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f6b3f-ef3b-4c6c-82be-14daae9869aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f583b56-6b2f-4d6e-8d0a-3572000b6aa5",
   "metadata": {},
   "source": [
    "## Partie 3 : Premiers pas vers les méthodes de ML supervisé en Python\n",
    "\n",
    "Premier point de contact : Thomas Faria"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9df28b4-9e9a-4ac1-8558-3db57f000021",
   "metadata": {},
   "source": [
    "L'idée de cette partie est de tester différentes méthodes d'apprentissage statistique supervisées usuelles. Pour cela nous allons utiliser les données issues de la table de description des individus interviewés lors de l'enquête INCA 3 sur la consommation et les habitudes alimentaires des français.\n",
    "\n",
    "L'objectif consistera à prédire au mieux l'IMC d'un individu grâce aux diverses informations que nous détenons sur la personne. Contrairement à la partie 2 sur le clustering, il s'agit ici de d'apprentissage supervisé car nous avons en notre possessions des données labélisées. Parmi les méthodes d'apprentissages supervisé on distingue généralement deux grandes familles que sont la classification et la régression. Ici nous sommes confronté à un problème de régression puisque nous souhaitons prédire l'indice de masse corporelle exacte. Pour cela nous allons tester plusieurs méthodes différentes afin d'analyser lesquelles sont les plus efficaces sur les données que nous possédons.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c457a8bf-78fb-401d-ad69-421b4fea71e0",
   "metadata": {},
   "source": [
    "### 1. Prise en main des données"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a67af3d0-ef4a-4f7c-8ef2-38d9099ecfc6",
   "metadata": {},
   "source": [
    "Les données de l'enquête INCA3 sont disponibles sur *Data.gouv* à l'adresse suivante : https://www.data.gouv.fr/fr/datasets/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/. Cette table contient les données des questionnaires face-à-face relatifs aux volets « Socio-économique » et « Mesures anthropométriques » et des données des questionnaires auto-administrés relatifs aux volets « Etat de santé » et « Tabagisme ». \n",
    "\n",
    "Elle regroupe les informations suivantes : caractéristiques socio-démographiques de l’individu (ou de son représentant dans le cas des enfants), caractéristiques\n",
    "socio-démographiques de la personne de référence du foyer, niveau de vie du foyer, insécurité alimentaire, caractéristiques anthropométriques (poids, taille, indice\n",
    "de masse corporelle, statut pondéral) ; statut vis-à-vis d’allergies ou d’intolérances alimentaires, types de régimes alimentaires, types d’allergies ou d’intolérances\n",
    "alimentaires, régimes et histoire pondérale, statut vis-à-vis de la grossesse, de l’allaitement et de la ménopause (uniquement pour les femmes de 15 ans et plus),\n",
    "statut tabagique ; indicateurs de sous ou sur-déclaration en termes de consommations alimentaires.\n",
    "\n",
    "Nous avons préalablement selectionné un grand nombre de variables issues de cette base que nous avons ensuite enregistré dans un bucket s3.\n",
    "Si vous avez bien téléchargé les tables au début du notebook, il s'agit de la table appelée ```df```. N'hésitez pas à la réimporter si besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b71488af-3c09-4772-90a6-dee57ba6bc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5841, 118)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d619b2f-e1fe-4159-b47a-0655f2774c59",
   "metadata": {},
   "source": [
    "<i  class=\"fa fa-pencil\"></i> On peut tout d'abord remarquer que le jeu de données ne semble, a priori, pas idéal pour réaliser des méthodes de machine learning très complexes avec beaucoup de paramètres à estimer. Il arrive très souvent que des méthodes plus classiques soient aussi, voire plus, efficaces que les méthodes d'apprentissage statistique. Cependant ce jeu de données peut tout à fait être utilisé à des fins pédagogiques pour comprendre les principes généraux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "c61d0c0c-731e-493d-acd8-71d5d42a18a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOIND</th>\n",
       "      <th>imc</th>\n",
       "      <th>sex_PS</th>\n",
       "      <th>tage_PS</th>\n",
       "      <th>tage_PS_mois</th>\n",
       "      <th>diplome_interv</th>\n",
       "      <th>etude_4cl_interv</th>\n",
       "      <th>situ_prof_5cl_interv</th>\n",
       "      <th>atrav_interv</th>\n",
       "      <th>trav_nuit_interv</th>\n",
       "      <th>trav_nuit_2cl_interv</th>\n",
       "      <th>PCS_8cl_interv</th>\n",
       "      <th>PCS_4cl_interv</th>\n",
       "      <th>tps_travail_interv</th>\n",
       "      <th>vacances_interv</th>\n",
       "      <th>soins</th>\n",
       "      <th>situ_fin_3cl</th>\n",
       "      <th>revenu</th>\n",
       "      <th>RUC_4cl</th>\n",
       "      <th>nbpers</th>\n",
       "      <th>nbadu</th>\n",
       "      <th>nbenf</th>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <th>IA_statut</th>\n",
       "      <th>IA_score</th>\n",
       "      <th>statnut</th>\n",
       "      <th>maladie_allergie_alim</th>\n",
       "      <th>intoall_confirm_med</th>\n",
       "      <th>regime_vegetarien</th>\n",
       "      <th>regime_allergie</th>\n",
       "      <th>regime_maigrir_med</th>\n",
       "      <th>regime_maigrir_choix</th>\n",
       "      <th>regime_autre_med</th>\n",
       "      <th>regime_poidsstable</th>\n",
       "      <th>regime_forme</th>\n",
       "      <th>regime_autreraison</th>\n",
       "      <th>regime_non</th>\n",
       "      <th>veget_viande</th>\n",
       "      <th>veget_prodmer</th>\n",
       "      <th>veget_prodlait</th>\n",
       "      <th>veget_oeuf</th>\n",
       "      <th>veget_miel</th>\n",
       "      <th>veget_autre_alim</th>\n",
       "      <th>allergie_laitvache</th>\n",
       "      <th>allergie_prepainfsoja</th>\n",
       "      <th>allergie_prepainfamande</th>\n",
       "      <th>allergie_gluten</th>\n",
       "      <th>allergie_farineble</th>\n",
       "      <th>allergie_lupin</th>\n",
       "      <th>allergie_arachide</th>\n",
       "      <th>allergie_fruitcoque</th>\n",
       "      <th>allergie_oeuf</th>\n",
       "      <th>allergie_poisson</th>\n",
       "      <th>allergie_crustace</th>\n",
       "      <th>allergie_mollusque</th>\n",
       "      <th>allergie_soja</th>\n",
       "      <th>allergie_sesame</th>\n",
       "      <th>allergie_moutarde</th>\n",
       "      <th>allergie_sulfite</th>\n",
       "      <th>allergie_celeri</th>\n",
       "      <th>allergie_autres_fruitleg</th>\n",
       "      <th>allergie_autresalim</th>\n",
       "      <th>allergie_nondetermine</th>\n",
       "      <th>allergie_fruits</th>\n",
       "      <th>allergie_legumes</th>\n",
       "      <th>regime_passe</th>\n",
       "      <th>regime_nb_2dernann</th>\n",
       "      <th>regime_nb_anter2dernann</th>\n",
       "      <th>regime_type</th>\n",
       "      <th>regime_duree_sem</th>\n",
       "      <th>regime_duree_mois</th>\n",
       "      <th>regime_duree_nsp</th>\n",
       "      <th>poids_modif</th>\n",
       "      <th>poids_modifalim</th>\n",
       "      <th>poids_plusAP</th>\n",
       "      <th>poids_medicaments</th>\n",
       "      <th>poids_substituts</th>\n",
       "      <th>poids_chirurgie</th>\n",
       "      <th>poids_modifalim_laityaourt</th>\n",
       "      <th>poids_modifalim_fromage</th>\n",
       "      <th>poids_modifalim_mg</th>\n",
       "      <th>poids_modifalim_fruit</th>\n",
       "      <th>poids_modifalim_legume</th>\n",
       "      <th>poids_modifalim_pdtfeculent</th>\n",
       "      <th>poids_modifalim_pizza</th>\n",
       "      <th>poids_modifalim_pain</th>\n",
       "      <th>poids_modifalim_vrouge</th>\n",
       "      <th>poids_modifalim_volaille</th>\n",
       "      <th>poids_modifalim_oeuf</th>\n",
       "      <th>poids_modifalim_gateau</th>\n",
       "      <th>poids_modifalim_edulcorant</th>\n",
       "      <th>poids_modifalim_pdtsalleges</th>\n",
       "      <th>poids_modifalim_BS</th>\n",
       "      <th>poids_modifalim_eau</th>\n",
       "      <th>poids_modifalim_autre</th>\n",
       "      <th>poids_perception</th>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <th>menopause</th>\n",
       "      <th>enceinte</th>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <th>allaite</th>\n",
       "      <th>allaite_nbsem</th>\n",
       "      <th>enceinte_12dermois</th>\n",
       "      <th>fume</th>\n",
       "      <th>nb_cigarettes_jour</th>\n",
       "      <th>nb_cigarettes_sem</th>\n",
       "      <th>nb_cigarettes_nsp</th>\n",
       "      <th>nb_cigares_jour</th>\n",
       "      <th>nb_cigares_sem</th>\n",
       "      <th>nb_cigares_nsp</th>\n",
       "      <th>nb_pipes_jour</th>\n",
       "      <th>nb_pipes_sem</th>\n",
       "      <th>nb_pipes_nsp</th>\n",
       "      <th>fume_age_debut</th>\n",
       "      <th>fume_age_debut_nsp</th>\n",
       "      <th>fume_age_arret</th>\n",
       "      <th>fume_age_arret_nsp</th>\n",
       "      <th>bmr_kcal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110100101</td>\n",
       "      <td>18.282312</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1378.0930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110100701</td>\n",
       "      <td>23.624619</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1352.7802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110100801</td>\n",
       "      <td>29.949701</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1630.9735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110101201</td>\n",
       "      <td>26.141914</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1749.4603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110101401</td>\n",
       "      <td>22.420361</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1090.1117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110101601</td>\n",
       "      <td>24.034611</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>110101901</td>\n",
       "      <td>26.258423</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110200101</td>\n",
       "      <td>26.592670</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110300301</td>\n",
       "      <td>20.939625</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>8.479999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1441.6642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>110300501</td>\n",
       "      <td>28.601023</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1655.5555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NOIND        imc  sex_PS  tage_PS  tage_PS_mois  diplome_interv  \\\n",
       "0  110100101  18.282312       1        7           NaN             7.0   \n",
       "1  110100701  23.624619       2        8           NaN             7.0   \n",
       "2  110100801  29.949701       1        8           NaN             7.0   \n",
       "3  110101201  26.141914       1        8           NaN            10.0   \n",
       "4  110101401  22.420361       2        9           NaN             7.0   \n",
       "5  110101601  24.034611       2        8           NaN             3.0   \n",
       "6  110101901  26.258423       1        7           NaN             9.0   \n",
       "7  110200101  26.592670       1        8           NaN            11.0   \n",
       "8  110300301  20.939625       1        8           NaN             7.0   \n",
       "9  110300501  28.601023       1        9           NaN             6.0   \n",
       "\n",
       "   etude_4cl_interv  situ_prof_5cl_interv  atrav_interv  trav_nuit_interv  \\\n",
       "0                 1                     3           2.0               NaN   \n",
       "1                 1                     1           NaN               4.0   \n",
       "2                 1                     1           NaN               4.0   \n",
       "3                 3                     1           NaN               4.0   \n",
       "4                 1                     4           1.0               NaN   \n",
       "5                 1                     1           NaN               4.0   \n",
       "6                 2                     1           NaN               4.0   \n",
       "7                 4                     1           NaN               4.0   \n",
       "8                 1                     2           1.0               NaN   \n",
       "9                 1                     4           1.0               NaN   \n",
       "\n",
       "   trav_nuit_2cl_interv  PCS_8cl_interv  PCS_4cl_interv  tps_travail_interv  \\\n",
       "0                   NaN               8               4                 NaN   \n",
       "1                   2.0               1               1                 2.0   \n",
       "2                   2.0               2               1                 1.0   \n",
       "3                   2.0               1               1                 1.0   \n",
       "4                   NaN               7               4                 1.0   \n",
       "5                   2.0               1               1                 1.0   \n",
       "6                   2.0               1               1                 1.0   \n",
       "7                   2.0               5               3                 1.0   \n",
       "8                   NaN               2               1                 1.0   \n",
       "9                   NaN               7               4                 1.0   \n",
       "\n",
       "   vacances_interv  soins  situ_fin_3cl  revenu  RUC_4cl  nbpers  nbadu  \\\n",
       "0                2      2             2      12      3.0       4      3   \n",
       "1                1      2             1      11      4.0       2      2   \n",
       "2                1      2             1      11      2.0       4      2   \n",
       "3                1      2             1      11      4.0       1      1   \n",
       "4                1      2             2       6      1.0       2      2   \n",
       "5                2      2             2      12      3.0       4      2   \n",
       "6                1      2             1      11      2.0       4      2   \n",
       "7                1      2             1      12      2.0       6      3   \n",
       "8                2      1             2       6      1.0       2      2   \n",
       "9                2      2             2       8      2.0       2      2   \n",
       "\n",
       "   nbenf  situ_alim_statut  IA_statut  IA_score  statnut  \\\n",
       "0      1                 1          0       NaN      0.0   \n",
       "1      0                 1          0       NaN      1.0   \n",
       "2      2                 1          0       NaN      3.0   \n",
       "3      0                 1          0       NaN      3.0   \n",
       "4      0                 1          0       NaN      1.0   \n",
       "5      2                 1          0       NaN      1.0   \n",
       "6      2                 1          0       NaN      3.0   \n",
       "7      3                 1          0  2.860000      3.0   \n",
       "8      0                 3          2  8.479999      1.0   \n",
       "9      0                 2          0       NaN      3.0   \n",
       "\n",
       "   maladie_allergie_alim  intoall_confirm_med  regime_vegetarien  \\\n",
       "0                    0.0                  NaN                0.0   \n",
       "1                    0.0                  NaN                0.0   \n",
       "2                    0.0                  NaN                0.0   \n",
       "3                    0.0                  NaN                0.0   \n",
       "4                    0.0                  NaN                0.0   \n",
       "5                    0.0                  NaN                0.0   \n",
       "6                    0.0                  NaN                0.0   \n",
       "7                    NaN                  NaN                NaN   \n",
       "8                    0.0                  NaN                0.0   \n",
       "9                    0.0                  NaN                0.0   \n",
       "\n",
       "   regime_allergie  regime_maigrir_med  regime_maigrir_choix  \\\n",
       "0              0.0                 0.0                   0.0   \n",
       "1              0.0                 0.0                   0.0   \n",
       "2              0.0                 0.0                   0.0   \n",
       "3              0.0                 0.0                   0.0   \n",
       "4              0.0                 0.0                   0.0   \n",
       "5              0.0                 0.0                   0.0   \n",
       "6              0.0                 0.0                   0.0   \n",
       "7              NaN                 NaN                   NaN   \n",
       "8              0.0                 0.0                   0.0   \n",
       "9              0.0                 0.0                   0.0   \n",
       "\n",
       "   regime_autre_med  regime_poidsstable  regime_forme  regime_autreraison  \\\n",
       "0               0.0                 0.0           0.0                 0.0   \n",
       "1               0.0                 0.0           0.0                 0.0   \n",
       "2               0.0                 0.0           0.0                 0.0   \n",
       "3               0.0                 0.0           0.0                 0.0   \n",
       "4               0.0                 0.0           0.0                 0.0   \n",
       "5               0.0                 0.0           0.0                 0.0   \n",
       "6               0.0                 0.0           0.0                 0.0   \n",
       "7               NaN                 NaN           NaN                 NaN   \n",
       "8               0.0                 0.0           0.0                 0.0   \n",
       "9               0.0                 0.0           0.0                 0.0   \n",
       "\n",
       "   regime_non  veget_viande  veget_prodmer  veget_prodlait  veget_oeuf  \\\n",
       "0         1.0           0.0            0.0             0.0         0.0   \n",
       "1         1.0           0.0            0.0             0.0         0.0   \n",
       "2         1.0           0.0            0.0             0.0         0.0   \n",
       "3         1.0           0.0            0.0             0.0         0.0   \n",
       "4         1.0           0.0            0.0             0.0         0.0   \n",
       "5         1.0           0.0            0.0             0.0         0.0   \n",
       "6         1.0           0.0            0.0             0.0         0.0   \n",
       "7         NaN           NaN            NaN             NaN         NaN   \n",
       "8         1.0           0.0            0.0             0.0         0.0   \n",
       "9         1.0           0.0            0.0             0.0         0.0   \n",
       "\n",
       "   veget_miel  veget_autre_alim  allergie_laitvache  allergie_prepainfsoja  \\\n",
       "0         0.0               0.0                 0.0                    0.0   \n",
       "1         0.0               0.0                 0.0                    0.0   \n",
       "2         0.0               0.0                 0.0                    0.0   \n",
       "3         0.0               0.0                 0.0                    0.0   \n",
       "4         0.0               0.0                 0.0                    0.0   \n",
       "5         0.0               0.0                 0.0                    0.0   \n",
       "6         0.0               0.0                 0.0                    0.0   \n",
       "7         NaN               NaN                 NaN                    NaN   \n",
       "8         0.0               0.0                 0.0                    0.0   \n",
       "9         0.0               0.0                 0.0                    0.0   \n",
       "\n",
       "   allergie_prepainfamande  allergie_gluten  allergie_farineble  \\\n",
       "0                      0.0              0.0                 0.0   \n",
       "1                      0.0              0.0                 0.0   \n",
       "2                      0.0              0.0                 0.0   \n",
       "3                      0.0              0.0                 0.0   \n",
       "4                      0.0              0.0                 0.0   \n",
       "5                      0.0              0.0                 0.0   \n",
       "6                      0.0              0.0                 0.0   \n",
       "7                      NaN              NaN                 NaN   \n",
       "8                      0.0              0.0                 0.0   \n",
       "9                      0.0              0.0                 0.0   \n",
       "\n",
       "   allergie_lupin  allergie_arachide  allergie_fruitcoque  allergie_oeuf  \\\n",
       "0             0.0                0.0                  0.0            0.0   \n",
       "1             0.0                0.0                  0.0            0.0   \n",
       "2             0.0                0.0                  0.0            0.0   \n",
       "3             0.0                0.0                  0.0            0.0   \n",
       "4             0.0                0.0                  0.0            0.0   \n",
       "5             0.0                0.0                  0.0            0.0   \n",
       "6             0.0                0.0                  0.0            0.0   \n",
       "7             NaN                NaN                  NaN            NaN   \n",
       "8             0.0                0.0                  0.0            0.0   \n",
       "9             0.0                0.0                  0.0            0.0   \n",
       "\n",
       "   allergie_poisson  allergie_crustace  allergie_mollusque  allergie_soja  \\\n",
       "0               0.0                0.0                 0.0            0.0   \n",
       "1               0.0                0.0                 0.0            0.0   \n",
       "2               0.0                0.0                 0.0            0.0   \n",
       "3               0.0                0.0                 0.0            0.0   \n",
       "4               0.0                0.0                 0.0            0.0   \n",
       "5               0.0                0.0                 0.0            0.0   \n",
       "6               0.0                0.0                 0.0            0.0   \n",
       "7               NaN                NaN                 NaN            NaN   \n",
       "8               0.0                0.0                 0.0            0.0   \n",
       "9               0.0                0.0                 0.0            0.0   \n",
       "\n",
       "   allergie_sesame  allergie_moutarde  allergie_sulfite  allergie_celeri  \\\n",
       "0              0.0                0.0               0.0              0.0   \n",
       "1              0.0                0.0               0.0              0.0   \n",
       "2              0.0                0.0               0.0              0.0   \n",
       "3              0.0                0.0               0.0              0.0   \n",
       "4              0.0                0.0               0.0              0.0   \n",
       "5              0.0                0.0               0.0              0.0   \n",
       "6              0.0                0.0               0.0              0.0   \n",
       "7              NaN                NaN               NaN              NaN   \n",
       "8              0.0                0.0               0.0              0.0   \n",
       "9              0.0                0.0               0.0              0.0   \n",
       "\n",
       "   allergie_autres_fruitleg  allergie_autresalim  allergie_nondetermine  \\\n",
       "0                       0.0                  0.0                    0.0   \n",
       "1                       0.0                  0.0                    0.0   \n",
       "2                       0.0                  0.0                    0.0   \n",
       "3                       0.0                  0.0                    0.0   \n",
       "4                       0.0                  0.0                    0.0   \n",
       "5                       0.0                  0.0                    0.0   \n",
       "6                       0.0                  0.0                    0.0   \n",
       "7                       NaN                  NaN                    NaN   \n",
       "8                       0.0                  0.0                    0.0   \n",
       "9                       0.0                  0.0                    0.0   \n",
       "\n",
       "   allergie_fruits  allergie_legumes  regime_passe  regime_nb_2dernann  \\\n",
       "0              0.0               0.0           2.0                 NaN   \n",
       "1              0.0               0.0           2.0                 NaN   \n",
       "2              0.0               0.0           2.0                 NaN   \n",
       "3              0.0               0.0           2.0                 NaN   \n",
       "4              0.0               0.0           2.0                 NaN   \n",
       "5              0.0               0.0           NaN                 NaN   \n",
       "6              0.0               0.0           2.0                 NaN   \n",
       "7              NaN               NaN           NaN                 NaN   \n",
       "8              0.0               0.0           2.0                 NaN   \n",
       "9              0.0               0.0           2.0                 NaN   \n",
       "\n",
       "   regime_nb_anter2dernann  regime_type  regime_duree_sem  regime_duree_mois  \\\n",
       "0                      NaN          NaN               NaN                NaN   \n",
       "1                      NaN          NaN               NaN                NaN   \n",
       "2                      NaN          NaN               NaN                NaN   \n",
       "3                      NaN          NaN               NaN                NaN   \n",
       "4                      NaN          NaN               NaN                NaN   \n",
       "5                      NaN          NaN               NaN                NaN   \n",
       "6                      NaN          NaN               NaN                NaN   \n",
       "7                      NaN          NaN               NaN                NaN   \n",
       "8                      NaN          NaN               NaN                NaN   \n",
       "9                      NaN          NaN               NaN                NaN   \n",
       "\n",
       "   regime_duree_nsp  poids_modif  poids_modifalim  poids_plusAP  \\\n",
       "0               NaN          4.0              NaN           NaN   \n",
       "1               NaN          2.0              0.0           1.0   \n",
       "2               NaN          4.0              NaN           NaN   \n",
       "3               NaN          4.0              NaN           NaN   \n",
       "4               NaN          4.0              NaN           NaN   \n",
       "5               NaN          NaN              NaN           NaN   \n",
       "6               NaN          4.0              NaN           NaN   \n",
       "7               NaN          NaN              NaN           NaN   \n",
       "8               NaN          4.0              NaN           NaN   \n",
       "9               NaN          NaN              NaN           NaN   \n",
       "\n",
       "   poids_medicaments  poids_substituts  poids_chirurgie  \\\n",
       "0                NaN               NaN              NaN   \n",
       "1                0.0               0.0              0.0   \n",
       "2                NaN               NaN              NaN   \n",
       "3                NaN               NaN              NaN   \n",
       "4                NaN               NaN              NaN   \n",
       "5                NaN               NaN              NaN   \n",
       "6                NaN               NaN              NaN   \n",
       "7                NaN               NaN              NaN   \n",
       "8                NaN               NaN              NaN   \n",
       "9                NaN               NaN              NaN   \n",
       "\n",
       "   poids_modifalim_laityaourt  poids_modifalim_fromage  poids_modifalim_mg  \\\n",
       "0                         NaN                      NaN                 NaN   \n",
       "1                         NaN                      NaN                 NaN   \n",
       "2                         NaN                      NaN                 NaN   \n",
       "3                         NaN                      NaN                 NaN   \n",
       "4                         NaN                      NaN                 NaN   \n",
       "5                         NaN                      NaN                 NaN   \n",
       "6                         NaN                      NaN                 NaN   \n",
       "7                         NaN                      NaN                 NaN   \n",
       "8                         NaN                      NaN                 NaN   \n",
       "9                         NaN                      NaN                 NaN   \n",
       "\n",
       "   poids_modifalim_fruit  poids_modifalim_legume  poids_modifalim_pdtfeculent  \\\n",
       "0                    NaN                     NaN                          NaN   \n",
       "1                    NaN                     NaN                          NaN   \n",
       "2                    NaN                     NaN                          NaN   \n",
       "3                    NaN                     NaN                          NaN   \n",
       "4                    NaN                     NaN                          NaN   \n",
       "5                    NaN                     NaN                          NaN   \n",
       "6                    NaN                     NaN                          NaN   \n",
       "7                    NaN                     NaN                          NaN   \n",
       "8                    NaN                     NaN                          NaN   \n",
       "9                    NaN                     NaN                          NaN   \n",
       "\n",
       "   poids_modifalim_pizza  poids_modifalim_pain  poids_modifalim_vrouge  \\\n",
       "0                    NaN                   NaN                     NaN   \n",
       "1                    NaN                   NaN                     NaN   \n",
       "2                    NaN                   NaN                     NaN   \n",
       "3                    NaN                   NaN                     NaN   \n",
       "4                    NaN                   NaN                     NaN   \n",
       "5                    NaN                   NaN                     NaN   \n",
       "6                    NaN                   NaN                     NaN   \n",
       "7                    NaN                   NaN                     NaN   \n",
       "8                    NaN                   NaN                     NaN   \n",
       "9                    NaN                   NaN                     NaN   \n",
       "\n",
       "   poids_modifalim_volaille  poids_modifalim_oeuf  poids_modifalim_gateau  \\\n",
       "0                       NaN                   NaN                     NaN   \n",
       "1                       NaN                   NaN                     NaN   \n",
       "2                       NaN                   NaN                     NaN   \n",
       "3                       NaN                   NaN                     NaN   \n",
       "4                       NaN                   NaN                     NaN   \n",
       "5                       NaN                   NaN                     NaN   \n",
       "6                       NaN                   NaN                     NaN   \n",
       "7                       NaN                   NaN                     NaN   \n",
       "8                       NaN                   NaN                     NaN   \n",
       "9                       NaN                   NaN                     NaN   \n",
       "\n",
       "   poids_modifalim_edulcorant  poids_modifalim_pdtsalleges  \\\n",
       "0                         NaN                          NaN   \n",
       "1                         NaN                          NaN   \n",
       "2                         NaN                          NaN   \n",
       "3                         NaN                          NaN   \n",
       "4                         NaN                          NaN   \n",
       "5                         NaN                          NaN   \n",
       "6                         NaN                          NaN   \n",
       "7                         NaN                          NaN   \n",
       "8                         NaN                          NaN   \n",
       "9                         NaN                          NaN   \n",
       "\n",
       "   poids_modifalim_BS  poids_modifalim_eau  poids_modifalim_autre  \\\n",
       "0                 NaN                  NaN                    NaN   \n",
       "1                 NaN                  NaN                    NaN   \n",
       "2                 NaN                  NaN                    NaN   \n",
       "3                 NaN                  NaN                    NaN   \n",
       "4                 NaN                  NaN                    NaN   \n",
       "5                 NaN                  NaN                    NaN   \n",
       "6                 NaN                  NaN                    NaN   \n",
       "7                 NaN                  NaN                    NaN   \n",
       "8                 NaN                  NaN                    NaN   \n",
       "9                 NaN                  NaN                    NaN   \n",
       "\n",
       "   poids_perception  nb_prise_10kg  menopause  enceinte  enceinte_nbmois  \\\n",
       "0               1.0            NaN        NaN       NaN              NaN   \n",
       "1               2.0            4.0        1.0       NaN              NaN   \n",
       "2               2.0            4.0        NaN       NaN              NaN   \n",
       "3               2.0            4.0        NaN       NaN              NaN   \n",
       "4               1.0            5.0        1.0       NaN              NaN   \n",
       "5               NaN            NaN        NaN       NaN              NaN   \n",
       "6               1.0            3.0        NaN       NaN              NaN   \n",
       "7               NaN            NaN        NaN       NaN              NaN   \n",
       "8               1.0            3.0        NaN       NaN              NaN   \n",
       "9               1.0            NaN        NaN       NaN              NaN   \n",
       "\n",
       "   allaite  allaite_nbsem  enceinte_12dermois  fume  nb_cigarettes_jour  \\\n",
       "0      NaN            NaN                 NaN   4.0                 NaN   \n",
       "1      NaN            NaN                 NaN   4.0                 NaN   \n",
       "2      NaN            NaN                 NaN   3.0                15.0   \n",
       "3      NaN            NaN                 NaN   4.0                 NaN   \n",
       "4      NaN            NaN                 NaN   4.0                 NaN   \n",
       "5      NaN            NaN                 NaN   NaN                 NaN   \n",
       "6      NaN            NaN                 NaN   4.0                 NaN   \n",
       "7      NaN            NaN                 NaN   NaN                 NaN   \n",
       "8      NaN            NaN                 NaN   1.0                 NaN   \n",
       "9      NaN            NaN                 NaN   3.0                 5.0   \n",
       "\n",
       "   nb_cigarettes_sem  nb_cigarettes_nsp  nb_cigares_jour  nb_cigares_sem  \\\n",
       "0                NaN                NaN              NaN             NaN   \n",
       "1                NaN                NaN              NaN             NaN   \n",
       "2                NaN                NaN              0.0             NaN   \n",
       "3                NaN                NaN              NaN             NaN   \n",
       "4                NaN                NaN              NaN             NaN   \n",
       "5                NaN                NaN              NaN             NaN   \n",
       "6                NaN                NaN              NaN             NaN   \n",
       "7                NaN                NaN              NaN             NaN   \n",
       "8               40.0                NaN              0.0             NaN   \n",
       "9                NaN                NaN              0.0             NaN   \n",
       "\n",
       "   nb_cigares_nsp  nb_pipes_jour  nb_pipes_sem  nb_pipes_nsp  fume_age_debut  \\\n",
       "0             NaN            NaN           NaN           NaN             NaN   \n",
       "1             NaN            NaN           NaN           NaN             NaN   \n",
       "2             NaN            0.0           NaN           NaN            25.0   \n",
       "3             NaN            NaN           NaN           NaN             NaN   \n",
       "4             NaN            NaN           NaN           NaN             NaN   \n",
       "5             NaN            NaN           NaN           NaN             NaN   \n",
       "6             NaN            NaN           NaN           NaN             NaN   \n",
       "7             NaN            NaN           NaN           NaN             NaN   \n",
       "8             NaN            0.0           NaN           NaN            16.0   \n",
       "9             NaN            0.0           NaN           NaN            20.0   \n",
       "\n",
       "   fume_age_debut_nsp  fume_age_arret  fume_age_arret_nsp   bmr_kcal  \n",
       "0                 NaN             NaN                 NaN  1378.0930  \n",
       "1                 NaN             NaN                 NaN  1352.7802  \n",
       "2                 NaN            33.0                 NaN  1630.9735  \n",
       "3                 NaN             NaN                 NaN  1749.4603  \n",
       "4                 NaN             NaN                 NaN  1090.1117  \n",
       "5                 NaN             NaN                 NaN        NaN  \n",
       "6                 NaN             NaN                 NaN        NaN  \n",
       "7                 NaN             NaN                 NaN        NaN  \n",
       "8                 NaN             NaN                 NaN  1441.6642  \n",
       "9                 NaN            46.0                 NaN  1655.5555  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "930d210c-24a0-4d8e-950e-d52dbaed3fae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_967/2518340673.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/mamba/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5985\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5986\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'summary'"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3928811b-7859-45c9-a142-d7d5778a07f5",
   "metadata": {},
   "source": [
    "Tout d'abord, commençons par définir quelques constantes qui nous seront utiles pour la suite, à savoir : \n",
    "- La variable d'intérêt que nous cherchons à prédire `TARGET_VARIABLE`\n",
    "- La variable correspondant au numéro d'individu `NOIND`\n",
    "- Un nombre arbitraire pour afin de simplifier la réplicabilité de nos expérimentations `SEED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3502292a-6e00-4d01-bf34-50a729fbc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VARIABLE=\"imc\"\n",
    "INDEX=\"NOIND\"\n",
    "SEED=2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6385ae65-600a-4deb-8f16-e5fcc57b42cc",
   "metadata": {},
   "source": [
    "**Question 1:** Comme souvent en science de la données, la partie la plus fastidieuse consiste à analyser les données à notre disposition. En vous aidant du dictionnaire accessible [ici](https://static.data.gouv.fr/resources/donnees-de-consommations-et-habitudes-alimentaires-de-letude-inca-3/20210128-192017/notice-utilisateurs-donnees-inca3-data.gouvjanv21.pdf) déterminer l'ensemble des variables numériques. Les autres variables seront considérées comme des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "16315a70-0c33-4c63-aa95-36e3d2382fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex_PS',\n",
       " 'tage_PS',\n",
       " 'tage_PS_mois',\n",
       " 'diplome_interv',\n",
       " 'etude_4cl_interv',\n",
       " 'situ_prof_5cl_interv',\n",
       " 'atrav_interv',\n",
       " 'trav_nuit_interv',\n",
       " 'trav_nuit_2cl_interv',\n",
       " 'PCS_8cl_interv',\n",
       " 'PCS_4cl_interv',\n",
       " 'tps_travail_interv',\n",
       " 'vacances_interv',\n",
       " 'soins',\n",
       " 'situ_fin_3cl',\n",
       " 'revenu',\n",
       " 'RUC_4cl',\n",
       " 'nbpers',\n",
       " 'nbadu',\n",
       " 'nbenf',\n",
       " 'situ_alim_statut',\n",
       " 'IA_statut',\n",
       " 'IA_score',\n",
       " 'statnut',\n",
       " 'maladie_allergie_alim',\n",
       " 'intoall_confirm_med',\n",
       " 'regime_vegetarien',\n",
       " 'regime_allergie',\n",
       " 'regime_maigrir_med',\n",
       " 'regime_maigrir_choix',\n",
       " 'regime_autre_med',\n",
       " 'regime_poidsstable',\n",
       " 'regime_forme',\n",
       " 'regime_autreraison',\n",
       " 'regime_non',\n",
       " 'veget_viande',\n",
       " 'veget_prodmer',\n",
       " 'veget_prodlait',\n",
       " 'veget_oeuf',\n",
       " 'veget_miel',\n",
       " 'veget_autre_alim',\n",
       " 'allergie_laitvache',\n",
       " 'allergie_prepainfsoja',\n",
       " 'allergie_prepainfamande',\n",
       " 'allergie_gluten',\n",
       " 'allergie_farineble',\n",
       " 'allergie_lupin',\n",
       " 'allergie_arachide',\n",
       " 'allergie_fruitcoque',\n",
       " 'allergie_oeuf',\n",
       " 'allergie_poisson',\n",
       " 'allergie_crustace',\n",
       " 'allergie_mollusque',\n",
       " 'allergie_soja',\n",
       " 'allergie_sesame',\n",
       " 'allergie_moutarde',\n",
       " 'allergie_sulfite',\n",
       " 'allergie_celeri',\n",
       " 'allergie_autres_fruitleg',\n",
       " 'allergie_autresalim',\n",
       " 'allergie_nondetermine',\n",
       " 'allergie_fruits',\n",
       " 'allergie_legumes',\n",
       " 'regime_passe',\n",
       " 'regime_nb_2dernann',\n",
       " 'regime_nb_anter2dernann',\n",
       " 'regime_type',\n",
       " 'regime_duree_sem',\n",
       " 'regime_duree_mois',\n",
       " 'regime_duree_nsp',\n",
       " 'poids_modif',\n",
       " 'poids_modifalim',\n",
       " 'poids_plusAP',\n",
       " 'poids_medicaments',\n",
       " 'poids_substituts',\n",
       " 'poids_chirurgie',\n",
       " 'poids_modifalim_laityaourt',\n",
       " 'poids_modifalim_fromage',\n",
       " 'poids_modifalim_mg',\n",
       " 'poids_modifalim_fruit',\n",
       " 'poids_modifalim_legume',\n",
       " 'poids_modifalim_pdtfeculent',\n",
       " 'poids_modifalim_pizza',\n",
       " 'poids_modifalim_pain',\n",
       " 'poids_modifalim_vrouge',\n",
       " 'poids_modifalim_volaille',\n",
       " 'poids_modifalim_oeuf',\n",
       " 'poids_modifalim_gateau',\n",
       " 'poids_modifalim_edulcorant',\n",
       " 'poids_modifalim_pdtsalleges',\n",
       " 'poids_modifalim_BS',\n",
       " 'poids_modifalim_eau',\n",
       " 'poids_modifalim_autre',\n",
       " 'poids_perception',\n",
       " 'nb_prise_10kg',\n",
       " 'menopause',\n",
       " 'enceinte',\n",
       " 'enceinte_nbmois',\n",
       " 'allaite',\n",
       " 'allaite_nbsem',\n",
       " 'enceinte_12dermois',\n",
       " 'fume',\n",
       " 'nb_cigarettes_jour',\n",
       " 'nb_cigarettes_sem',\n",
       " 'nb_cigarettes_nsp',\n",
       " 'nb_cigares_jour',\n",
       " 'nb_cigares_sem',\n",
       " 'nb_cigares_nsp',\n",
       " 'nb_pipes_jour',\n",
       " 'nb_pipes_sem',\n",
       " 'nb_pipes_nsp',\n",
       " 'fume_age_debut',\n",
       " 'fume_age_debut_nsp',\n",
       " 'fume_age_arret',\n",
       " 'fume_age_arret_nsp',\n",
       " 'bmr_kcal']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERICAL = [ x for x in df.select_dtypes(include=['int','float64']).columns.tolist() if x not in[INDEX, TARGET_VARIABLE] ]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE] ]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "\n",
    "NUMERICAL\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daf73d0d-8900-49b3-9713-8ad00ef090b2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "32cd6e55-b8ba-4444-ab18-b87f0db8f5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IA_score',\n",
       " 'bmr_kcal',\n",
       " 'nbenf',\n",
       " 'enceinte_nbmois',\n",
       " 'nb_cigarettes_jour',\n",
       " 'nb_cigarettes_sem',\n",
       " 'nb_cigares_jour',\n",
       " 'nb_cigares_sem',\n",
       " 'nb_pipes_jour',\n",
       " 'nb_pipes_sem',\n",
       " 'fume_age_debut',\n",
       " 'fume_age_arret',\n",
       " 'allaite_nbsem',\n",
       " 'regime_nb_2dernann',\n",
       " 'regime_nb_anter2dernann']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUMERICAL = [\n",
    "    \"IA_score\",\n",
    "    \"bmr_kcal\",\n",
    "    'nbenf',\n",
    "    \"enceinte_nbmois\",\n",
    "    'nb_cigarettes_jour',\n",
    "    'nb_cigarettes_sem',\n",
    "    'nb_cigares_jour',\n",
    "    'nb_cigares_sem',\n",
    "    'nb_pipes_jour',\n",
    "    'nb_pipes_sem',\n",
    "    'fume_age_debut',\n",
    "    'fume_age_arret',\n",
    "    'allaite_nbsem',\n",
    "    \"regime_nb_2dernann\",\n",
    "    \"regime_nb_anter2dernann\"\n",
    "]\n",
    "\n",
    "CATEGORICAL = [x for x in df.columns if x not in NUMERICAL + [INDEX, TARGET_VARIABLE]]\n",
    "\n",
    "FEATURES = NUMERICAL + CATEGORICAL\n",
    "\n",
    "NUMERICAL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a83ec8bd-de7b-40ea-85d2-855b8e3dfac5",
   "metadata": {},
   "source": [
    "Une pratique courante dans les projets de machine learning c'est de commencer par spécifier une fraction de notre jeu données comme un **échantillon de test**. Cet échantillon va être utilisé à la toute fin du projet de sorte à évaluer la performance de nos modèles sur des données qu'il n'aura jamais vu auparavant. L'échantillon restant, celui **d'entrainement**, est lui utilisé pour entrainer les algorithmes et comparer leurs performances. L'idée derrière cette division est de réduire le risque de sur-apprentissage de notre modèle et d'estimer une erreur de généralisation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1878fd3d-2e4d-4c6d-b76e-115f15685ef7",
   "metadata": {},
   "source": [
    "**Question 2:** Créer les variables `y` et `X` correspondant respectivement à la variable d'intérêt et aux différentes features de notre jeu de données. Diviser ensuite ce jeu de données en un échantillon de train et de test en utilisant la fonction `train_test_split` de [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). Ne pas oublier de spécifier le `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "57ba0bd2-52df-4142-b052-6899e0c94426",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# VOTRE CODE\n",
    "y = df[TARGET_VARIABLE]\n",
    "X = df[FEATURES]\n",
    "\n",
    "y.head()\n",
    "X.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2da58e23-bd89-4cab-bc00-b6762aea8c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       18.282312\n",
       "1       23.624619\n",
       "2       29.949701\n",
       "3       26.141914\n",
       "4       22.420361\n",
       "          ...    \n",
       "5850    18.099375\n",
       "5851    14.955483\n",
       "5852    20.687473\n",
       "5853    20.538029\n",
       "5854    18.827110\n",
       "Name: imc, Length: 5841, dtype: float64"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c575abf7-3a48-4086-82f2-7b859163cd27",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[FEATURES]\n",
    "y = df[TARGET_VARIABLE]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d528062-037f-42f7-8d79-c7fdd8470daf",
   "metadata": {},
   "source": [
    "### 2. Un modèle de régression linéaire simple"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33d45ab5-c5f0-41ff-b900-97a969a2c528",
   "metadata": {},
   "source": [
    "**Question 3:** Avant d'étudier différentes méthodes d'apprentissage statistique commençons par réaliser une régression linéaire classique. Pour cela, sélectionnez un petit nombre de variables $(< 10)$ qui vous semble pertinent pour prédire l'indice de masse corporelle d'une personne. Prenez à la fois des variables numériques et catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6afcecbb-2fab-43b0-8c71-f282c615e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "    \"poids_perception\" ,\n",
    "    \"enceinte\",\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92c0628b-9bad-499b-bdf1-c397ca8de899",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "CATEGORICAL_REGRESSION = [\n",
    "    \"sex_PS\",\n",
    "    \"tage_PS\",\n",
    "    \"revenu\",\n",
    "    \"situ_alim_statut\",\n",
    "    \"poids_perception\" ,\n",
    "    \"enceinte\",\n",
    "]\n",
    "\n",
    "NUMERICAL_REGRESSION = [\n",
    "    \"IA_score\",\n",
    "    \"enceinte_nbmois\",\n",
    "    \"nb_prise_10kg\"\n",
    "]\n",
    "\n",
    "FEATURES_REGRESSION = NUMERICAL_REGRESSION + CATEGORICAL_REGRESSION\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d61095c4-62c0-4ab7-95cf-7044fb57f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regression = X_train[FEATURES_REGRESSION]\n",
    "X_test_regression = X_test[FEATURES_REGRESSION]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "41490ec7-609d-44dc-9b53-2af8ea153a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4672 entries, 4763 to 4962\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   IA_score          781 non-null    float64\n",
      " 1   enceinte_nbmois   14 non-null     float64\n",
      " 2   nb_prise_10kg     1699 non-null   float64\n",
      " 3   sex_PS            4672 non-null   int64  \n",
      " 4   tage_PS           4672 non-null   int64  \n",
      " 5   revenu            4672 non-null   int64  \n",
      " 6   situ_alim_statut  4672 non-null   int64  \n",
      " 7   poids_perception  2572 non-null   float64\n",
      " 8   enceinte          666 non-null    float64\n",
      "dtypes: float64(5), int64(4)\n",
      "memory usage: 365.0 KB\n"
     ]
    }
   ],
   "source": [
    "X_train_regression.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3a026d11-ea40-4ff6-889e-2338e13a6611",
   "metadata": {},
   "source": [
    "Ces informations nous indiquent qu'il y a plusieurs variables qui contiennent des valeurs manquantes. Afin de ne pas supprimer les lignes qui contiennent des valeurs manquantes nous allons tenter de les imputer. Plusieurs méthodes d'imputations peuvent être réalisées :\n",
    "\n",
    "- **Pour les variables numériques:** Il est courant de remplacer les variables manquantes par la moyenne ou la médiane de l'échantillon.\n",
    "- **Pour les variables catégorielles:** On peut remplacer les variables manquantes par le moden c'est à dire la valeur la plus fréquente dans l'échantillon ou en créant une nouvelle categorie reflétant une valeur manquante.\n",
    "\n",
    "D'autres méthodes qui requiert plus de modélisation sont également possible comme réaliser une régression afin de prédire les valeurs manquantes grâce aux autres features ou  utiliser un algorithme de K plus proche voisin. Toutes ces méthodes ont à la fois leurs avantages et leurs inconvénients, il est important de déterminer celle qui est la plus approprié pour le problème que vous souhaitez résoudre."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68770063-c3c2-4926-b47d-2fd7e7da41e7",
   "metadata": {},
   "source": [
    "**Question 4:** Pour faire simple, nous allons remplacer les valeurs manquantes des variables numériques par la médiane et pour celles des variables catégorielles nous allons créer une nouvelle catégorie qui sera égale à $-1$. Ce dernier choix vous semble t-il approprié ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "10a08843-d7f8-436f-9dde-6e6f40665ed1",
   "metadata": {},
   "source": [
    "**Question 5:** En vous aidant de la (documentation)[https://scikit-learn.org/stable/modules/classes.html#module-sklearn.impute] de scikit learn , créez ces deux *Imputer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "a9eedbf8-0a59-49e3-b323-96d7ec45e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b476aa35-f8cd-4239-88b0-9ea55b52bfce",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "544fa445-5c3f-40e0-a18d-685010b7beac",
   "metadata": {},
   "source": [
    "**Question 6:** Analysez les modalités de la variables `enceinte_nbmois`, une imputation par la moyenne vous semble-t-elle justifiée ? Si non, proposez une autre imputation. Existe t-il d'autres variables dans ce cas ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d913d7ba-a56d-48c9-8d6c-2660d2adf3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f05ba2-c495-4bd8-a452-e67388c02f36",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pd.unique(X_train_regression[\"enceinte_nbmois\"])\n",
    "```\n",
    "\n",
    "```python\n",
    "# Les valeurs manquantes correspondent plutôt à la modalité \"pas enceinte\", il est donc plus judicieux de remplacer les valeurs manquantes par 0.\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2081de6-121f-4af7-b2cd-d2ec0f5cbafb",
   "metadata": {},
   "source": [
    "Une étape très importante lorsqu'on utilise des méthodes de machine learning est la standardisation des données afin de mettre toutes les variables à la même échelle. Lorsque les variables ont des échelles différentes, certaines peuvent dominer les autres dans le processus d'apprentissage, ce qui peut fausser les résultats. Plusieurs méthodes de standardisation peuvent être utilisées, les deux plus courantes sont: \n",
    "- la normalisation standard : $z = \\frac{x - \\bar{x}}{\\sigma}$\n",
    "- la normalisation 0-1 : $z = \\frac{x - min}{max - min}$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "211b548b-d09d-47ca-ac37-6b990bba0f52",
   "metadata": {},
   "source": [
    "Nous pouvons donc créer une pipeline dans laquelle nos *features* passeront afin de subir diverses transformations. En l'occurence, nous souhaitons que nos les valeurs manquantes *features* soient imputées et que ces dernières soit standardisées. Pour cela nous pouvons utiliser la fonction `make_pipeline`. Pour le *scaler* nous allons utiliser la normalisation standard qui peut être réalisée grâce à la méthode `StandardScaler()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f1dc6264-cb07-4f5c-81b7-c47ba9a6f2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8931151-ead6-4681-aab1-a9d2760b9bfa",
   "metadata": {},
   "source": [
    "Une fois nos *pipelines* définies ils faut déterminer quelles *features* passent par quelles *pipelines*. Dans notre cas, on souhaite que les variables catégorielles traversent la pipeline qui impute les valeurs manquantes par $-1$ et les variables numériques par la pipeline qui impute soit par la médiane, soit par 0. Pour cela on doit utiliser la fonction `ColumnTransformer`. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fd7f237-434d-4765-9c1a-66a006be2c4f",
   "metadata": {},
   "source": [
    "**Question 7:** En vous référant à la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) de la fonction, créez votre pipeline de preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5d747536-394d-4f92-be80-7b0e4b8f6afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f39bcfbb-8c9a-486b-ae75-db073db0eb58",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor_regression = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, [\"enceinte_nbmois\", \"nb_prise_10kg\"]),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL_REGRESSION if x not in  [\"enceinte_nbmois\", \"nb_prise_10kg\"]]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL_REGRESSION)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c19dcf20-277b-46ab-a1e0-6dff3a32219a",
   "metadata": {},
   "source": [
    "Maintenant que nos étapes de *preprocessing* sont définies, on peut les réaliser et observer les changements qui ont été opéré sur notre jeu de données afin de vérifier que les modifications ont bien été faites comme attendues. Pour cela, commencons par observer notre échantillon d'entrainement initial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "750c7b79-9826-4a7e-8160-67576bca4cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IA_score</th>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <th>sex_PS</th>\n",
       "      <th>tage_PS</th>\n",
       "      <th>revenu</th>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <th>poids_perception</th>\n",
       "      <th>enceinte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4763</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4655</th>\n",
       "      <td>2.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3429</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>2.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4442</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3923</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3670</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      IA_score  enceinte_nbmois  nb_prise_10kg  sex_PS  tage_PS  revenu  \\\n",
       "4763       NaN              NaN            NaN       2        9      15   \n",
       "4655      2.86              NaN            NaN       1        7       5   \n",
       "3429       NaN              NaN            NaN       1        6      15   \n",
       "3965      2.86              NaN            2.0       2        8       7   \n",
       "4442       NaN              NaN            NaN       1        4      12   \n",
       "3923       NaN              NaN            3.0       1        7      11   \n",
       "1065       NaN              NaN            NaN       2        4      13   \n",
       "3670       NaN              NaN            4.0       2        7       7   \n",
       "808        NaN              NaN            NaN       1        6      10   \n",
       "2077       NaN              NaN            NaN       2        5       5   \n",
       "\n",
       "      situ_alim_statut  poids_perception  enceinte  \n",
       "4763                 1               NaN       NaN  \n",
       "4655                 2               NaN       NaN  \n",
       "3429                 1               NaN       NaN  \n",
       "3965                 1               2.0       2.0  \n",
       "4442                 1               NaN       NaN  \n",
       "3923                 1               3.0       NaN  \n",
       "1065                 1               NaN       NaN  \n",
       "3670                 2               1.0       2.0  \n",
       "808                  2               1.0       NaN  \n",
       "2077                 1               1.0       NaN  "
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_regression.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5136a929-719a-4a84-88fe-db37876457f2",
   "metadata": {},
   "source": [
    "Jusqu'à présent nous avons seulement définies les étapes de notre *preprocessing* mais celles ci n'ont pas été réalisées, pour cela nous devons `fit` notre preprocessing à notre jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "9a6a63ca-650e-46e6-822c-2a66c15fc62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_zero&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;enceinte_nbmois&#x27;, &#x27;nb_prise_10kg&#x27;]),\n",
       "                                (&#x27;numerical_median&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;IA_score&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=-1,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;sex_PS&#x27;, &#x27;tage_PS&#x27;, &#x27;revenu&#x27;,\n",
       "                                  &#x27;situ_alim_statut&#x27;, &#x27;poids_perception&#x27;,\n",
       "                                  &#x27;enceinte&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical_zero&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;enceinte_nbmois&#x27;, &#x27;nb_prise_10kg&#x27;]),\n",
       "                                (&#x27;numerical_median&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;IA_score&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;simpleimputer&#x27;,\n",
       "                                                  SimpleImputer(fill_value=-1,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;standardscaler&#x27;,\n",
       "                                                  StandardScaler())]),\n",
       "                                 [&#x27;sex_PS&#x27;, &#x27;tage_PS&#x27;, &#x27;revenu&#x27;,\n",
       "                                  &#x27;situ_alim_statut&#x27;, &#x27;poids_perception&#x27;,\n",
       "                                  &#x27;enceinte&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_zero</label><div class=\"sk-toggleable__content\"><pre>[&#x27;enceinte_nbmois&#x27;, &#x27;nb_prise_10kg&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=0, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical_median</label><div class=\"sk-toggleable__content\"><pre>[&#x27;IA_score&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;sex_PS&#x27;, &#x27;tage_PS&#x27;, &#x27;revenu&#x27;, &#x27;situ_alim_statut&#x27;, &#x27;poids_perception&#x27;, &#x27;enceinte&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value=-1, strategy=&#x27;constant&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('numerical_zero',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=0,\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['enceinte_nbmois', 'nb_prise_10kg']),\n",
       "                                ('numerical_median',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['IA_score']),\n",
       "                                ('categorical',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(fill_value=-1,\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 ['sex_PS', 'tage_PS', 'revenu',\n",
       "                                  'situ_alim_statut', 'poids_perception',\n",
       "                                  'enceinte'])])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_regression.fit(X_train_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "a032c6f5-c8f3-462f-bf61-22fba9a86983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['numerical_zero__enceinte_nbmois', 'numerical_zero__nb_prise_10kg',\n",
       "       'numerical_median__IA_score', 'categorical__sex_PS',\n",
       "       'categorical__tage_PS', 'categorical__revenu',\n",
       "       'categorical__situ_alim_statut', 'categorical__poids_perception',\n",
       "       'categorical__enceinte'], dtype=object)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor_regression.get_feature_names_out()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3c2e43a-92ee-4006-9d31-c6bd361d3409",
   "metadata": {},
   "source": [
    "`Scikit-learn` juxtapose automatiquement le nom de la transformation effectuée à la variable. Pour simplifier la comparaison nous allons supprimer ce qui a été rajouté en prefixe de sorte à retrouver les même nom de variable qu'initialement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "30b23a80-b5c1-4113-a246-656f695f3585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['enceinte_nbmois',\n",
       " 'nb_prise_10kg',\n",
       " 'IA_score',\n",
       " 'sex_PS',\n",
       " 'tage_PS',\n",
       " 'revenu',\n",
       " 'situ_alim_statut',\n",
       " 'poids_perception',\n",
       " 'enceinte']"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "original_feature_names = [re.sub(r'^.*__', '', item) for item in preprocessor_regression.get_feature_names_out()]\n",
    "original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c52ed3e7-5b44-4d7a-8267-8e538cbb2893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <th>IA_score</th>\n",
       "      <th>sex_PS</th>\n",
       "      <th>tage_PS</th>\n",
       "      <th>revenu</th>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <th>poids_perception</th>\n",
       "      <th>enceinte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>0.952742</td>\n",
       "      <td>1.355361</td>\n",
       "      <td>1.633466</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>-1.004860</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-1.635165</td>\n",
       "      <td>-1.049602</td>\n",
       "      <td>0.390153</td>\n",
       "      <td>-1.525420</td>\n",
       "      <td>1.634321</td>\n",
       "      <td>-1.004860</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>-1.049602</td>\n",
       "      <td>-0.092451</td>\n",
       "      <td>1.633466</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>-1.004860</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>0.396878</td>\n",
       "      <td>-1.635165</td>\n",
       "      <td>0.952742</td>\n",
       "      <td>0.872757</td>\n",
       "      <td>-0.893643</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>1.148345</td>\n",
       "      <td>2.466247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>-1.049602</td>\n",
       "      <td>-1.057659</td>\n",
       "      <td>0.685800</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>-1.004860</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>0.955544</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>-1.049602</td>\n",
       "      <td>0.390153</td>\n",
       "      <td>0.369912</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>1.866080</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>0.952742</td>\n",
       "      <td>-1.057659</td>\n",
       "      <td>1.001689</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>-1.004860</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>1.514211</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>0.952742</td>\n",
       "      <td>0.390153</td>\n",
       "      <td>-0.893643</td>\n",
       "      <td>1.634321</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>2.466247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>-1.049602</td>\n",
       "      <td>-0.092451</td>\n",
       "      <td>0.054023</td>\n",
       "      <td>1.634321</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.052955</td>\n",
       "      <td>-0.720455</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>0.952742</td>\n",
       "      <td>-0.575055</td>\n",
       "      <td>-1.525420</td>\n",
       "      <td>-0.462205</td>\n",
       "      <td>0.430610</td>\n",
       "      <td>-0.406907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enceinte_nbmois  nb_prise_10kg  IA_score    sex_PS   tage_PS    revenu  \\\n",
       "0        -0.052955      -0.720455 -0.125994  0.952742  1.355361  1.633466   \n",
       "1        -0.052955      -0.720455 -1.635165 -1.049602  0.390153 -1.525420   \n",
       "2        -0.052955      -0.720455 -0.125994 -1.049602 -0.092451  1.633466   \n",
       "3        -0.052955       0.396878 -1.635165  0.952742  0.872757 -0.893643   \n",
       "4        -0.052955      -0.720455 -0.125994 -1.049602 -1.057659  0.685800   \n",
       "5        -0.052955       0.955544 -0.125994 -1.049602  0.390153  0.369912   \n",
       "6        -0.052955      -0.720455 -0.125994  0.952742 -1.057659  1.001689   \n",
       "7        -0.052955       1.514211 -0.125994  0.952742  0.390153 -0.893643   \n",
       "8        -0.052955      -0.720455 -0.125994 -1.049602 -0.092451  0.054023   \n",
       "9        -0.052955      -0.720455 -0.125994  0.952742 -0.575055 -1.525420   \n",
       "\n",
       "   situ_alim_statut  poids_perception  enceinte  \n",
       "0         -0.462205         -1.004860 -0.406907  \n",
       "1          1.634321         -1.004860 -0.406907  \n",
       "2         -0.462205         -1.004860 -0.406907  \n",
       "3         -0.462205          1.148345  2.466247  \n",
       "4         -0.462205         -1.004860 -0.406907  \n",
       "5         -0.462205          1.866080 -0.406907  \n",
       "6         -0.462205         -1.004860 -0.406907  \n",
       "7          1.634321          0.430610  2.466247  \n",
       "8          1.634321          0.430610 -0.406907  \n",
       "9         -0.462205          0.430610 -0.406907  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed = pd.DataFrame(preprocessor_regression.fit_transform(X_train_regression), columns=original_feature_names)\n",
    "data_preprocessed.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a00d5cca-6499-4482-aa9c-c5b103c871e6",
   "metadata": {},
   "source": [
    "Une fois qu'on a vérifié que le preprocessing nous convient on peut analyser la corrélation des différentes variables explicatives pour se prévenir du problème de la collinéarité. Pour cela, rien de mieux qu'une visualisation graphique pour obtenir une première idée !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d60f8a8-208a-45e1-bad9-d76aea6f1471",
   "metadata": {},
   "source": [
    "**Question 8:** Calculer la matrice de correlation des variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "80cef4f6-4615-44f5-b1bf-40b2e13f8efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <th>IA_score</th>\n",
       "      <th>sex_PS</th>\n",
       "      <th>tage_PS</th>\n",
       "      <th>revenu</th>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <th>poids_perception</th>\n",
       "      <th>enceinte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>enceinte_nbmois</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.076569</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>0.050452</td>\n",
       "      <td>0.020660</td>\n",
       "      <td>-0.004388</td>\n",
       "      <td>-0.007206</td>\n",
       "      <td>0.050675</td>\n",
       "      <td>0.079883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nb_prise_10kg</th>\n",
       "      <td>0.076569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036067</td>\n",
       "      <td>0.078960</td>\n",
       "      <td>0.583019</td>\n",
       "      <td>-0.035983</td>\n",
       "      <td>-0.057732</td>\n",
       "      <td>0.585390</td>\n",
       "      <td>0.285977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IA_score</th>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.036067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>-0.225937</td>\n",
       "      <td>0.488432</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>-0.010532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_PS</th>\n",
       "      <td>0.050452</td>\n",
       "      <td>0.078960</td>\n",
       "      <td>0.025295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>-0.047679</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.387678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tage_PS</th>\n",
       "      <td>0.020660</td>\n",
       "      <td>0.583019</td>\n",
       "      <td>-0.000805</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>-0.023890</td>\n",
       "      <td>0.466337</td>\n",
       "      <td>0.152425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>revenu</th>\n",
       "      <td>-0.004388</td>\n",
       "      <td>-0.035983</td>\n",
       "      <td>-0.225937</td>\n",
       "      <td>-0.047679</td>\n",
       "      <td>-0.114955</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333381</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>-0.015316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>situ_alim_statut</th>\n",
       "      <td>-0.007206</td>\n",
       "      <td>-0.057732</td>\n",
       "      <td>0.488432</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>-0.023890</td>\n",
       "      <td>-0.333381</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.050903</td>\n",
       "      <td>0.034116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poids_perception</th>\n",
       "      <td>0.050675</td>\n",
       "      <td>0.585390</td>\n",
       "      <td>-0.056022</td>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.466337</td>\n",
       "      <td>0.013279</td>\n",
       "      <td>-0.050903</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enceinte</th>\n",
       "      <td>0.079883</td>\n",
       "      <td>0.285977</td>\n",
       "      <td>-0.010532</td>\n",
       "      <td>0.387678</td>\n",
       "      <td>0.152425</td>\n",
       "      <td>-0.015316</td>\n",
       "      <td>0.034116</td>\n",
       "      <td>0.330145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  enceinte_nbmois  nb_prise_10kg  IA_score    sex_PS  \\\n",
       "enceinte_nbmois          1.000000       0.076569 -0.001231  0.050452   \n",
       "nb_prise_10kg            0.076569       1.000000 -0.036067  0.078960   \n",
       "IA_score                -0.001231      -0.036067  1.000000  0.025295   \n",
       "sex_PS                   0.050452       0.078960  0.025295  1.000000   \n",
       "tage_PS                  0.020660       0.583019 -0.000805  0.075672   \n",
       "revenu                  -0.004388      -0.035983 -0.225937 -0.047679   \n",
       "situ_alim_statut        -0.007206      -0.057732  0.488432  0.018948   \n",
       "poids_perception         0.050675       0.585390 -0.056022  0.064074   \n",
       "enceinte                 0.079883       0.285977 -0.010532  0.387678   \n",
       "\n",
       "                   tage_PS    revenu  situ_alim_statut  poids_perception  \\\n",
       "enceinte_nbmois   0.020660 -0.004388         -0.007206          0.050675   \n",
       "nb_prise_10kg     0.583019 -0.035983         -0.057732          0.585390   \n",
       "IA_score         -0.000805 -0.225937          0.488432         -0.056022   \n",
       "sex_PS            0.075672 -0.047679          0.018948          0.064074   \n",
       "tage_PS           1.000000 -0.114955         -0.023890          0.466337   \n",
       "revenu           -0.114955  1.000000         -0.333381          0.013279   \n",
       "situ_alim_statut -0.023890 -0.333381          1.000000         -0.050903   \n",
       "poids_perception  0.466337  0.013279         -0.050903          1.000000   \n",
       "enceinte          0.152425 -0.015316          0.034116          0.330145   \n",
       "\n",
       "                  enceinte  \n",
       "enceinte_nbmois   0.079883  \n",
       "nb_prise_10kg     0.285977  \n",
       "IA_score         -0.010532  \n",
       "sex_PS            0.387678  \n",
       "tage_PS           0.152425  \n",
       "revenu           -0.015316  \n",
       "situ_alim_statut  0.034116  \n",
       "poids_perception  0.330145  \n",
       "enceinte          1.000000  "
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr = data_preprocessed.corr()\n",
    "corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03d7d7aa-870c-486e-bd85-bda2a2fca987",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "corr = data_preprocessed.corr()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "124a8305-9760-48b2-88f7-5637e55fc836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    "    )\n",
    "\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e13b440-eba9-4b13-b7fc-f68a97efcbc4",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant passer à la modélisation ! Sachant qu'on a déjà une *pipeline* qui contient les instructions pour le *preprocessing* il est très simple de rajouter une étape supplémentaire à cette pipeline afin de réaliser la modélisation. Pour estimer une régression linéaire nous allons utiliser une nouvelle fois une méthode de scikit-learn: `LinearRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "bb2b1cf0-3cf1-4efe-bca4-4a6cab5fd428",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessor', preprocessor_regression), # 1ère étape réaliser le preprocessing\n",
    "    ('regression', LinearRegression()) # 2ème étape estime notre régression linéaire\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e810ba3-6a91-4f4d-b330-5721c0bf4a45",
   "metadata": {},
   "source": [
    "Comme précédemment, notre pipeline n'a pas été exécutée, nous l'avons seulement définie. Il est donc nécessaire de l'exécuter sur nos données grâce à la méthode `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "7014290d-d415-4885-92b1-4e14922cb158",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pipe_lr.fit(X_train_regression, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbc3fbef-3fbf-4d9b-b6b4-c9c4099360b1",
   "metadata": {},
   "source": [
    "**Question 9:** Prédisez les indices de masse corporelles des individus de votre échantillon de test à l'aide de votre modèle. Evaluez le en calculant l'écart quadratique moyen (RMSE) et le R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "bd4a5d02-6b8d-4b89-a48f-d6d9d9748b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le RMSE sur le jeu de test est : 4.3542\n",
      "Le R2 sur le jeu de test est : 0.4517\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lr.predict(X_test_regression)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0704abd0-60fa-4423-bd49-524247f553ec",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lr.predict(X_test_regression)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f40d0ce4-491f-498b-9411-1220281ae490",
   "metadata": {},
   "source": [
    "Il est difficile d'interpréter la valeur absolue du RMSE car il dépend de l'échelle et de la volatilité des données que nous cherchons à prédire. Regardons quelques statistiques de nl'IMC de nos individus de l'échantillons de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "209e81b4-0ec9-4787-a9f0-4b040c9880eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La variance de l'IMC de jeu de test est : 34.6071\n",
      "La moyenne de l'IMC de jeu de test est : 22.3912\n",
      "L'écart interquartile de l'IMC de jeu de test est : 8.1963\n"
     ]
    }
   ],
   "source": [
    "print(f\"La variance de l'IMC de jeu de test est : {round(y_test.var(), 4)}\")\n",
    "print(f\"La moyenne de l'IMC de jeu de test est : {round(y_test.mean(), 4)}\")\n",
    "print(f\"L'écart interquartile de l'IMC de jeu de test est : {round(y_test.quantile(0.75) - y_test.quantile(0.25), 4)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "73b06b38-6bf0-4adf-bb9b-74c6b9bd6d92",
   "metadata": {},
   "source": [
    "On peut donc normaliser notre RMSE par l'une de ces statistiques pour avoir une idée plus précise des erreurs. La variance et la moyenne sont généralement les plus utilisées pour normaliser le RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "dac1c1ae-9a93-483f-83f6-af749f5fac0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le RMSE sur le jeu de test équivaut à 12.58% de la variance de l'échantillon.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d276417-0682-4aad-a216-66a5dd61efc6",
   "metadata": {},
   "source": [
    "Une autre méthode qu'on ne saurait que vous recommander est une nouvelle fois la représentation graphique ! "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "82d5720e-1bdb-4ce2-bae3-024aac979477",
   "metadata": {},
   "source": [
    "**Question 10:** Représentez graphiquement les valeurs prédites par rapport aux vraies valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "dc761d49-9c15-4b0d-8b5a-94d1ffbcefc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creer le scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Ajout des labels\n",
    "plt.xlabel('Vrai IMC')\n",
    "plt.ylabel('IMC prédit')\n",
    "\n",
    "# Ajout de la ligne à 45° comme référence\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Affichagedu graphique\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f565bf29-54fd-457c-a57d-4d8a27941b32",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creer le scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Ajout des labels\n",
    "plt.xlabel('Vrai IMC')\n",
    "plt.ylabel('IMC prédit')\n",
    "\n",
    "# Ajout de la ligne à 45° comme référence\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Affichagedu graphique\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01578772-470a-4e3c-a8b0-4ea9c6810597",
   "metadata": {},
   "source": [
    "**Question 11:** Commentez le graphique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53117eb-70d0-428a-b93b-bb047691d0a5",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "- valeurs globalement alignées, mais pas tout à fait\n",
    "- pour les Vrai IMC >30, le modèle a tendance à sous-estimer lors de la prédiction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "859a0c32-9cda-4e1d-b597-833b26b6e9d0",
   "metadata": {},
   "source": [
    "### 3. Méthodes de Machine Learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "932fee4b-e891-4b69-a99b-b68c060ab083",
   "metadata": {},
   "source": [
    "#### 3.1 Random Forest Regression\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4e67837-2db3-4734-b835-27ddfe12c2c4",
   "metadata": {},
   "source": [
    "Grâce à scikit learn, on va voir qu'il est très facile d'utiliser des méthodes de machine learning différentes maintenant qu'on a utilisé les fonctions de base lors de la régression linéaire. \n",
    "Nous allons maintenant essayer d'utiliser l'intégralité des variables qui nous sont disponibles dans la base de données initiale. Cela implique de se replonger un petit peu dans l'analyse des données. Nous avons vu précédemment que toutes les variables numériques ne pouvaient pas être imputées par la médiane et que dans certains cas une imputation par 0 est préférable. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eef8c90d-715a-4681-9c16-6b105a3d2441",
   "metadata": {},
   "source": [
    "**Question 12:** Répertoriez l'ensemble des variables numériques à imputer par 0 dans une liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2b9f70cd-390b-464e-b76a-95dce55cb3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERICAL_0_IMPUT = [\n",
    "        \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74132696-083c-4241-9e09-a6c130e52baf",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "NUMERICAL_0_IMPUT = [\n",
    "    \"enceinte_nbmois\", \"nb_prise_10kg\", \"nb_cigarettes_jour\",  \n",
    "    \"nb_cigarettes_sem\", \"nb_cigares_jour\", \"nb_cigares_sem\", \n",
    "    \"nb_pipes_jour\", \"nb_pipes_sem\", \"allaite_nbsem\", \n",
    "    \"regime_nb_2dernann\", \"regime_nb_anter2dernann\"\n",
    "    ]\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6763e442-e5e2-4ce7-b6cf-e66e6e86ec80",
   "metadata": {},
   "source": [
    "**Question 13:** En vous aidant de ce qui a été fait précédemment, construisez un objet `preprocessor` qui imputera correctement toutes les variables de notre jeu de données d'entrainement, à savoir `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "06616f2b-ec1f-4822-a6b0-7122a4f0c692",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4df2ccb-42c3-4f8e-8bf2-fbbead02c965",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "zero_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0)\n",
    "minus_one_imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1)\n",
    "median_imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "numerical_zero = make_pipeline(zero_imputer, StandardScaler())\n",
    "numerical_median = make_pipeline(median_imputer, StandardScaler())\n",
    "categorical_encoder = make_pipeline(minus_one_imputer, StandardScaler())\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"numerical_zero\", numerical_zero, NUMERICAL_0_IMPUT),\n",
    "        (\"numerical_median\", numerical_median, [x for x in NUMERICAL if x not in NUMERICAL_0_IMPUT]),\n",
    "        (\"categorical\", categorical_encoder, CATEGORICAL)\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfaef515-935c-4ee9-b111-1e056bb43f40",
   "metadata": {},
   "source": [
    "**Question 14:** De la même manière que ce qui a été fait en 2., construisez une pipeline qui preprocesse vos données avant d'estimer un modèle Random Forest. N'oubliez pas de spécifier un `random_state` pour pouvoir répliquer vos résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "eab1968e-a27b-4d7d-b324-2432b8fafbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a0c4f1-021c-4515-8735-5b14f81bd8de",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "pipe_rfr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', RandomForestRegressor(random_state=SEED))\n",
    "])\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c208d95-1c8d-4045-8138-e21e01f707ac",
   "metadata": {},
   "source": [
    "Lorsque l'on entraine un modèle de machine on souhaite minimiser l'erreur de prédiction sur les données non utilisées lors de l'entrainement. Pour faire cela, il existe généralement \n",
    "plusieurs paramètres propres à chaque modèle que l'on peut faire varier de sorte à influer sur les performances. On utilise plus souvent le terme d'*hyperparamètre* que l'on cherche à *calibrer* (*fine-tune*), c'est-à-dire déterminer la combinaison d'hyperparamètres qui obtient la meilleure performance. Pour pouvoir calibrer ces hyperparamètres nous avons besoins de connaitre quels sont ceux des modèles Ra&ndom Forest, pour cela on peut utiliser la commande suivante : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "f1964f17-2128-46ed-a417-da5794f0c876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'criterion': 'squared_error',\n",
       " 'max_depth': None,\n",
       " 'max_features': 1.0,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': 2023,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_rfr['regression'].get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b5620c6-036d-46aa-a875-64d46d8d2874",
   "metadata": {},
   "source": [
    "On voit que `scikit-learn` fournit directement des valeurs par défauts pour ces hyperparamètres et ces valeurs par défaut sont généralement des bonnes valeurs pour commencer. En plus de ces paramètres par défaut nous allons également tester d'autres combinaisons avec la méthode dites de *grid search* qui consiste simplement à tester toutes les combinaisons possibles parmi un ensemble de valeurs pour chaque paramètre à optimiser. Pour le moment nous allons choisir les paramètres `n_estimators` et `max_leaf_nodes` dont vous pouvez retrouver la signification dans la [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8e7f898d-e90a-41e0-a891-d868aab2584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"regression__n_estimators\": [50, 100, 200],\n",
    "    \"regression__max_leaf_nodes\": [5, 10, 50, None]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f5441f3-342b-4375-96bb-ed9382d2b321",
   "metadata": {},
   "source": [
    "De sorte à limiter l'*overfitting* en calibrant les hyperparamètres nous allons également utiliser la méthode de *cross-validation* à 5 blocs (qui est très bien expliquée [ici](https://scikit-learn.org/stable/modules/cross_validation.html)). Pour effectuer tout cela, `scikit-learn` fournit une nouvelle fois une fonction particulièrement utile : `GridSearchCV()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "baeffe5a-c66c-4c36-8154-a83ec9a7490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipe_rfr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07629083-561d-46b6-bd8f-3dad076c218b",
   "metadata": {},
   "source": [
    "**Question 14:** Pouvez vous deviner le nombre de `fit` total que nous allons effectuer lorsque nous allons appeler la méthode `fit` sur l'objet `pipe_rfr` ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d5419485-2a54-444e-9b4e-a5445d565654",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "Pour le grid search nous avons $3*4=12$ modèles à entrainer. Cependant, pour chaque combinaison nous effectuons une cross validation à $5$ blocs ce qui implique 5 entrainements pour chaque combinaisons tester. A la fin, nous avons donc à entrainer $60$ modèles.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4e5fa-9161-4320-a610-653f3fb58d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    }
   ],
   "source": [
    "rfr = pipe_gscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc935b-349a-40fa-b6a0-de04d040dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meilleure combinaison retenue: {rfr.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c727b-5ec1-4304-8194-2a1af9018486",
   "metadata": {},
   "source": [
    "Il est possible d'accéder aux résultats de tous les modèles entrainés afin de comparer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d860d86-6531-46ec-9784-fb7a6c92b596",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_random_forest = pd.DataFrame(rfr.cv_results_)\n",
    "perf_random_forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2720edc9-d7eb-436d-b5b5-215fb66d7499",
   "metadata": {},
   "source": [
    "**Question 15:** Calculez les mêmes métriques que pour la régression linéaire et comparez la performance entre les deux modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f639d9-87db-4d88-82e3-19a394681e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7acff629-fcf5-45df-bfc2-3dbcb4724956",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "y_pred = rfr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4b567f-fe10-4376-adca-61d097d13580",
   "metadata": {},
   "source": [
    "**Question 16:** Reproduisez le graphique représentant les valeurs prédites par rapport aux vraies valeurs et observez visuellement la différence de performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ae9e4a-70c3-4d1d-ba11-7079ceb4f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebe125e1-917a-4745-aa9e-1f6f2dd38d3d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "# Create the scatter plot\n",
    "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Actual IMC')\n",
    "plt.ylabel('Predicted IMC')\n",
    "plt.title('Scatter Plot of Predicted IMC vs Actual IMC')\n",
    "\n",
    "# Add a diagonal line for reference\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linestyle='--')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8c61ab1-97ec-4030-bf89-01d1ca473565",
   "metadata": {},
   "source": [
    "#### 3.2 D'autres méthodes de machine learning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cf652da-063b-4ca0-aa1b-2e2901043f42",
   "metadata": {},
   "source": [
    "L'une des grandes forces de `scikit-learn` est que tout a été pensé pour que les fonctions soient extrêmement modulaire. Ainsi, une fois que l'on a un preprocessing bien défini, il est très facile de tester différents modèles pour savoir lesquels sont les mieux adaptés à nos jeux de données. Nous allons maintenant appliquer 3 autres méthodes, à savoir : \n",
    "- Les **Support Vectors Machines** (SVM) : documentation [ici](https://scikit-learn.org/stable/modules/svm.html),\n",
    "- L'**eXtreme Gradient Boosting** (XGBoost) : documentation [ici](https://xgboost.readthedocs.io/en/stable/),\n",
    "- La régression par les **plus proches voisins** (KNN) : documentation [ici](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html),\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "045e191a-b600-48b0-9954-a996010cc38a",
   "metadata": {},
   "source": [
    "**Question 17:** En reprenant la même trame que pour la méthode des *Random Forests*, essayez de trouver le modèle le plus performant en utilisant les **SVM**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29410872-bfd6-4301-896f-6ce4e63c86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# VOTRE CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6775aabb-786c-4286-87dd-7f1c18beed46",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "pipeline_svr = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', SVR())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__C\": np.logspace(-8, 8, 9, base=2), \n",
    "    \"regression__kernel\": [\"rbf\"],\n",
    "    \"regression__gamma\": [0.01],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_svr, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "svr = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {svr.best_params_}\")\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3616f28e-c701-433f-b1ec-4fab83ce24d2",
   "metadata": {},
   "source": [
    "**Question 18:** De même, essayez de trouver le modèle le plus performant en utilisant le **XGBoost**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0f272de6-f82e-4c8e-a8f1-1d521dda1856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Meilleure combinaison retenue: {'regression__gamma': 0.25, 'regression__max_depth': 5, 'regression__max_leaves': 5, 'regression__n_estimators': 75}\n",
      "Le RMSE sur le jeu de test est : 1.5933\n",
      "Le R2 sur le jeu de test est : 0.9266\n",
      "Le RMSE sur le jeu de test équivaut à 4.6% de la variance de l'échantillon.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a2383a90-12de-47e3-a544-e1f5be7e79d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': None,\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': None,\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': 2023,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_xgb['regression'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3e2dcdcc-abf7-48d8-9e6b-61342c0a67c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6237 candidates, totalling 31185 fits\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   5.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.263) r2: (test=0.661) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-1.877) r2: (test=0.888) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.928) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.723) neg_root_mean_squared_error: (test=-8.121) r2: (test=-0.958) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.864) neg_root_mean_squared_error: (test=-3.395) r2: (test=0.641) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.901) neg_root_mean_squared_error: (test=-2.022) r2: (test=0.873) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.556) r2: (test=0.925) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.932) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.925) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   5.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   5.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.733) neg_root_mean_squared_error: (test=-8.087) r2: (test=-1.084) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.873) neg_root_mean_squared_error: (test=-3.330) r2: (test=0.671) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-1.959) r2: (test=0.886) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.606) r2: (test=0.923) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.564) r2: (test=0.924) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.929) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.934) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.935) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.929) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.473) r2: (test=0.931) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   5.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   5.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.873) neg_root_mean_squared_error: (test=-3.330) r2: (test=0.671) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.556) r2: (test=0.925) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.558) r2: (test=0.925) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   5.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.928) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.934) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   5.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   5.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.733) neg_root_mean_squared_error: (test=-8.087) r2: (test=-1.084) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.609) r2: (test=0.919) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.576) r2: (test=0.923) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.930) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.622) r2: (test=0.918) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.929) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.929) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.723) neg_root_mean_squared_error: (test=-8.121) r2: (test=-0.958) total time=   0.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.263) r2: (test=0.661) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.572) r2: (test=0.921) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.932) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.929) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.911) neg_root_mean_squared_error: (test=-1.890) r2: (test=0.889) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.622) r2: (test=0.918) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.558) r2: (test=0.925) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.473) r2: (test=0.931) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.902) neg_root_mean_squared_error: (test=-3.124) r2: (test=0.696) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.876) r2: (test=0.890) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   3.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-1.703) r2: (test=0.910) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.582) r2: (test=0.926) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.926) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.864) neg_root_mean_squared_error: (test=-3.395) r2: (test=0.641) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-1.703) r2: (test=0.910) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.929) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.572) r2: (test=0.921) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.929) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.929) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.767) r2: (test=0.901) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   2.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.786) neg_root_mean_squared_error: (test=-8.019) r2: (test=-0.910) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.897) neg_root_mean_squared_error: (test=-3.242) r2: (test=0.673) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   3.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.920) neg_root_mean_squared_error: (test=-1.665) r2: (test=0.918) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.927) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.609) r2: (test=0.919) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.927) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.929) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.788) neg_root_mean_squared_error: (test=-7.914) r2: (test=-0.952) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.902) neg_root_mean_squared_error: (test=-3.124) r2: (test=0.696) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.589) r2: (test=0.921) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.423) r2: (test=0.939) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.906) neg_root_mean_squared_error: (test=-3.143) r2: (test=0.685) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.566) r2: (test=0.927) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.932) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.920) neg_root_mean_squared_error: (test=-1.665) r2: (test=0.918) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.576) r2: (test=0.923) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.930) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.545) r2: (test=0.926) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.928) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.790) neg_root_mean_squared_error: (test=-7.983) r2: (test=-1.031) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.796) r2: (test=0.899) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.463) r2: (test=0.932) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.933) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.936) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.932) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.838) r2: (test=0.900) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.933) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.386) r2: (test=0.942) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.393) r2: (test=0.942) total time=   3.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.730) neg_root_mean_squared_error: (test=-8.007) r2: (test=-0.999) total time=   0.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.882) neg_root_mean_squared_error: (test=-3.430) r2: (test=0.647) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.927) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.933) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.717) neg_root_mean_squared_error: (test=-8.183) r2: (test=-1.084) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.263) r2: (test=0.661) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.927) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.838) r2: (test=0.900) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.453) r2: (test=0.933) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.933) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.939) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.795) neg_root_mean_squared_error: (test=-8.216) r2: (test=-1.025) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.876) r2: (test=0.890) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.932) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.424) r2: (test=0.939) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.518) r2: (test=0.928) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.896) r2: (test=-0.943) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.927) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.928) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.738) neg_root_mean_squared_error: (test=-8.370) r2: (test=-1.102) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-1.959) r2: (test=0.886) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.928) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.930) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.938) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.589) r2: (test=0.921) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.938) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.938) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.814) neg_root_mean_squared_error: (test=-8.168) r2: (test=-1.002) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.759) r2: (test=0.904) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.934) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.392) r2: (test=0.942) total time=   2.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.992) r2: (test=-0.897) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-3.193) r2: (test=0.683) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.717) neg_root_mean_squared_error: (test=-8.183) r2: (test=-1.084) total time=   0.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.738) neg_root_mean_squared_error: (test=-8.370) r2: (test=-1.102) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.882) neg_root_mean_squared_error: (test=-3.430) r2: (test=0.647) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.609) r2: (test=0.919) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.552) r2: (test=0.925) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.934) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.901) neg_root_mean_squared_error: (test=-2.022) r2: (test=0.873) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.582) r2: (test=0.926) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.966) r2: (test=0.884) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.576) r2: (test=0.923) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.939) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.896) r2: (test=-0.943) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-3.197) r2: (test=0.693) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.936) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.730) neg_root_mean_squared_error: (test=-8.007) r2: (test=-0.999) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.876) neg_root_mean_squared_error: (test=-3.236) r2: (test=0.674) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.911) neg_root_mean_squared_error: (test=-1.890) r2: (test=0.889) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.625) r2: (test=0.921) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.927) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.933) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.545) r2: (test=0.926) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.606) r2: (test=0.923) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.564) r2: (test=0.924) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.934) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.928) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.536) r2: (test=0.930) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.928) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.934) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.939) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-3.193) r2: (test=0.683) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.935) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.935) total time=   2.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.930) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.622) r2: (test=0.918) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.928) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.934) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.873) neg_root_mean_squared_error: (test=-3.330) r2: (test=0.671) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.625) r2: (test=0.921) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.562) r2: (test=0.928) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.780) neg_root_mean_squared_error: (test=-8.069) r2: (test=-1.026) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.906) neg_root_mean_squared_error: (test=-3.143) r2: (test=0.685) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.790) neg_root_mean_squared_error: (test=-7.983) r2: (test=-1.031) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.904) neg_root_mean_squared_error: (test=-3.199) r2: (test=0.696) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.527) r2: (test=0.930) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   3.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.932) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   3.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.813) neg_root_mean_squared_error: (test=-7.953) r2: (test=-1.016) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-3.197) r2: (test=0.693) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.555) r2: (test=0.928) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.932) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   4.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.911) neg_root_mean_squared_error: (test=-1.890) r2: (test=0.889) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.590) r2: (test=0.921) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.925) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.536) r2: (test=0.930) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.928) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.535) r2: (test=0.930) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.938) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.938) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.420) r2: (test=0.940) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.396) r2: (test=0.942) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.386) r2: (test=0.942) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   3.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.896) r2: (test=-0.943) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.814) neg_root_mean_squared_error: (test=-8.168) r2: (test=-1.002) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.800) r2: (test=0.899) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   4.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.572) r2: (test=0.921) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.927) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.933) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-1.877) r2: (test=0.888) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.928) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.864) neg_root_mean_squared_error: (test=-3.395) r2: (test=0.641) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.556) r2: (test=0.925) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.928) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.795) neg_root_mean_squared_error: (test=-8.216) r2: (test=-1.025) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.830) r2: (test=0.900) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.933) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.936) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.800) r2: (test=0.899) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   4.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-3.091) r2: (test=0.702) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.518) r2: (test=0.928) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.930) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.544) r2: (test=0.926) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.926) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.532) r2: (test=0.930) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.928) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.546) r2: (test=0.926) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.780) neg_root_mean_squared_error: (test=-8.069) r2: (test=-1.026) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.796) r2: (test=0.899) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.933) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.938) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.386) r2: (test=0.942) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.883) neg_root_mean_squared_error: (test=-2.955) r2: (test=0.728) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.562) r2: (test=0.928) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.535) r2: (test=0.930) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.545) r2: (test=0.926) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.532) r2: (test=0.930) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.938) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.939) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.421) r2: (test=0.939) total time=   3.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.788) neg_root_mean_squared_error: (test=-7.914) r2: (test=-0.952) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.904) neg_root_mean_squared_error: (test=-3.199) r2: (test=0.696) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.992) r2: (test=-0.897) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.710) r2: (test=0.907) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.390) r2: (test=0.942) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   4.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.934) total time=   4.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.813) neg_root_mean_squared_error: (test=-7.953) r2: (test=-1.016) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-3.081) r2: (test=0.697) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.933) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   4.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.886) neg_root_mean_squared_error: (test=-2.998) r2: (test=0.714) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.933) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.928) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.930) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.897) neg_root_mean_squared_error: (test=-3.242) r2: (test=0.673) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.932) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.424) r2: (test=0.939) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.589) r2: (test=0.921) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.933) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.933) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.934) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.803) neg_root_mean_squared_error: (test=-8.038) r2: (test=-1.010) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.822) r2: (test=0.901) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.935) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.934) total time=   4.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   4.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.810) neg_root_mean_squared_error: (test=-7.992) r2: (test=-0.897) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-3.180) r2: (test=0.700) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.931) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   3.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.671) r2: (test=0.913) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.933) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.476) r2: (test=0.935) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   5.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.566) r2: (test=0.927) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.786) neg_root_mean_squared_error: (test=-8.019) r2: (test=-0.910) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.909) neg_root_mean_squared_error: (test=-3.253) r2: (test=0.682) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.928) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.933) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.441) r2: (test=0.934) total time=   3.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.935) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   4.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.822) r2: (test=0.901) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.403) r2: (test=0.941) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   4.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.822) r2: (test=0.901) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   4.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   4.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.927) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.473) r2: (test=0.931) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.933) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.909) neg_root_mean_squared_error: (test=-3.253) r2: (test=0.682) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.546) r2: (test=0.926) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.938) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   3.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.935) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   4.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   4.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.934) total time=   4.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.551) r2: (test=0.923) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.928) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.546) r2: (test=0.926) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.934) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.536) r2: (test=0.930) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.928) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.552) r2: (test=0.925) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.738) neg_root_mean_squared_error: (test=-8.370) r2: (test=-1.102) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-1.877) r2: (test=0.888) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.547) r2: (test=0.926) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.931) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.933) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.441) r2: (test=0.934) total time=   3.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.780) neg_root_mean_squared_error: (test=-8.069) r2: (test=-1.026) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.906) neg_root_mean_squared_error: (test=-3.143) r2: (test=0.685) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.527) r2: (test=0.930) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.933) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.441) r2: (test=0.934) total time=   3.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   4.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   3.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.398) r2: (test=0.941) total time=   5.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.936) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   3.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   5.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.930) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.876) neg_root_mean_squared_error: (test=-3.236) r2: (test=0.674) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-1.703) r2: (test=0.910) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.932) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.926) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.939) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.788) neg_root_mean_squared_error: (test=-7.914) r2: (test=-0.952) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.897) neg_root_mean_squared_error: (test=-3.242) r2: (test=0.673) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.421) r2: (test=0.939) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   3.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.934) total time=   4.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-3.180) r2: (test=0.700) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.518) r2: (test=0.928) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.935) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   5.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   5.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.928) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.723) neg_root_mean_squared_error: (test=-8.121) r2: (test=-0.958) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-1.959) r2: (test=0.886) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.590) r2: (test=0.921) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.930) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.934) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.936) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.938) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.463) r2: (test=0.932) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.767) r2: (test=0.901) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.453) r2: (test=0.933) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.423) r2: (test=0.939) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.403) r2: (test=0.941) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   4.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.931) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   4.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.931) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   4.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.717) neg_root_mean_squared_error: (test=-8.183) r2: (test=-1.084) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.966) r2: (test=0.884) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.934) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.927) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.767) r2: (test=0.901) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.453) r2: (test=0.933) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.424) r2: (test=0.939) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.909) neg_root_mean_squared_error: (test=-3.253) r2: (test=0.682) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.938) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.813) neg_root_mean_squared_error: (test=-7.953) r2: (test=-1.016) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.755) r2: (test=0.908) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.931) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.934) total time=   5.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.390) r2: (test=0.942) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.392) r2: (test=0.942) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   4.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.461) r2: (test=0.936) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.730) neg_root_mean_squared_error: (test=-8.007) r2: (test=-0.999) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.882) neg_root_mean_squared_error: (test=-3.430) r2: (test=0.647) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.606) r2: (test=0.923) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.933) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.934) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.904) neg_root_mean_squared_error: (test=-3.199) r2: (test=0.696) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.527) r2: (test=0.930) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.938) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   2.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.795) neg_root_mean_squared_error: (test=-8.216) r2: (test=-1.025) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.838) r2: (test=0.900) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.546) r2: (test=0.926) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.932) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.938) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.934) total time=   2.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   3.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   3.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   5.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   4.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.925) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.535) r2: (test=0.930) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.786) neg_root_mean_squared_error: (test=-8.019) r2: (test=-0.910) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.876) r2: (test=0.890) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.790) neg_root_mean_squared_error: (test=-7.983) r2: (test=-1.031) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.796) r2: (test=0.899) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.929) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.914) neg_root_mean_squared_error: (test=-3.180) r2: (test=0.700) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.931) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   3.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.710) r2: (test=0.907) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.934) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.396) r2: (test=0.942) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.755) r2: (test=0.908) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.935) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   4.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.931) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.928) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.538) r2: (test=0.930) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.733) neg_root_mean_squared_error: (test=-8.087) r2: (test=-1.084) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.901) neg_root_mean_squared_error: (test=-2.022) r2: (test=0.873) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.582) r2: (test=0.926) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.934) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.932) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.932) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.938) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.463) r2: (test=0.932) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.939) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-3.091) r2: (test=0.702) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   3.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   4.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   4.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.935) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.575) r2: (test=0.926) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   4.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.966) r2: (test=0.884) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.590) r2: (test=0.921) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.928) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.934) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.929) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.935) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.929) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.938) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.496) r2: (test=0.933) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.934) total time=   4.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.933) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.936) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.442) r2: (test=0.934) total time=   5.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   5.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   2.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.928) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.928) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.876) neg_root_mean_squared_error: (test=-3.236) r2: (test=0.674) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.625) r2: (test=0.921) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.929) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.541) r2: (test=0.929) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.938) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.423) r2: (test=0.939) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.938) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.939) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.421) r2: (test=0.939) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   4.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.390) r2: (test=0.942) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   4.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.393) r2: (test=0.942) total time=   3.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.442) r2: (test=0.934) total time=   5.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.468) r2: (test=0.931) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   5.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   3.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.0, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   5.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.934) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.935) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.932) total time=   3.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.932) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.933) total time=   2.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.931) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   3.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   3.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.934) total time=   4.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.710) r2: (test=0.907) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.931) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   5.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.928) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.926) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.925) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.938) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.938) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.939) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.938) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.930) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.902) neg_root_mean_squared_error: (test=-3.124) r2: (test=0.696) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.928) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   3.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.935) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.934) total time=   4.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.936) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   4.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   3.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   5.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.937) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.883) neg_root_mean_squared_error: (test=-2.955) r2: (test=0.728) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.925) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.476) r2: (test=0.935) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.542) r2: (test=0.926) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.562) r2: (test=0.928) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.544) r2: (test=0.926) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.934) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.935) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   2.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.830) r2: (test=0.900) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.488) r2: (test=0.931) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.830) r2: (test=0.900) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.933) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.939) total time=   2.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.932) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.936) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   4.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.934) total time=   5.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   4.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.474) r2: (test=0.931) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.937) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.933) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.931) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.452) r2: (test=0.937) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.938) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.933) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.930) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.555) r2: (test=0.928) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   3.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.931) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.392) r2: (test=0.942) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   4.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.759) r2: (test=0.904) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.935) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   4.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.871) neg_root_mean_squared_error: (test=-3.129) r2: (test=0.695) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.925) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.920) neg_root_mean_squared_error: (test=-1.665) r2: (test=0.918) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.564) r2: (test=0.924) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.544) r2: (test=0.926) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.932) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.938) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   3.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.814) neg_root_mean_squared_error: (test=-8.168) r2: (test=-1.002) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.759) r2: (test=0.904) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.933) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.935) total time=   2.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   4.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.803) neg_root_mean_squared_error: (test=-8.038) r2: (test=-1.010) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.910) neg_root_mean_squared_error: (test=-3.193) r2: (test=0.683) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.555) r2: (test=0.928) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.398) r2: (test=0.941) total time=   5.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.464) r2: (test=0.936) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.403) r2: (test=0.941) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.935) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   3.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.053) r2: (test=0.723) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.643) r2: (test=0.920) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.922) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.455) r2: (test=0.936) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.588) r2: (test=0.921) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.933) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.935) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.935) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.908) neg_root_mean_squared_error: (test=-2.877) r2: (test=0.736) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.928) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.558) r2: (test=0.925) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.532) r2: (test=0.930) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.931) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.552) r2: (test=0.925) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   3.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.420) r2: (test=0.940) total time=   3.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.420) r2: (test=0.940) total time=   3.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.935) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.935) total time=   3.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   4.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.396) r2: (test=0.942) total time=   4.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.930) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.931) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.928) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.932) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.938) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.933) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.932) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.398) r2: (test=0.941) total time=   4.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   4.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-3.197) r2: (test=0.693) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.933) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.933) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.464) r2: (test=0.936) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.522) r2: (test=0.928) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.907) neg_root_mean_squared_error: (test=-2.931) r2: (test=0.745) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.931) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.931) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.476) r2: (test=0.931) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.933) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.935) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.803) neg_root_mean_squared_error: (test=-8.038) r2: (test=-1.010) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-3.081) r2: (test=0.697) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   5.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.394) r2: (test=0.942) total time=   3.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.934) total time=   4.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.542) r2: (test=0.926) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.539) r2: (test=0.926) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.928) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.871) neg_root_mean_squared_error: (test=-3.129) r2: (test=0.695) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.925) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.931) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.928) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.937) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.465) r2: (test=0.932) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.935) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.931) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.476) r2: (test=0.931) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.938) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.800) r2: (test=0.899) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.486) r2: (test=0.931) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.935) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   3.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.935) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.871) neg_root_mean_squared_error: (test=-3.129) r2: (test=0.695) total time=   0.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.588) r2: (test=0.921) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.929) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.930) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.534) r2: (test=0.930) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.931) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.937) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.474) r2: (test=0.931) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.522) r2: (test=0.928) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.551) r2: (test=0.923) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.929) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.932) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.932) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.933) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.932) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.935) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-2.973) r2: (test=0.735) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.566) r2: (test=0.927) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.930) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.933) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-3.081) r2: (test=0.697) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.933) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   3.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.442) r2: (test=0.934) total time=   4.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.934) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.388) r2: (test=0.942) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.934) total time=   4.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.931) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.525) r2: (test=0.928) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.937) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.932) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.934) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.938) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.933) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.890) neg_root_mean_squared_error: (test=-3.133) r2: (test=0.705) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.929) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.525) r2: (test=0.928) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.886) neg_root_mean_squared_error: (test=-2.998) r2: (test=0.714) total time=   0.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.643) r2: (test=0.920) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.476) r2: (test=0.935) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.053) r2: (test=0.723) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.922) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.930) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.927) total time=   0.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.907) neg_root_mean_squared_error: (test=-2.931) r2: (test=0.745) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.564) r2: (test=0.927) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.931) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.931) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.931) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.938) total time=   3.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.931) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.932) total time=   2.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.890) neg_root_mean_squared_error: (test=-3.133) r2: (test=0.705) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.929) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.935) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.455) r2: (test=0.936) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.901) neg_root_mean_squared_error: (test=-2.970) r2: (test=0.726) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.923) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.937) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   3.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.465) r2: (test=0.932) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.435) r2: (test=0.936) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.936) total time=   3.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-2.806) r2: (test=0.749) total time=   0.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.393) r2: (test=0.942) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.931) total time=   3.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.935) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.491) r2: (test=0.931) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.932) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.537) r2: (test=0.930) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.468) r2: (test=0.931) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.921) neg_root_mean_squared_error: (test=-1.643) r2: (test=0.920) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.492) r2: (test=0.933) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.933) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.933) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.938) total time=   3.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.933) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.933) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.935) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.462) r2: (test=0.933) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.442) r2: (test=0.934) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   4.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-2.915) r2: (test=0.745) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   4.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.428) r2: (test=0.935) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.935) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.934) total time=   4.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.936) total time=   1.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.931) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.437) r2: (test=0.934) total time=   4.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.935) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.468) r2: (test=0.931) total time=   2.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.464) r2: (test=0.936) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.521) r2: (test=0.928) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.930) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.474) r2: (test=0.931) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.531) r2: (test=0.930) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.937) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.935) total time=   3.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.474) r2: (test=0.932) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.929) total time=   0.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.936) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   4.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.915) neg_root_mean_squared_error: (test=-2.821) r2: (test=0.752) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.929) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.530) r2: (test=0.927) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.477) r2: (test=0.930) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.932) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.937) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.521) r2: (test=0.928) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   1.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.931) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.933) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.907) neg_root_mean_squared_error: (test=-2.931) r2: (test=0.745) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.915) neg_root_mean_squared_error: (test=-2.821) r2: (test=0.752) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.423) r2: (test=0.939) total time=   4.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.406) r2: (test=0.941) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.441) r2: (test=0.934) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   3.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.934) total time=   3.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   5.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.935) total time=   3.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.934) total time=   4.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.931) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.671) r2: (test=0.913) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.928) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   1.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.521) r2: (test=0.928) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.931) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.931) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.933) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   2.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.455) r2: (test=0.936) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.932) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.938) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.936) total time=   1.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.404) r2: (test=0.941) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.415) r2: (test=0.940) total time=   3.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.939) total time=   5.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   4.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-3.091) r2: (test=0.702) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.755) r2: (test=0.908) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.458) r2: (test=0.934) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.935) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.942) neg_root_mean_squared_error: (test=-1.395) r2: (test=0.942) total time=   4.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.521) r2: (test=0.928) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.931) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.938) total time=   2.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.928) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.934) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.933) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.935) total time=   3.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.936) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.931) total time=   3.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   5.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.915) neg_root_mean_squared_error: (test=-2.821) r2: (test=0.752) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.929) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.407) r2: (test=0.941) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.935) total time=   2.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   1.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.522) r2: (test=0.928) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.575) r2: (test=0.926) total time=   0.5s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.550) r2: (test=0.929) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.461) r2: (test=0.936) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.511) r2: (test=0.929) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.933) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.935) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.938) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.932) total time=   3.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.531) r2: (test=0.930) total time=   4.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.935) total time=   2.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.415) r2: (test=0.940) total time=   3.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-2.924) r2: (test=0.734) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.931) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.929) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.519) r2: (test=0.928) total time=   4.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.883) neg_root_mean_squared_error: (test=-2.955) r2: (test=0.728) total time=   0.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.925) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.886) neg_root_mean_squared_error: (test=-2.998) r2: (test=0.714) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.575) r2: (test=0.926) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   1.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.937) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.923) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   0.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.487) r2: (test=0.931) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.934) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.409) r2: (test=0.940) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.519) r2: (test=0.928) total time=   4.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.936) total time=   1.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.416) r2: (test=0.940) total time=   2.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.928) total time=   4.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.936) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.462) r2: (test=0.932) total time=   4.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.577) r2: (test=0.923) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.540) r2: (test=0.930) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.930) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.923) neg_root_mean_squared_error: (test=-1.588) r2: (test=0.921) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.925) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   1.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.901) neg_root_mean_squared_error: (test=-2.970) r2: (test=0.726) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.564) r2: (test=0.927) total time=   0.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.933) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.931) total time=   2.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.932) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.445) r2: (test=0.937) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.908) neg_root_mean_squared_error: (test=-2.877) r2: (test=0.736) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.931) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.446) r2: (test=0.937) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.483) r2: (test=0.935) total time=   2.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.936) total time=   1.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.441) r2: (test=0.934) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.931) total time=   4.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.453) r2: (test=0.934) total time=   0.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.422) r2: (test=0.936) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   4.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.502) r2: (test=0.933) total time=   1.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.404) r2: (test=0.941) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.415) r2: (test=0.940) total time=   3.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.521) r2: (test=0.928) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.922) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.482) r2: (test=0.930) total time=   0.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.533) r2: (test=0.927) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.916) neg_root_mean_squared_error: (test=-1.671) r2: (test=0.913) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.516) r2: (test=0.928) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.543) r2: (test=0.926) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.524) r2: (test=0.928) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.937) total time=   2.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.932) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.935) total time=   2.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.531) r2: (test=0.930) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.930) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.475) r2: (test=0.932) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.935) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.932) total time=   1.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=140; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.440) r2: (test=0.938) total time=   2.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.382) r2: (test=-13.878) total time=   0.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.900) r2: (test=-14.734) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-2.806) r2: (test=0.749) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.935) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.519) r2: (test=0.932) total time=   3.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.534) r2: (test=0.930) total time=   5.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.409) r2: (test=0.940) total time=   3.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.531) r2: (test=0.930) total time=   4.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.929) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.431) r2: (test=0.936) total time=   3.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.928) total time=   5.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.1, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   5.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   2.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.546) r2: (test=0.926) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.455) r2: (test=0.936) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.931) total time=   2.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.534) r2: (test=0.930) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   1.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.445) r2: (test=0.937) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-2.973) r2: (test=0.735) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.937) total time=   0.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=100; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.932) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.439) r2: (test=0.938) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.513) r2: (test=0.929) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=50; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.449) r2: (test=0.937) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.933) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.931) total time=   2.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   1.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.933) total time=   3.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.536) r2: (test=0.930) total time=   5.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.933) total time=   3.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.430) r2: (test=0.939) total time=   5.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.936) total time=   4.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.919) neg_root_mean_squared_error: (test=-1.784) r2: (test=0.905) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.535) r2: (test=0.927) total time=   0.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.928) total time=   0.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.929) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   1.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.930) total time=   1.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.930) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.880) neg_root_mean_squared_error: (test=-3.053) r2: (test=0.723) total time=   0.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.551) r2: (test=0.923) total time=   0.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.929) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.479) r2: (test=0.930) total time=   1.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.933) total time=   2.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.515) r2: (test=0.932) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=100; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.933) total time=   1.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.474) r2: (test=0.932) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.512) r2: (test=0.932) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.489) r2: (test=0.934) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.462) r2: (test=0.933) total time=   2.8s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   2.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.427) r2: (test=0.935) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.461) r2: (test=0.932) total time=   4.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.508) r2: (test=0.929) total time=   0.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.930) total time=   1.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.929) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=120; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   2.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.464) r2: (test=0.932) total time=   4.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.933) total time=   2.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   3.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   4.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   1.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.583) r2: (test=0.925) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.925) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.537) r2: (test=0.930) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.456) r2: (test=0.936) total time=   1.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.932) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.938) total time=   2.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.457) r2: (test=0.936) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.468) r2: (test=0.931) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.931) total time=   0.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.931) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.933) total time=   1.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.485) r2: (test=0.935) total time=   2.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.929) total time=   2.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.933) total time=   3.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.932) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.471) r2: (test=0.933) total time=   2.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   1.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=120; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.448) r2: (test=0.933) total time=   3.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=180; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.939) total time=   4.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.933) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=160; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.936) total time=   3.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=10; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-2.915) r2: (test=0.745) total time=   0.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=30; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   0.9s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.933) total time=   1.7s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.513) r2: (test=0.932) total time=   3.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.438) r2: (test=0.936) total time=   4.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.529) r2: (test=0.931) total time=   1.4s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.478) r2: (test=0.930) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   1.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.514) r2: (test=0.929) total time=   2.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=120; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.5s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=180; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   2.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.929) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.506) r2: (test=0.929) total time=   2.3s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.467) r2: (test=0.931) total time=   3.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.937) total time=   2.2s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.938) total time=   2.8s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=100; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.932) total time=   1.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=160; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.935) total time=   2.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-2.915) r2: (test=0.745) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.931) total time=   0.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=70; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.936) total time=   2.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.450) r2: (test=0.933) total time=   3.4s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.432) r2: (test=0.938) total time=   5.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.443) r2: (test=0.934) total time=   3.0s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=180; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.519) r2: (test=0.928) total time=   4.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=90; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.936) total time=   2.5s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.526) r2: (test=0.931) total time=   4.0s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.517) r2: (test=0.927) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.927) neg_root_mean_squared_error: (test=-1.531) r2: (test=0.927) total time=   0.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=60; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.495) r2: (test=0.929) total time=   0.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.472) r2: (test=0.935) total time=   1.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.478) r2: (test=0.930) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.251) r2: (test=-14.432) total time=   0.1s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.379) r2: (test=-14.960) total time=   0.1s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.911) neg_root_mean_squared_error: (test=-1.833) r2: (test=0.900) total time=   0.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.924) neg_root_mean_squared_error: (test=-1.599) r2: (test=0.924) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.928) neg_root_mean_squared_error: (test=-1.525) r2: (test=0.928) total time=   1.7s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.907) neg_root_mean_squared_error: (test=-2.851) r2: (test=0.747) total time=   0.3s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.926) neg_root_mean_squared_error: (test=-1.570) r2: (test=0.923) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=40; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.451) r2: (test=0.937) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.447) r2: (test=0.937) total time=   1.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.503) r2: (test=0.930) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.907) neg_root_mean_squared_error: (test=-2.851) r2: (test=0.747) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.927) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.455) r2: (test=0.936) total time=   0.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.509) r2: (test=0.932) total time=   1.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.494) r2: (test=0.934) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.935) total time=   3.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.499) r2: (test=0.933) total time=   1.9s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.466) r2: (test=0.931) total time=   2.8s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.409) r2: (test=0.940) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.513) r2: (test=0.932) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.936) total time=   4.3s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.500) r2: (test=0.933) total time=   1.2s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=80; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.434) r2: (test=0.936) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=140; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.523) r2: (test=0.931) total time=   3.7s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.469) r2: (test=0.931) total time=   5.2s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=150; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.510) r2: (test=0.929) total time=   3.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=0; explained_variance: (test=0.000) neg_root_mean_squared_error: (test=-22.489) r2: (test=-14.735) total time=   0.1s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=10; explained_variance: (test=0.913) neg_root_mean_squared_error: (test=-1.755) r2: (test=0.904) total time=   0.3s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=20; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.553) r2: (test=0.925) total time=   0.4s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=30; explained_variance: (test=0.922) neg_root_mean_squared_error: (test=-1.586) r2: (test=0.922) total time=   0.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.934) neg_root_mean_squared_error: (test=-1.478) r2: (test=0.934) total time=   0.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=80; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.935) total time=   1.1s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.549) r2: (test=0.925) total time=   1.6s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.498) r2: (test=0.933) total time=   2.2s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=160; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.468) r2: (test=0.931) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=40; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.557) r2: (test=0.925) total time=   0.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=70; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.461) r2: (test=0.936) total time=   0.9s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.454) r2: (test=0.937) total time=   1.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=10, regression__n_estimators=200; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.493) r2: (test=0.931) total time=   2.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.520) r2: (test=0.931) total time=   1.4s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=2, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.507) r2: (test=0.933) total time=   1.9s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   1.0s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=110; explained_variance: (test=0.932) neg_root_mean_squared_error: (test=-1.480) r2: (test=0.932) total time=   1.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=5, regression__n_estimators=170; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.505) r2: (test=0.929) total time=   2.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=50; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.497) r2: (test=0.930) total time=   0.8s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=90; explained_variance: (test=0.933) neg_root_mean_squared_error: (test=-1.501) r2: (test=0.933) total time=   1.6s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=10, regression__n_estimators=150; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.470) r2: (test=0.931) total time=   2.6s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=20; explained_variance: (test=0.929) neg_root_mean_squared_error: (test=-1.528) r2: (test=0.927) total time=   0.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=40; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.930) total time=   0.8s\n",
      "[CV 4/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=70; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.481) r2: (test=0.930) total time=   1.3s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=130; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.444) r2: (test=0.937) total time=   2.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=3, regression__max_leaves=25, regression__n_estimators=190; explained_variance: (test=0.935) neg_root_mean_squared_error: (test=-1.484) r2: (test=0.935) total time=   3.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.404) r2: (test=0.941) total time=   2.5s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=5, regression__n_estimators=150; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.417) r2: (test=0.940) total time=   4.0s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=10; explained_variance: (test=0.918) neg_root_mean_squared_error: (test=-2.903) r2: (test=0.750) total time=   0.4s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=30; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.490) r2: (test=0.931) total time=   0.9s\n",
      "[CV 1/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=60; explained_variance: (test=0.930) neg_root_mean_squared_error: (test=-1.504) r2: (test=0.929) total time=   1.7s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=110; explained_variance: (test=0.937) neg_root_mean_squared_error: (test=-1.429) r2: (test=0.936) total time=   3.0s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=10, regression__n_estimators=170; explained_variance: (test=0.939) neg_root_mean_squared_error: (test=-1.423) r2: (test=0.939) total time=   4.1s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=60; explained_variance: (test=0.941) neg_root_mean_squared_error: (test=-1.406) r2: (test=0.941) total time=   1.7s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=110; explained_variance: (test=0.940) neg_root_mean_squared_error: (test=-1.409) r2: (test=0.940) total time=   2.5s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.2, regression__max_depth=5, regression__max_leaves=25, regression__n_estimators=170; explained_variance: (test=0.936) neg_root_mean_squared_error: (test=-1.436) r2: (test=0.936) total time=   4.6s\n",
      "[CV 2/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=90; explained_variance: (test=0.925) neg_root_mean_squared_error: (test=-1.558) r2: (test=0.924) total time=   1.2s\n",
      "[CV 3/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=130; explained_variance: (test=0.931) neg_root_mean_squared_error: (test=-1.522) r2: (test=0.931) total time=   1.6s\n",
      "[CV 5/5] END regression__gamma=0.1, regression__learning_rate=0.30000000000000004, regression__max_depth=2, regression__max_leaves=5, regression__n_estimators=190; explained_variance: (test=0.938) neg_root_mean_squared_error: (test=-1.433) r2: (test=0.938) total time=   2.2s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[293], line 27\u001b[0m\n\u001b[1;32m     11\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression__max_leaves\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m25\u001b[39m],\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression__max_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m5\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression__learning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: [ k\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m11\u001b[39m) ]\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     19\u001b[0m pipe_gscv \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline_xgb, \n\u001b[1;32m     20\u001b[0m                          param_grid\u001b[38;5;241m=\u001b[39mparam_grid, \n\u001b[1;32m     21\u001b[0m                          scoring\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplained_variance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                          n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \n\u001b[1;32m     25\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m xgb \u001b[38;5;241m=\u001b[39m \u001b[43mpipe_gscv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMeilleure combinaison retenue: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mxgb\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Bonus : essayons de mieux tuner le modèle\n",
    "# RMSE à battre : 1.5933\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [ 10*k for k in range(0,21) ],\n",
    "    \"regression__learning_rate\": [ k*0.1 for k in range(0,5) ]\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=3)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5120b775-670b-4ca6-b5f4-650b611a356e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', XGBRegressor(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__max_leaves\": [5, 10, 25],\n",
    "    \"regression__max_depth\": [2, 3, 5],\n",
    "    \"regression__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"regression__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8436d6a3-e15f-422c-9dc7-8f2ce13c5cd6",
   "metadata": {},
   "source": [
    "**Question 19:** De même, essayez de trouver le modèle le plus performant en utilisant les **K plus proches voisins**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "a428943c-a28f-4512-812b-5ae752d5f88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "Meilleure combinaison retenue: {'regression__n_neighbors': 6, 'regression__p': 2}\n",
      "Le RMSE sur le jeu de test est : 3.4711\n",
      "Le R2 sur le jeu de test est : 0.6516\n",
      "Le RMSE sur le jeu de test équivaut à 10.03% de la variance de l'échantillon.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_knn, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "knn = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {knn.best_params_}\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30f75233-99f1-486e-aa2b-5008ce7245de",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "pipeline_knn = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('regression', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regression__n_neighbors\": [3, 4, 5, 6],\n",
    "    \"regression__p\": [1, 2, 3],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_knn, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"explained_variance\", \"r2\", \"neg_root_mean_squared_error\"],\n",
    "                         refit=\"neg_root_mean_squared_error\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "knn = pipe_gscv.fit(X_train, y_train)\n",
    "print(f\"Meilleure combinaison retenue: {knn.best_params_}\")\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Le RMSE sur le jeu de test est : {round(rmse, 4)}\")\n",
    "print(f\"Le R2 sur le jeu de test est : {round(r2, 4)}\")\n",
    "print(f\"Le RMSE sur le jeu de test équivaut à {round(rmse / y_test.var() * 100 , 2)}% de la variance de l'échantillon.\")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48031915-e0d6-4671-8252-b2f3c4bcb3ad",
   "metadata": {},
   "source": [
    "### 4. Pour aller plus loin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7723936a-09ab-458f-b410-ec5d3e021e7b",
   "metadata": {},
   "source": [
    "Précédemment nous avons réalisé que des tâches de régression. Les méthodes de machine learning peuvent aussi s'avérer particulièrement efficace pour effectuer des tâches de classification. Pour illustrer nos propos, essayons de transformer notre problème de régression en un problème de classification. \n",
    "Les valeurs de l'indice de masse corporelle peuvent donner lieu à plusieurs interprétations que l'on peut résumer dans le tableau suivant :\n",
    "\n",
    "| IMC ($kg/m^2$) | Interprétation | Classe |\n",
    "| --- | --- | --- |\n",
    "|  $< 16.5$ | Dénutrition | 0 |\n",
    "|  $16.5$ à $18.5$| Maigreur | 1 |\n",
    "|  $18.5$ à $25$| Poids normal | 2 |\n",
    "|  $25$ à $30$| Surpoids | 3 |\n",
    "|  $30$ à $35$| Obésité modérée | 4 |\n",
    "|  $35$ à $40$| Obésité sévère | 5 |\n",
    "|  $> 40$ | Obésité morbide | 6 |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d27fca0a-e169-41ea-bf0c-f1549825d2cb",
   "metadata": {},
   "source": [
    "**Question 20:** Créer deux variables `y_train_class` et `y_test_class` de sorte à ce les valeurs des IMC soient remplacées par la classe à laquelle ils appartiennt. Par exemple, si l'IMC est égal à 23 alors on renverra la valeur 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "33babde5-846e-4f0a-8ad1-1471403c9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_class = y_train.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )\n",
    "\n",
    "y_test_class = y_test.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "139dc801-36fa-4b39-b896-73309142a455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4679    22.938578\n",
       " 4639    27.309969\n",
       " 3162    18.582815\n",
       " 3658    30.367348\n",
       " 1548    29.270994\n",
       "           ...    \n",
       " 4454    16.141529\n",
       " 2123    18.365473\n",
       " 399     27.362715\n",
       " 3074    17.348541\n",
       " 2496    26.813591\n",
       " Name: imc, Length: 1169, dtype: float64,\n",
       " 4679    3\n",
       " 4639    4\n",
       " 3162    3\n",
       " 3658    5\n",
       " 1548    4\n",
       "        ..\n",
       " 4454    1\n",
       " 2123    2\n",
       " 399     4\n",
       " 3074    2\n",
       " 2496    4\n",
       " Name: imc, Length: 1169, dtype: int64)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test , y_test_class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c357005d-7766-426b-ba7d-af14bdaa3b6e",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquez pour voir la réponse </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "y_train_class = y_train.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )\n",
    "\n",
    "y_test_class = y_test.apply(\n",
    "        lambda imc: 1\n",
    "        if imc < 16.5\n",
    "        else 2\n",
    "        if 16.5 <= imc < 18.5\n",
    "        else 3\n",
    "        if 18.5 <= imc < 25\n",
    "        else 4\n",
    "        if 25 <= imc < 30\n",
    "        else 5\n",
    "        if 30 <= imc < 35\n",
    "        else 6\n",
    "        if 35 <= imc < 40\n",
    "        else 7\n",
    "    )\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e973e846-0d44-4c47-8017-c35282be85f7",
   "metadata": {},
   "source": [
    "**Question 21:** Essayez plusieurs de méthodes de machine learning de classification sur ce nouveau problème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90b146-d43e-4d36-b9bd-e65b82067594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A VOUS DE JOUER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24dbbb43-3532-4dca-8f3c-7af7dc82f00d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=3 color=\"red\"><b>Cliquer pour voir une proposition de solution </b></font>\n",
    "</summary>\n",
    "\n",
    "```python\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('preprocessor', preprocessor), \n",
    "    ('classification', XGBClassifier(random_state=SEED))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"classification__max_leaves\": [5, 10, 25],\n",
    "    \"classification__max_depth\": [2, 3, 5],\n",
    "    \"classification__gamma\": [0.1, 0.25, 0.5],\n",
    "    \"classification__n_estimators\": [75, 150, 250],\n",
    "}\n",
    "\n",
    "pipe_gscv = GridSearchCV(pipeline_xgb, \n",
    "                         param_grid=param_grid, \n",
    "                         scoring=[\"accuracy\", \"f1_weighted\"],\n",
    "                         refit=\"f1_weighted\",\n",
    "                         cv=5, \n",
    "                         n_jobs=-1, \n",
    "                         verbose=1)\n",
    "                         \n",
    "xgb = pipe_gscv.fit(X_train, y_train_class)\n",
    "print(f\"Meilleure combinaison retenue: {xgb.best_params_}\")\n",
    "\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    xgb,\n",
    "    X_test,\n",
    "    y_test_class,\n",
    "    cmap=plt.cm.Blues,\n",
    "    normalize=\"true\",\n",
    ")\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18455188-e334-43c4-b55b-7010de2c9d39",
   "metadata": {},
   "source": [
    "**Pour aller plus loin:** Comparez les performances de classification entre votre meilleur modèle de classification et votre meilleur modèle de régression pour lequel vous reconstruisez les classes prédites selon la valeurs exactes prédites."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c7c031-d534-4624-9723-e862e432a70a",
   "metadata": {},
   "source": [
    "# Fin :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
